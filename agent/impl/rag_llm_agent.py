import os
import random
import re
import json
import shutil
from datetime import datetime
from typing import List, Dict, Any
import math

from action.impl.click_action import ClickAction
from action.impl.random_input_action import RandomInputAction
from action.impl.random_select_action import RandomSelectAction
from action.impl.restart_action import RestartAction
from action.web_action import WebAction
from agent.agent import Agent
from state.web_state import WebState
import requests
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¤„ç†Chromaç‰ˆæœ¬å…¼å®¹æ€§
try:
    from langchain_chroma import Chroma
except ImportError:
    try:
        from langchain_community.vectorstores import Chroma
    except ImportError:
        from langchain.vectorstores import Chroma
        import warnings
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain")

from langchain.embeddings.base import Embeddings
from langchain.schema import Document


def manage_vectorstore(vectorstore, max_entries=None, cleanup_ratio=0.8, kb_name="KB", 
                      close_connection=False, verbose=False):
    """
    ğŸš€ ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•° - åˆå¹¶æ¸…ç†å’Œè¿æ¥ç®¡ç†åŠŸèƒ½
    
    Args:
        vectorstore: å‘é‡å­˜å‚¨å¯¹è±¡
        max_entries: æœ€å¤§è®°å½•æ•°ï¼ŒNoneè¡¨ç¤ºä¸æ¸…ç†è®°å½•
        cleanup_ratio: æ¸…ç†åä¿ç•™çš„æ¯”ä¾‹ï¼ˆ0.8 = ä¿ç•™80%ï¼‰
        kb_name: çŸ¥è¯†åº“åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        close_connection: æ˜¯å¦å…³é—­è¿æ¥
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        bool: æ˜¯å¦æ‰§è¡Œäº†æ¸…ç†æ“ä½œ
    """
    if vectorstore is None:
        return False
    
    cleaned = False
    
    # 1. è®°å½•æ¸…ç†åŠŸèƒ½
    if max_entries is not None:
        try:
            if hasattr(vectorstore, '_collection'):
                current_count = vectorstore._collection.count()
                if current_count > max_entries:
                    if verbose:
                        print(f"ğŸ§¹ {kb_name} cleanup: {current_count} > {max_entries}")
                    
                    # è®¡ç®—åˆ é™¤æ•°é‡
                    target_count = int(max_entries * cleanup_ratio)
                    excess_count = current_count - target_count
                    
                    try:
                        # è·å–æ‰€æœ‰è®°å½•çš„IDå’Œæ—¶é—´æˆ³
                        all_data = vectorstore._collection.get(include=['metadatas'])
                        
                        # æŒ‰æ—¶é—´æˆ³æ’åº
                        records_with_ids = []
                        for i, metadata in enumerate(all_data['metadatas']):
                            timestamp = metadata.get('timestamp', '1970-01-01T00:00:00')
                            records_with_ids.append((timestamp, all_data['ids'][i]))
                        
                        # åˆ é™¤æœ€æ—§çš„è®°å½•
                        records_with_ids.sort(key=lambda x: x[0])
                        ids_to_delete = [record[1] for record in records_with_ids[:excess_count]]
                        
                        if ids_to_delete:
                            vectorstore._collection.delete(ids=ids_to_delete)
                            if verbose:
                                print(f"ğŸ§¹ {kb_name}: Deleted {len(ids_to_delete)} records (kept {target_count})")
                            cleaned = True
                    
                    except Exception as delete_error:
                        if verbose:
                            print(f"âš ï¸ {kb_name}: Delete failed: {delete_error}")
                
                elif verbose and current_count > max_entries * 0.8:
                    print(f"ğŸ“Š {kb_name}: {current_count} records (limit: {max_entries})")
                    
        except Exception as e:
            if verbose:
                print(f"Error checking {kb_name} records: {e}")
    
    # 2. è¿æ¥å…³é—­åŠŸèƒ½
    if close_connection:
        try:
            if verbose:
                print(f"ğŸ”Œ Closing {kb_name} connections...")
            
            # å…³é—­Chromaå®¢æˆ·ç«¯
            if hasattr(vectorstore, '_client') and vectorstore._client:
                vectorstore._client.reset()
            
            # æ¸…ç†é›†åˆå¼•ç”¨
            if hasattr(vectorstore, '_collection'):
                del vectorstore._collection
            
        except Exception as e:
            if verbose:
                print(f"Error closing {kb_name} connections: {e}")
    
    return cleaned


# ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’ - ä½¿ç”¨SiliconFlow API
class LLMInterface:
    def __init__(self, params, verbose=False):
        """
        ä½¿ç”¨SiliconFlow APIè¿›è¡ŒLLMäº¤äº’
        """
        self.api_key = params.get("api_key", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.chat_url = params.get("chat_url", "https://api.siliconflow.cn/v1/chat/completions")
        self.model = params.get("model", "deepseek-ai/DeepSeek-R1")
        self.enable_thinking = params.get("enable_thinking", False)
        self.max_tokens = params.get("max_tokens", 1024)
        self.temperature = params.get("temperature", 0.7)
        self.verbose = verbose  # æ·»åŠ  verbose å±æ€§
        
        # ä¸ºæ¯ä¸ªLLMå®ä¾‹ç”Ÿæˆå”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
        import uuid
        self.session_id = str(uuid.uuid4())
        self.test_session_counter = 0  # æµ‹è¯•ä¼šè¯è®¡æ•°å™¨
        
        if self.verbose:
            print(f"LLMä¼šè¯ID: {self.session_id}")

    def reset_session(self):
        """
        é‡ç½®ä¼šè¯çŠ¶æ€ - ä¸ºæ–°æµ‹è¯•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„ä¼šè¯
        """
        import uuid
        old_session_id = self.session_id
        self.session_id = str(uuid.uuid4())
        self.test_session_counter += 1
        
        if self.verbose:
            print(f"LLMä¼šè¯é‡ç½®:")
            print(f"  æ—§ä¼šè¯ID: {old_session_id}")
            print(f"  æ–°ä¼šè¯ID: {self.session_id}")
            print(f"  æµ‹è¯•è®¡æ•°: {self.test_session_counter}")

    def _build_isolation_prompt(self, user_prompt: str) -> str:
        """
        æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        isolation_header = f"""
[æµ‹è¯•éš”ç¦»å£°æ˜]
- è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„ç‹¬ç«‹æµ‹è¯•ä¼šè¯
- ä¼šè¯ID: {self.session_id}
- æµ‹è¯•ç¼–å·: {self.test_session_counter}
- è¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯å†å²å’Œè®°å¿†
- è¯·åŸºäºå½“å‰æä¾›çš„ä¿¡æ¯ç‹¬ç«‹åšå‡ºå†³ç­–
- ä¸è¦å‚è€ƒä¹‹å‰æµ‹è¯•çš„ç»“æœæˆ–ç»éªŒ

[å½“å‰æµ‹è¯•ä»»åŠ¡]
{user_prompt}

è¯·ä¸¥æ ¼åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œç¡®ä¿æµ‹è¯•çš„ç‹¬ç«‹æ€§å’Œä¸€è‡´æ€§ã€‚
"""
        return isolation_header.strip()
        
    def chat_with_thinking(self, prompt: str) -> Dict[str, str]:
        """
        å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å†…å®¹å’Œthinkingè¿‡ç¨‹
        è¿”å›: {"content": "å›ç­”å†…å®¹", "reasoning": "æ€è€ƒè¿‡ç¨‹"}
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            # æ·»åŠ ä¼šè¯æ ‡è¯†ç¬¦åˆ°è¯·æ±‚å¤´
            "X-Session-ID": self.session_id,
            "X-Test-Session": str(self.test_session_counter)
        }
        
        # æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯
        isolated_prompt = self._build_isolation_prompt(prompt)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯ä¸€ä¸ªWebæµ‹è¯•ä¸“å®¶ã€‚å½“å‰ä¼šè¯ID: {self.session_id}ã€‚è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æµ‹è¯•ä¼šè¯ï¼Œè¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯è®°å¿†ã€‚"
                },
                {
                    "role": "user", 
                    "content": isolated_prompt
                }
            ],
            "stream": False,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.7,
            "top_k": 50,
            "frequency_penalty": 0.5,
            "n": 1,
            # æ·»åŠ éšæœºç§å­ç¡®ä¿æ¯æ¬¡è°ƒç”¨çš„ç‹¬ç«‹æ€§
            "seed": hash(self.session_id + str(self.test_session_counter)) % 2147483647
        }
        
        # åªæœ‰æ”¯æŒthinkingçš„æ¨¡å‹æ‰æ·»åŠ ç›¸å…³å‚æ•°
        if "QwQ" in self.model and self.enable_thinking:
            payload.update({
                "enable_thinking": True,
                "thinking_budget": 4096
            })
        
        try:
            response = requests.post(self.chat_url, json=payload, headers=headers)
            response.raise_for_status()
            
            result = response.json()
            choice = result.get("choices", [{}])[0]
            message = choice.get("message", {})
            
            content = message.get("content", "")
            reasoning = message.get("reasoning_content", "")
            
            if self.verbose:
                print(f"LLMå“åº” [ä¼šè¯:{self.session_id[:8]}]: {content}")
            if reasoning:
                print(f"LLMæ¨ç†è¿‡ç¨‹ [ä¼šè¯:{self.session_id[:8]}]: {reasoning[:200]}...")  # åªæ‰“å°å‰200ä¸ªå­—ç¬¦
                
            return {
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            if self.verbose:
                print(f"LLMè°ƒç”¨å¤±è´¥ [ä¼šè¯:{self.session_id[:8]}]: {e}")
            return {
                "content": "æ¨¡å‹è°ƒç”¨å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "reasoning": ""
            }


class SiliconFlowEmbeddings(Embeddings):
    """
    ä½¿ç”¨SiliconFlow APIçš„åµŒå…¥æœåŠ¡
    """

    def __init__(
            self,
            token: str = "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
            url: str = "https://api.siliconflow.cn/v1/embeddings",
            model: str = "BAAI/bge-large-zh-v1.5",
            verbose: bool = False
    ):
        super().__init__()
        self.token = token
        self.url = url
        self.model = model
        self.verbose = verbose

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£çš„å‘é‡åŒ–"""
        embeddings = []
        for text in texts:
            embedding = self._get_embedding(text)
            embeddings.append(embedding)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢æ–‡æœ¬çš„å‘é‡åŒ–"""
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        payload = {
            "model": self.model,
            "input": text,
            "encoding_format": "float"
        }
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data["data"][0]["embedding"]
        except Exception as e:
            if self.verbose:
                print(f"åµŒå…¥å‘é‡è·å–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„å‘é‡ï¼ˆå…¨é›¶å‘é‡ï¼Œç»´åº¦å‡è®¾ä¸º1024ï¼‰
            return [0.0] * 1024


class StateKnowledgeBase:
    """
    ä¸“é—¨ç®¡ç†é¡µé¢çŠ¶æ€ä¿¡æ¯çš„çŸ¥è¯†åº“
    å­˜å‚¨æ¯ä¸ªæµ‹è¯•çŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯ï¼šå¯ç‚¹å‡»ç»„ä»¶ã€é¡µé¢ç»“æ„ã€æµ‹è¯•è·¯å¾„ç­‰
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("state_collection_name", "state_knowledge")
        self.chunk_size = params.get("state_chunk_size", 800)  # çŠ¶æ€ä¿¡æ¯è¾ƒå¤§ï¼Œä½¿ç”¨æ›´å¤§çš„chunk
        self.chunk_overlap = params.get("state_chunk_overlap", 100)
        self.max_entries = params.get("max_state_entries", 500)
        self.persist_directory = params.get("state_persist_directory", "./state_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        # å¦‚æœéœ€è¦æ¸…ç©ºstateçŸ¥è¯†åº“
        if params.get("clear_state_on_init", True):
            self.clear_state_vectorstore()
    
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded state KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new state KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize state KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_state_vectorstore(self):
        """æ¸…ç©ºçŠ¶æ€çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing state KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="State KB", verbose=self.verbose)
        self.vectorstore = None
        
        import gc
        gc.collect()
        
        # åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("State KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear state KB: {e}")
        
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create state directory: {e}")

    def add_page_state(self, page_title: str, action_list: List, selected_action_index: int, 
                      reasoning: str = "", timestamp: str = None):
        """
        æ·»åŠ è¯¦ç»†çš„é¡µé¢çŠ¶æ€ä¿¡æ¯åˆ°çŸ¥è¯†åº“
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            # è¯¦ç»†åˆ†æå¯ç”¨åŠ¨ä½œ
            click_actions = []
            input_actions = []
            select_actions = []
            other_actions = []
            
            for i, action in enumerate(action_list):
                action_info = {
                    "index": i,
                    "text": getattr(action, 'text', 'Unknown'),
                    "type": type(action).__name__
                }
                
                if isinstance(action, ClickAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'unknown'),
                        "addition_info": getattr(action, 'addition_info', '')
                    })
                    click_actions.append(action_info)
                elif isinstance(action, RandomInputAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'input')
                    })
                    input_actions.append(action_info)
                elif isinstance(action, RandomSelectAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'select'),
                        "options": getattr(action, 'options', 'N/A')
                    })
                    select_actions.append(action_info)
                else:
                    other_actions.append(action_info)
            
            state_summary = {
                "total_actions": len(action_list),
                "click_actions_count": len(click_actions),
                "input_actions_count": len(input_actions),
                "select_actions_count": len(select_actions),
                "other_actions_count": len(other_actions),
                "selected_action_index": selected_action_index,
                "selected_action_type": type(action_list[selected_action_index]).__name__ if selected_action_index < len(action_list) else "Invalid"
            }
            
            # æ„é€ è¯¦ç»†çš„æ–‡æ¡£å†…å®¹
            content = f"""
æ—¶é—´: {timestamp}
é¡µé¢æ ‡é¢˜: {page_title}

é¡µé¢çŠ¶æ€æ¦‚è§ˆ:
- æ€»å¯ç”¨åŠ¨ä½œæ•°: {state_summary['total_actions']}
- å¯ç‚¹å‡»å…ƒç´ : {state_summary['click_actions_count']} ä¸ª
- è¾“å…¥å­—æ®µ: {state_summary['input_actions_count']} ä¸ª  
- é€‰æ‹©æ¡†: {state_summary['select_actions_count']} ä¸ª
- å…¶ä»–åŠ¨ä½œ: {state_summary['other_actions_count']} ä¸ª

é€‰æ‹©çš„åŠ¨ä½œ:
- ç´¢å¼•: {selected_action_index}
- ç±»å‹: {state_summary['selected_action_type']}
- è¯¦æƒ…: {getattr(action_list[selected_action_index], 'text', 'Unknown') if selected_action_index < len(action_list) else 'Invalid'}

è¯¦ç»†å¯ç‚¹å‡»å…ƒç´ :
{json.dumps(click_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†è¾“å…¥å­—æ®µ:
{json.dumps(input_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†é€‰æ‹©æ¡†:
{json.dumps(select_actions, ensure_ascii=False, indent=2)}

å†³ç­–æ¨ç†:
{reasoning[:500]}{'...' if len(reasoning) > 500 else ''}

æµ‹è¯•è·¯å¾„åˆ†æ:
é¡µé¢ "{page_title}" æä¾›äº† {state_summary['total_actions']} ä¸ªäº¤äº’é€‰é¡¹ï¼Œä¸»è¦åŒ…å« {state_summary['click_actions_count']} ä¸ªç‚¹å‡»ç›®æ ‡å’Œ {state_summary['input_actions_count']} ä¸ªè¾“å…¥æœºä¼šã€‚è¿™ç§é…ç½®é€‚åˆè¿›è¡Œ{'å¯¼èˆªæµ‹è¯•' if state_summary['click_actions_count'] > state_summary['input_actions_count'] else 'è¡¨å•æµ‹è¯•'}ã€‚
"""
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "page_title": page_title[:100],
                    "total_actions": state_summary['total_actions'],
                    "click_actions": state_summary['click_actions_count'],
                    "input_actions": state_summary['input_actions_count'],
                    "selected_action_index": selected_action_index,
                    "selected_action_type": state_summary['selected_action_type'],
                    "type": "page_state_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            # æŒä¹…åŒ–
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved state: {page_title} ({state_summary['total_actions']} actions, {len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save page state: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)

    def retrieve_similar_states(self, current_page_title: str, action_count: int, k: int = 3) -> str:
        """
        æ ¹æ®é¡µé¢æ ‡é¢˜å’ŒåŠ¨ä½œæ•°é‡æ£€ç´¢ç›¸ä¼¼çš„é¡µé¢çŠ¶æ€ä¿¡æ¯
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            # æ„å»ºæŸ¥è¯¢
            query = f"é¡µé¢æ ‡é¢˜ {current_page_title} åŠ¨ä½œæ•°é‡ {action_count} é¡µé¢çŠ¶æ€ äº¤äº’é€‰é¡¹"
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            # ç»„ç»‡æ£€ç´¢åˆ°çš„çŠ¶æ€è®°å½•
            similar_states = []
            for doc in results:
                similar_states.append(doc.page_content)
            
            state_context = "\n--- ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ ---\n" + "\n\n".join(similar_states)
            return state_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve similar states: {e}")
            return ""


class ThinkingKnowledgeBase:
    """
    ç®¡ç†thinkingè¿‡ç¨‹çš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("thinking_collection_name", "thinking_knowledge")
        self.chunk_size = params.get("thinking_chunk_size", 500)
        self.chunk_overlap = params.get("thinking_chunk_overlap", 50)
        self.max_entries = params.get("max_thinking_entries", 1000)  # é™åˆ¶çŸ¥è¯†åº“å¤§å°
        self.persist_directory = params.get("thinking_persist_directory", "./thinking_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        # æ¸…ç†è®¡æ•°å™¨å’Œé—´éš”
        self.cleanup_counter = 0
        self.cleanup_interval = params.get("thinking_cleanup_interval", 20)  # æ¯20æ¬¡æ·»åŠ åæ¸…ç†ä¸€æ¬¡
        
        if params.get("clear_thinking_on_init", True):
            self.clear_thinking_vectorstore()
        
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            # å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡å­˜å‚¨
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded thinking KB with {self.vectorstore._collection.count()} documents")
            else:
                # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new thinking KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize thinking KB: {e}")
            # åˆ›å»ºä¸´æ—¶çš„å†…å­˜å‘é‡å­˜å‚¨ä½œä¸ºå¤‡ç”¨
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_thinking_vectorstore(self):
        """æ¸…ç©ºThinkingçŸ¥è¯†åº“ - å½»åº•åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
        if self.verbose:
            print("Clearing thinking KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="Thinking KB", verbose=self.verbose)
        self.vectorstore = None
        
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # 3. åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Thinking KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear thinking KB: {e}")
        
        # 4. é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create thinking directory: {e}")
    
    def add_thinking(self, prompt: str, reasoning: str, action_taken: str, timestamp: str = None):
        """
        å°†thinkingè¿‡ç¨‹æ·»åŠ åˆ°çŸ¥è¯†åº“
        """
        if not reasoning or reasoning.strip() == "":
            return
            
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            content = f"""
            æ—¶é—´: {timestamp}
            æµ‹è¯•åœºæ™¯: {prompt[:200]}...
            æ¨ç†è¿‡ç¨‹: {reasoning}
            é‡‡å–çš„è¡ŒåŠ¨: {action_taken}
            """
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "prompt_preview": prompt[:100],
                    "action": action_taken,
                    "type": "thinking_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])

            self.vectorstore.add_documents(split_docs)
            
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved thinking: {action_taken[:30]}... ({len(split_docs)} chunks)")
            
            self.cleanup_counter += 1
            if self.cleanup_counter >= self.cleanup_interval:
                manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)
                self.cleanup_counter = 0
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save thinking: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)

    def retrieve_relevant_thinking(self, query: str, k: int = 3) -> str:
        """
        æ ¹æ®æŸ¥è¯¢æ£€ç´¢ç›¸å…³çš„thinkingè®°å½•
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            relevant_thinking = []
            for doc in results:
                relevant_thinking.append(doc.page_content)
            
            thinking_context = "\n--- ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ ---\n" + "\n\n".join(relevant_thinking)
            return thinking_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve thinking: {e}")
            return ""


class RetrieverInterface:
    def __init__(self, params, verbose=False):
        self.knowledge_path = params.get("knowledge_path", r"C:\Users\ASUS\Desktop\Reasoning+RAG Web Exploration\Make LLM a Testing Expert Bringing Human-like Interaction to.pdf")
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        self.web_testing_pdf = os.path.join(project_root, "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf")
        
        self.chunk_size = params.get("chunk_size", 500)
        self.chunk_overlap = params.get("chunk_overlap", 50)
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("collection_name", "siliconflow_embed")
        self.top_k = params.get("top_k", 3)
        self.verbose = verbose
        self.persist_directory = params.get("rag_persist_directory", "./rag_vectorstore")
        self._vectorstore = None

    def _close_vectorstore_connections(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥å…³é—­æ–¹æ³•"""
        manage_vectorstore(self._vectorstore, close_connection=True, kb_name="RAG KB", verbose=self.verbose)
        self._vectorstore = None

    def _force_close_sqlite_connections(self):
        """
        å¼ºåˆ¶å…³é—­SQLiteè¿æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        try:
            import sqlite3
            import glob
            
            if self.verbose:
                print("Forcing SQLite connections to close...")
            
            # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„SQLiteæ–‡ä»¶
            sqlite_patterns = [
                os.path.join(self.persist_directory, "**/*.sqlite*"),
                os.path.join(self.persist_directory, "**/chroma*"),
            ]
            
            sqlite_files = []
            for pattern in sqlite_patterns:
                sqlite_files.extend(glob.glob(pattern, recursive=True))
            
            if sqlite_files and self.verbose:
                print(f"Found {len(sqlite_files)} database files")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©è¿æ¥è‡ªç„¶å…³é—­
            import time
            time.sleep(0.5)
            
        except Exception as e:
            if self.verbose:
                print(f"Error forcing SQLite connections close: {e}")

    def _remove_files_with_retry(self, max_attempts=5, delay=1):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        for attempt in range(max_attempts):
            try:
                if not os.path.exists(self.persist_directory):
                    return True
                
                if self.verbose:
                    print(f"Attempting to remove directory (attempt {attempt + 1}/{max_attempts})")
                
                # åˆ é™¤ç›®å½•
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("RAG vectorstore cleared successfully")
                return True
                
            except Exception as e:
                if attempt < max_attempts - 1:
                    if self.verbose:
                        print(f"Deletion failed, retrying in {delay}s... Error: {e}")
                    import time
                    time.sleep(delay)
                    delay *= 1.5  # æŒ‡æ•°é€€é¿
                else:
                    if self.verbose:
                        print(f"Failed to delete directory after {max_attempts} attempts: {e}")
                    return False
        
        return False

    def clear_vectorstore(self):
        """
        å½»åº•æ¸…ç©ºRAGæ•°æ®åº“ - å®Œå…¨æ”¹è¿›ç‰ˆ
        """
        if self.verbose:
            print("Clearing RAG database...")
        
        # æ­¥éª¤1: å…³é—­æ‰€æœ‰å‘é‡å­˜å‚¨è¿æ¥
        self._close_vectorstore_connections()
        
        # æ­¥éª¤2: å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # æ­¥éª¤3: å¼ºåˆ¶å…³é—­SQLiteè¿æ¥
        self._force_close_sqlite_connections()
        
        # æ­¥éª¤4: å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤
        success = self._remove_files_with_retry()
        
        # æ­¥éª¤5: é‡æ–°åˆ›å»ºç©ºçš„æŒä¹…åŒ–ç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # éªŒè¯ç›®å½•ç¡®å®ä¸ºç©º
            files_remaining = []
            if os.path.exists(self.persist_directory):
                for root, dirs, files in os.walk(self.persist_directory):
                    files_remaining.extend(files)
            
            if not files_remaining:
                if self.verbose:
                    print("RAG database cleared completely")
            else:
                if self.verbose:
                    print(f"Warning: {len(files_remaining)} files still remain")
                    
        except Exception as e:
            if self.verbose:
                print(f"Failed to create persist directory: {e}")

    def _load_vectorstore(self):
        if self._vectorstore is not None:
            return

        if self.verbose:
            print("Initializing RAG knowledge base...")

        possible_paths = [
            self.web_testing_pdf,
            os.path.join(os.getcwd(), "..", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            os.path.join(os.path.dirname(os.getcwd()), "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            "../../agent/ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"
        ]

        actual_pdf_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                actual_pdf_path = abs_path
                if self.verbose:
                    print(f"Found PDF: {os.path.basename(abs_path)}")
                break
        
        try:
            all_docs = []
            
            if self.knowledge_path and os.path.exists(self.knowledge_path):
                if self.verbose:
                    print(f"Loading knowledge file: {os.path.basename(self.knowledge_path)}")
                loader = PyPDFLoader(self.knowledge_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Knowledge Base"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            
            if actual_pdf_path:
                if self.verbose:
                    print("Loading web testing guidelines")
                loader = PyPDFLoader(actual_pdf_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Web Testing Guidelines"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            else:
                if self.verbose:
                    print("Warning: Web testing guidelines PDF not found")
            
            if not all_docs:
                if self.verbose:
                    print("Warning: No knowledge documents found")

                embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
                self._vectorstore = Chroma(
                    embedding_function=embed_model,
                    collection_name=self.collection_name,
                    persist_directory=self.persist_directory
                )
                return
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
            )
            docs = text_splitter.split_documents(all_docs)
            if self.verbose:
                print(f"Document splitting complete: {len(docs)} chunks")
            
            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma.from_documents(
                documents=docs, 
                embedding=embed_model, 
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )
            
            if self.verbose:
                print("RAG knowledge base initialized successfully")
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to load vectorstore: {e}")

            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma(
                embedding_function=embed_model,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )

    def retrieve(self, prompt: str) -> str:
        try:
            if not self._vectorstore:
                self._load_vectorstore()
            
            if not self._vectorstore:
                if self.verbose:
                    print("Vectorstore not initialized, cannot retrieve")
                return prompt
                
            query = prompt
            result = self._vectorstore.similarity_search(query, k=self.top_k)
            
            if not result:
                if self.verbose:
                    print("No relevant knowledge retrieved")
                return prompt
            
            source_groups = {}
            for doc in result:
                source = doc.metadata.get("source_file", "Unknown")
                if source not in source_groups:
                    source_groups[source] = []
                source_groups[source].append(doc.page_content)
            
            knowledge_sections = []
            for source, contents in source_groups.items():
                section = f"[{source}]:\n" + "\n".join(contents)
                knowledge_sections.append(section)
            
            source_knowledge = "\n\n".join(knowledge_sections)
            
            augmented_prompt = f"""
            ä½¿ç”¨ä¸‹é¢çš„ä¸“ä¸šçŸ¥è¯†æ¥å¸®åŠ©å›ç­”æŸ¥è¯¢:
            
            ä¸“ä¸šçŸ¥è¯†åº“:
            {source_knowledge}
            
            æŸ¥è¯¢: 
            {query}
            
            è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ï¼Œç»“åˆWebæµ‹è¯•çš„æœ€ä½³å®è·µæ¥å›ç­”ã€‚
            """
            
            if self.verbose:
                print(f"RAG retrieved {len(result)} chunks from {len(source_groups)} sources")
            
            return augmented_prompt
            
        except Exception as e:
            if self.verbose:
                print(f"RAG retrieval failed: {e}")
            return prompt


class DiversityTracker:
    """
    ğŸ² å¤šæ ·æ€§è·Ÿè¸ªå™¨ - ç›‘æ§å’Œå¢å¼ºæµ‹è¯•çš„å¤šæ ·æ€§
    """
    
    def __init__(self, verbose=False):
        self.verbose = verbose
        self.action_diversity_score = 0.0
        self.path_diversity_score = 0.0
        self.exploration_history = []
        self.decision_modes_used = {}  # è·Ÿè¸ªä½¿ç”¨çš„å†³ç­–æ¨¡å¼
        self.exploration_strategies_used = {}  # è·Ÿè¸ªä½¿ç”¨çš„æ¢ç´¢ç­–ç•¥
        
        # æ¢ç´¢ç­–ç•¥æƒé‡ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        self.exploration_strategy_weights = {
            'conservative': 0.25,    # ä¿å®ˆç­–ç•¥ï¼šåŸºäºæˆåŠŸç»éªŒ
            'innovative': 0.35,     # åˆ›æ–°ç­–ç•¥ï¼šæ¢ç´¢æ–°è·¯å¾„
            'balanced': 0.25,       # å¹³è¡¡ç­–ç•¥ï¼šç»¼åˆè€ƒè™‘
            'risk_focused': 0.15    # é£é™©å¯¼å‘ï¼šä¸“æ³¨è¾¹ç•Œæµ‹è¯•
        }
        
        # å†³ç­–æ¨¡å¼æƒé‡ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        self.decision_mode_weights = {
            'conservative': 0.3,    # ä¿å®ˆå†³ç­–ï¼šåŸºäºå†å²æˆåŠŸ
            'exploratory': 0.4,     # æ¢ç´¢å†³ç­–ï¼šå°è¯•æ–°è·¯å¾„
            'balanced': 0.3         # å¹³è¡¡å†³ç­–ï¼šç»¼åˆè€ƒè™‘
        }
    
    def select_exploration_strategy(self) -> str:
        """
        ğŸ¯ æ™ºèƒ½é€‰æ‹©æ¢ç´¢ç­–ç•¥ï¼Œå¹³è¡¡å„ç§ç­–ç•¥çš„ä½¿ç”¨
        """
        # è®¡ç®—å„ç­–ç•¥çš„ä½¿ç”¨é¢‘ç‡
        total_used = sum(self.exploration_strategies_used.values()) or 1
        strategy_usage = {
            strategy: self.exploration_strategies_used.get(strategy, 0) / total_used
            for strategy in self.exploration_strategy_weights.keys()
        }
        
        # è®¡ç®—è°ƒæ•´åçš„æƒé‡ï¼ˆé™ä½è¿‡åº¦ä½¿ç”¨ç­–ç•¥çš„æƒé‡ï¼‰
        adjusted_weights = {}
        for strategy, base_weight in self.exploration_strategy_weights.items():
            usage_penalty = strategy_usage[strategy] * 0.5  # ä½¿ç”¨é¢‘ç‡æƒ©ç½š
            adjusted_weights[strategy] = max(0.1, base_weight - usage_penalty)
        
        # åŠ æƒéšæœºé€‰æ‹©
        strategies = list(adjusted_weights.keys())
        weights = list(adjusted_weights.values())
        selected_strategy = random.choices(strategies, weights=weights)[0]
        
        # æ›´æ–°ä½¿ç”¨è®¡æ•°
        self.exploration_strategies_used[selected_strategy] = self.exploration_strategies_used.get(selected_strategy, 0) + 1
        
        if self.verbose:
            print(f"ğŸ¯ é€‰æ‹©æ¢ç´¢ç­–ç•¥: {selected_strategy} (æƒé‡: {adjusted_weights[selected_strategy]:.2f})")
        
        return selected_strategy
    
    def select_decision_mode(self) -> str:
        """
        âš¡ æ™ºèƒ½é€‰æ‹©å†³ç­–æ¨¡å¼ï¼Œç¡®ä¿å†³ç­–å¤šæ ·æ€§
        """
        # è®¡ç®—å„æ¨¡å¼çš„ä½¿ç”¨é¢‘ç‡
        total_used = sum(self.decision_modes_used.values()) or 1
        mode_usage = {
            mode: self.decision_modes_used.get(mode, 0) / total_used
            for mode in self.decision_mode_weights.keys()
        }
        
        # è®¡ç®—è°ƒæ•´åçš„æƒé‡
        adjusted_weights = {}
        for mode, base_weight in self.decision_mode_weights.items():
            usage_penalty = mode_usage[mode] * 0.4  # ä½¿ç”¨é¢‘ç‡æƒ©ç½š
            adjusted_weights[mode] = max(0.1, base_weight - usage_penalty)
        
        # åŠ æƒéšæœºé€‰æ‹©
        modes = list(adjusted_weights.keys())
        weights = list(adjusted_weights.values())
        selected_mode = random.choices(modes, weights=weights)[0]
        
        # æ›´æ–°ä½¿ç”¨è®¡æ•°
        self.decision_modes_used[selected_mode] = self.decision_modes_used.get(selected_mode, 0) + 1
        
        if self.verbose:
            print(f"âš¡ é€‰æ‹©å†³ç­–æ¨¡å¼: {selected_mode} (æƒé‡: {adjusted_weights[selected_mode]:.2f})")
        
        return selected_mode
    
    def calculate_action_diversity(self, action_history: List[str]) -> float:
        """
        ğŸ“Š è®¡ç®—åŠ¨ä½œå¤šæ ·æ€§åˆ†æ•°
        """
        if len(action_history) < 2:
            return 1.0
        
        # åˆ†ææœ€è¿‘çš„åŠ¨ä½œç±»å‹åˆ†å¸ƒ
        recent_actions = action_history[-10:]  # åˆ†ææœ€è¿‘10ä¸ªåŠ¨ä½œ
        action_types = {}
        for action in recent_actions:
            action_type = action.split()[0] if action else "Unknown"
            action_types[action_type] = action_types.get(action_type, 0) + 1
        
        # è®¡ç®—ç†µä½œä¸ºå¤šæ ·æ€§æŒ‡æ ‡
        total = len(recent_actions)
        entropy = 0
        for count in action_types.values():
            p = count / total
            if p > 0:
                entropy -= p * math.log2(p)
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        max_entropy = math.log2(len(action_types)) if action_types else 1
        diversity_score = entropy / max_entropy if max_entropy > 0 else 0
        
        self.action_diversity_score = diversity_score
        return diversity_score
    
    def get_diversity_feedback(self, action_history: List[str]) -> str:
        """
        ğŸ¨ è·å–å¤šæ ·æ€§åé¦ˆå»ºè®®
        """
        diversity_score = self.calculate_action_diversity(action_history)
        
        if diversity_score < 0.3:
            return """
ğŸ² **å¤šæ ·æ€§å¢å¼ºå»ºè®®**ï¼š
- å½“å‰æµ‹è¯•æ¨¡å¼è¾ƒä¸ºå•ä¸€ï¼Œå»ºè®®å°è¯•ä¸åŒç±»å‹çš„äº¤äº’
- è€ƒè™‘æ¢ç´¢è¾“å…¥å­—æ®µã€é€‰æ‹©æ¡†ã€é“¾æ¥ç­‰å¤šç§å…ƒç´ 
- å°è¯•ä¸åŒçš„æµ‹è¯•æ•°æ®å’Œæ“ä½œåºåˆ—
"""
        elif diversity_score < 0.6:
            return """
âš–ï¸ **å¹³è¡¡æ€§å»ºè®®**ï¼š
- æµ‹è¯•å¤šæ ·æ€§é€‚ä¸­ï¼Œå¯ä»¥åœ¨å½“å‰åŸºç¡€ä¸Šé€‚åº¦æ‰©å±•
- æ³¨æ„å¹³è¡¡æ¢ç´¢æ–°åŠŸèƒ½å’ŒéªŒè¯å·²çŸ¥åŠŸèƒ½
- é€‚å½“å¢åŠ è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸åœºæ™¯æµ‹è¯•
"""
        else:
            return """
ğŸŒŸ **å¤šæ ·æ€§è‰¯å¥½**ï¼š
- å½“å‰æµ‹è¯•å±•ç°äº†è‰¯å¥½çš„å¤šæ ·æ€§
- ç»§ç»­ä¿æŒå¤šå…ƒåŒ–çš„æµ‹è¯•ç­–ç•¥
- å¯ä»¥æ·±å…¥æ¢ç´¢å‘ç°çš„æœ‰è¶£åŠŸèƒ½ç‚¹
"""
    
    def get_exploration_enhancement_queries(self, page_title: str, exploration_strategy: str) -> List[str]:
        """
        ğŸ” æ ¹æ®é€‰æ‹©çš„æ¢ç´¢ç­–ç•¥ç”Ÿæˆå¢å¼ºæŸ¥è¯¢
        """
        base_queries = {
            'conservative': [
                f"é¡µé¢æµ‹è¯•åˆ†æ {page_title} åŠŸèƒ½æµ‹è¯• é£é™©è¯†åˆ«",
                f"æˆåŠŸæµ‹è¯•æ¡ˆä¾‹ {page_title} æœ€ä½³å®è·µ",
                f"ç¨³å®šæµ‹è¯•ç­–ç•¥ éªŒè¯æ–¹æ³• {page_title}"
            ],
            'innovative': [
                f"åˆ›æ–°æµ‹è¯•æ–¹æ³• {page_title} æœªè¦†ç›–æµ‹è¯•ç‚¹",
                f"è¾¹ç•Œæµ‹è¯• å¼‚å¸¸åœºæ™¯ {page_title} æ¢ç´¢æ€§æµ‹è¯•",
                f"æ–°é¢–æµ‹è¯•è·¯å¾„ å‘ç°æ½œåœ¨é—®é¢˜ {page_title}"
            ],
            'balanced': [
                f"ç»¼åˆæµ‹è¯•ç­–ç•¥ {page_title} å…¨é¢è¦†ç›–",
                f"å¹³è¡¡æ¢ç´¢ä¸éªŒè¯ {page_title} æµ‹è¯•è§„åˆ’",
                f"å¤šç»´åº¦æµ‹è¯•åˆ†æ {page_title} ç³»ç»Ÿæ€§æ–¹æ³•"
            ],
            'risk_focused': [
                f"é£é™©å¯¼å‘æµ‹è¯• {page_title} å®‰å…¨æ¼æ´",
                f"è¾¹ç•Œæ¡ä»¶æµ‹è¯• æç«¯åœºæ™¯ {page_title}",
                f"é”™è¯¯å¤„ç†æµ‹è¯• å¼‚å¸¸æƒ…å†µ {page_title}"
            ]
        }
        
        return base_queries.get(exploration_strategy, base_queries['balanced'])
    
    def get_decision_enhancement_context(self, decision_mode: str) -> str:
        """
        ğŸ¯ æ ¹æ®å†³ç­–æ¨¡å¼ç”Ÿæˆå¢å¼ºä¸Šä¸‹æ–‡
        """
        context_templates = {
            'conservative': """
## ğŸ›¡ï¸ ä¿å®ˆå†³ç­–æ¨¡å¼æ¿€æ´»
**å†³ç­–åŸåˆ™**ï¼š
- ä¼˜å…ˆé€‰æ‹©å†å²ä¸ŠæˆåŠŸç‡é«˜çš„åŠ¨ä½œç±»å‹
- åŸºäºå·²éªŒè¯çš„æµ‹è¯•è·¯å¾„è¿›è¡Œå†³ç­–
- æœ€å°åŒ–æµ‹è¯•é£é™©ï¼Œç¡®ä¿ç¨³å®šæ¨è¿›
- é‡ç‚¹éªŒè¯æ ¸å¿ƒåŠŸèƒ½å’Œå…³é”®è·¯å¾„

**é€‚ç”¨åœºæ™¯**ï¼šå…³é”®åŠŸèƒ½éªŒè¯ã€ç¨³å®šæ€§æµ‹è¯•ã€å›å½’æµ‹è¯•
""",
            'exploratory': """
## ğŸš€ æ¢ç´¢å†³ç­–æ¨¡å¼æ¿€æ´»
**å†³ç­–åŸåˆ™**ï¼š
- ä¼˜å…ˆå°è¯•å†å²ä¸Šè¾ƒå°‘æ‰§è¡Œçš„åŠ¨ä½œç±»å‹
- å‹‡äºæ¢ç´¢æ–°çš„æµ‹è¯•è·¯å¾„å’ŒåŠŸèƒ½ç‚¹
- é€‚å½“æ‰¿æ‹…æµ‹è¯•é£é™©ä»¥è·å¾—æ–°å‘ç°
- å…³æ³¨æœªè¦†ç›–çš„åŠŸèƒ½åŒºåŸŸå’Œè¾¹ç•Œæ¡ä»¶

**é€‚ç”¨åœºæ™¯**ï¼šåŠŸèƒ½æ¢ç´¢ã€è¾¹ç•Œæµ‹è¯•ã€åˆ›æ–°è·¯å¾„å‘ç°
""",
            'balanced': """
## âš–ï¸ å¹³è¡¡å†³ç­–æ¨¡å¼æ¿€æ´»
**å†³ç­–åŸåˆ™**ï¼š
- åœ¨ç¨³å¥æµ‹è¯•å’Œæ¢ç´¢åˆ›æ–°ä¹‹é—´æ‰¾åˆ°å¹³è¡¡
- æ ¹æ®é¡µé¢é‡è¦æ€§åŠ¨æ€è°ƒæ•´ç­–ç•¥
- ç»¼åˆè€ƒè™‘æµ‹è¯•è¦†ç›–ç‡å’Œé£é™©æ§åˆ¶
- å…¼é¡¾éªŒè¯å·²çŸ¥åŠŸèƒ½å’Œå‘ç°æ–°åŠŸèƒ½

**é€‚ç”¨åœºæ™¯**ï¼šç»¼åˆæµ‹è¯•ã€åŠŸèƒ½éªŒè¯ä¸æ¢ç´¢å¹¶é‡
"""
        }
        
        return context_templates.get(decision_mode, context_templates['balanced'])
    
    def update_diversity_metrics(self, action_taken: str, exploration_strategy: str, decision_mode: str):
        """
        ğŸ“ˆ æ›´æ–°å¤šæ ·æ€§æŒ‡æ ‡
        """
        self.exploration_history.append({
            'action': action_taken,
            'exploration_strategy': exploration_strategy,
            'decision_mode': decision_mode,
            'timestamp': datetime.now().isoformat()
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.exploration_history) > 50:
            self.exploration_history = self.exploration_history[-50:]
    
    def get_diversity_stats(self) -> Dict[str, Any]:
        """
        ğŸ“Š è·å–å¤šæ ·æ€§ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'action_diversity_score': self.action_diversity_score,
            'exploration_strategies_usage': dict(self.exploration_strategies_used),
            'decision_modes_usage': dict(self.decision_modes_used),
            'total_explorations': len(self.exploration_history),
            'current_weights': {
                'exploration': dict(self.exploration_strategy_weights),
                'decision': dict(self.decision_mode_weights)
            }
        }


class DualModelSystem:
    """
    ğŸš€ åŒæ¨¡å‹åä½œç³»ç»Ÿ - R1æ¢ç´¢ + QwQå†³ç­–
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æµ‹æ˜¯å¦åˆ°è¾¾æ–°çŠ¶æ€
    2. å¦‚æœæ˜¯æ–°çŠ¶æ€ï¼Œä½¿ç”¨R1è¿›è¡Œæ·±åº¦æ¢ç´¢åˆ†æ
    3. å°†R1çš„æ¢ç´¢ç»“æœå­˜å‚¨åˆ°ä¸“ç”¨çŸ¥è¯†åº“
    4. ä½¿ç”¨QwQåŸºäºæ¢ç´¢ç»“æœå¿«é€Ÿåšå†³ç­–
    """
    
    def __init__(self, params, knowledge_bases=None, verbose=False):
        self.verbose = verbose
        
        # ğŸ² åˆå§‹åŒ–å¤šæ ·æ€§è·Ÿè¸ªå™¨
        self.diversity_tracker = DiversityTracker(verbose=verbose)
        
        # ğŸš€ RAGçŸ¥è¯†åº“ç³»ç»Ÿ - æ¥æ”¶å¤–éƒ¨ä¼ é€’çš„çŸ¥è¯†åº“å®ä¾‹
        if knowledge_bases:
            self.retriever = knowledge_bases.get('retriever')
            self.state_kb = knowledge_bases.get('state_kb')
            self.thinking_kb = knowledge_bases.get('thinking_kb')
            self.exploration_kb = knowledge_bases.get('exploration_kb')
        else:
            # å¦‚æœæ²¡æœ‰ä¼ é€’çŸ¥è¯†åº“ï¼Œåˆ™è®¾ä¸ºNone
            self.retriever = None
            self.state_kb = None
            self.thinking_kb = None
            self.exploration_kb = None
            if verbose:
                print("âš ï¸ è­¦å‘Š: æœªä¼ é€’çŸ¥è¯†åº“å®ä¾‹ï¼ŒRAGå¢å¼ºåŠŸèƒ½å°†è¢«ç¦ç”¨")
        
        # R1æ¢ç´¢æ¨¡å‹é…ç½®
        r1_params = params.copy()
        r1_params.update({
            "model": "deepseek-ai/DeepSeek-R1",
            "max_tokens": 2048,  # R1éœ€è¦æ›´å¤štokenç”¨äºæ·±åº¦åˆ†æ
            "temperature": 0.8,  # ç¨é«˜æ¸©åº¦é¼“åŠ±æ¢ç´¢
            "enable_thinking": True
        })
        
        # QwQå†³ç­–æ¨¡å‹é…ç½®  
        qwq_params = params.copy()
        qwq_params.update({
            "model": "Qwen/QwQ-32B-Preview", 
            "max_tokens": 512,   # QwQåªéœ€å°‘é‡tokenåšå†³ç­–
            "temperature": 0.3,  # ä½æ¸©åº¦ç¡®ä¿å†³ç­–ç¨³å®š
            "enable_thinking": True
        })
        
        self.r1_explorer = LLMInterface(r1_params, verbose)
        self.qwq_decider = LLMInterface(qwq_params, verbose)
        
        # çŠ¶æ€è·Ÿè¸ª
        self.explored_states = set()  # å·²æ¢ç´¢çš„çŠ¶æ€ç­¾å
        self.state_exploration_cache = {}  # çŠ¶æ€æ¢ç´¢ç»“æœç¼“å­˜
        self.exploration_count = 0
        
        if verbose:
            print(f"ğŸš€ åŒæ¨¡å‹ç³»ç»Ÿåˆå§‹åŒ–:")
            print(f"   ğŸ“¡ R1æ¢ç´¢æ¨¡å‹: {r1_params['model']}")
            print(f"   âš¡ QwQå†³ç­–æ¨¡å‹: {qwq_params['model']}")
            print(f"   ğŸ§  RAGå¢å¼º: {'å¯ç”¨' if knowledge_bases else 'ç¦ç”¨'}")
            print(f"   ğŸ² å¤šæ ·æ€§è·Ÿè¸ªå™¨: å·²å¯ç”¨")
    
    def reset_for_new_test(self):
        """é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€"""
        self.r1_explorer.reset_session()
        self.qwq_decider.reset_session()
        self.explored_states.clear()
        self.state_exploration_cache.clear()
        self.exploration_count = 0
        
        if self.verbose:
            print("ğŸ”„ åŒæ¨¡å‹ç³»ç»Ÿå·²é‡ç½®")
    
    def generate_state_signature(self, page_title: str, action_list: list, html_snippet: str = "") -> str:
        """
        ç”Ÿæˆé¡µé¢çŠ¶æ€çš„å”¯ä¸€ç­¾å
        """
        # åŸºäºé¡µé¢æ ‡é¢˜ã€åŠ¨ä½œæ•°é‡å’Œç±»å‹ç”Ÿæˆç­¾å
        action_types = [type(action).__name__ for action in action_list]
        action_signature = "_".join(sorted(set(action_types)))
        
        # ç®€åŒ–HTMLç‰¹å¾(é¿å…è¿‡äºè¯¦ç»†)
        html_features = ""
        if html_snippet:
            # æå–å…³é”®HTMLæ ‡ç­¾
            import re
            form_count = len(re.findall(r'<form', html_snippet, re.IGNORECASE))
            input_count = len(re.findall(r'<input', html_snippet, re.IGNORECASE))
            button_count = len(re.findall(r'<button', html_snippet, re.IGNORECASE))
            html_features = f"form{form_count}_input{input_count}_btn{button_count}"
        
        signature = f"{page_title}_{len(action_list)}_{action_signature}_{html_features}"
        return signature[:200]  # é™åˆ¶é•¿åº¦
    
    def is_new_state(self, state_signature: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çŠ¶æ€"""
        return state_signature not in self.explored_states
    
    def r1_explore_state(self, page_title: str, action_list: list, page_context: str, 
                        history_str: str, html: str = "") -> Dict[str, Any]:
        """
        ğŸ” R1æ¨¡å‹æ·±åº¦æ¢ç´¢æ–°çŠ¶æ€ - å¤šæ ·æ€§å¢å¼ºç‰ˆï¼šæ™ºèƒ½ç­–ç•¥é€‰æ‹© + RAGçŸ¥è¯†å¢å¼º
        
        è¿”å›æ¢ç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
        - analysis: é¡µé¢åˆ†æ
        - strategy: æµ‹è¯•ç­–ç•¥
        - recommendations: æ¨èåŠ¨ä½œ
        - risk_areas: é£é™©åŒºåŸŸ
        - exploration_strategy: ä½¿ç”¨çš„æ¢ç´¢ç­–ç•¥
        """
        self.exploration_count += 1
        
        # ğŸ¯ æ™ºèƒ½é€‰æ‹©æ¢ç´¢ç­–ç•¥
        exploration_strategy = self.diversity_tracker.select_exploration_strategy()
        
        # ğŸš€ å¤šæ ·æ€§å¢å¼ºçš„RAGçŸ¥è¯†æ£€ç´¢
        if self.verbose:
            print(f"ğŸ” R1æ¢ç´¢ #{self.exploration_count} - ç­–ç•¥: {exploration_strategy}")
            print(f"   å¼€å§‹æ”¶é›†å¤šæ ·åŒ–RAGçŸ¥è¯†...")
        
        # 1. åŸºäºæ¢ç´¢ç­–ç•¥çš„å¤šæ ·åŒ–ä¸“ä¸šçŸ¥è¯†æ£€ç´¢
        professional_knowledge = ""
        if self.retriever:
            try:
                # è·å–ç­–ç•¥ç›¸å…³çš„å¤šæ ·åŒ–æŸ¥è¯¢
                strategy_queries = self.diversity_tracker.get_exploration_enhancement_queries(page_title, exploration_strategy)
                
                # éšæœºé€‰æ‹©2ä¸ªæŸ¥è¯¢ä»¥å¢åŠ å¤šæ ·æ€§
                selected_queries = random.sample(strategy_queries, k=min(2, len(strategy_queries)))
                
                combined_knowledge = []
                for query in selected_queries:
                    knowledge = self.retriever.retrieve(query)
                    if knowledge:
                        combined_knowledge.append(f"=== {query} ===\n{knowledge}")
                
                professional_knowledge = "\n\n".join(combined_knowledge)
                
                if self.verbose and professional_knowledge:
                    print(f"   ğŸ“š è·å–ä¸“ä¸šçŸ¥è¯†: {len(professional_knowledge)} å­—ç¬¦ (ç­–ç•¥: {exploration_strategy})")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ ä¸“ä¸šçŸ¥è¯†æ£€ç´¢å¤±è´¥: {e}")
        
        # 2. æ£€ç´¢ç›¸ä¼¼é¡µé¢çŠ¶æ€åˆ†æç»éªŒï¼ˆå¢åŠ åå‘å­¦ä¹ ï¼‰
        similar_states_context = ""
        if self.state_kb:
            try:
                similar_states_context = self.state_kb.retrieve_similar_states(
                    page_title, len(action_list), k=2
                )
                
                # ğŸ² 20%æ¦‚ç‡æ·»åŠ å¤±è´¥æ¡ˆä¾‹å­¦ä¹ ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if random.random() < 0.2 and self.thinking_kb:
                    failure_query = f"æµ‹è¯•å¤±è´¥ é”™è¯¯æ¡ˆä¾‹ {page_title} é¿å…é‡å¤"
                    failure_experience = self.thinking_kb.retrieve_relevant_thinking(failure_query, k=1)
                    if failure_experience:
                        similar_states_context += f"\n\n=== å¤±è´¥æ¡ˆä¾‹åå‘å­¦ä¹  ===\n{failure_experience}"
                
                if self.verbose and similar_states_context:
                    print(f"   ğŸ“Š è·å–ç›¸ä¼¼çŠ¶æ€: {len(similar_states_context)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ ç›¸ä¼¼çŠ¶æ€æ£€ç´¢å¤±è´¥: {e}")
        
        # 3. æ£€ç´¢å†å²åˆ†æç»éªŒï¼ˆå¤šè§’åº¦æŸ¥è¯¢ï¼‰
        analysis_experience = ""
        if self.thinking_kb:
            try:
                # åŸºäºæ¢ç´¢ç­–ç•¥çš„å¤šæ ·åŒ–æ€ç»´æŸ¥è¯¢
                thinking_queries = {
                    'conservative': f"ç¨³å¥åˆ†æ æˆåŠŸç»éªŒ {page_title} æµ‹è¯•ç­–ç•¥",
                    'innovative': f"åˆ›æ–°æ€è·¯ æ–°é¢–æ–¹æ³• {page_title} æ¢ç´¢å‘ç°",
                    'balanced': f"å…¨é¢åˆ†æ å¹³è¡¡ç­–ç•¥ {page_title} ç»¼åˆè€ƒè™‘", 
                    'risk_focused': f"é£é™©åˆ†æ è¾¹ç•Œæµ‹è¯• {page_title} å®‰å…¨è€ƒé‡"
                }
                
                thinking_query = thinking_queries.get(exploration_strategy, thinking_queries['balanced'])
                analysis_experience = self.thinking_kb.retrieve_relevant_thinking(thinking_query, k=2)
                
                if self.verbose and analysis_experience:
                    print(f"   ğŸ§  è·å–åˆ†æç»éªŒ: {len(analysis_experience)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ åˆ†æç»éªŒæ£€ç´¢å¤±è´¥: {e}")
        
        # ğŸ¨ è·å–å¤šæ ·æ€§åé¦ˆ
        action_history = [item.get('action', '') for item in self.diversity_tracker.exploration_history]
        diversity_feedback = self.diversity_tracker.get_diversity_feedback(action_history)
        
        # ğŸ” RAGå¢å¼ºçŠ¶æ€æŠ¥å‘Š
        if self.verbose:
            rag_sources = []
            if professional_knowledge: rag_sources.append("ç­–ç•¥çŸ¥è¯†âœ“")
            if similar_states_context: rag_sources.append("ç›¸ä¼¼çŠ¶æ€âœ“")
            if analysis_experience: rag_sources.append("åˆ†æç»éªŒâœ“")
            
            if rag_sources:
                print(f"   ğŸš€ RAGå¢å¼ºæ¥æº: {' '.join(rag_sources)}")
            else:
                print(f"   âš ï¸ æœªè·å–åˆ°RAGå¢å¼ºæ•°æ®ï¼Œä½¿ç”¨åŸºç¡€æ¢ç´¢æ¨¡å¼")
        
        # æ„å»ºè¯¦ç»†çš„åŠ¨ä½œåˆ—è¡¨
        action_details = []
        for i, action in enumerate(action_list):
            if isinstance(action, ClickAction):
                details = f"{i}. [ç‚¹å‡»] {getattr(action, 'text', 'Unknown')} (ç±»å‹: {getattr(action, 'action_type', 'unknown')})"
            elif isinstance(action, RandomInputAction):
                details = f"{i}. [è¾“å…¥] {getattr(action, 'text', 'Unknown')} (å­—æ®µç±»å‹: {getattr(action, 'action_type', 'input')})"
            elif isinstance(action, RandomSelectAction):
                details = f"{i}. [é€‰æ‹©] {getattr(action, 'text', 'Unknown')} (é€‰é¡¹: {getattr(action, 'options', 'N/A')})"
            else:
                details = f"{i}. [å…¶ä»–] {getattr(action, 'text', 'Unknown')}"
            action_details.append(details)
        
        # ğŸŒŸ æ„å»ºç­–ç•¥å¯¼å‘çš„æ¢ç´¢ç­–ç•¥æç¤º
        strategy_guidance = {
            'conservative': """
## ğŸ›¡ï¸ ä¿å®ˆæ¢ç´¢ç­–ç•¥æ¿€æ´»
**åˆ†æé‡ç‚¹**ï¼š
- é‡ç‚¹åˆ†ææ ¸å¿ƒåŠŸèƒ½å’Œä¸»è¦ç”¨æˆ·æµç¨‹
- åŸºäºæˆåŠŸç»éªŒè¯†åˆ«å…³é”®æµ‹è¯•ç‚¹
- è¯„ä¼°åŠŸèƒ½ç¨³å®šæ€§å’Œå¯é æ€§
- åˆ¶å®šæ¸è¿›å¼éªŒè¯ç­–ç•¥
""",
            'innovative': """
## ğŸš€ åˆ›æ–°æ¢ç´¢ç­–ç•¥æ¿€æ´»  
**åˆ†æé‡ç‚¹**ï¼š
- å¯»æ‰¾æœªè¢«å……åˆ†æµ‹è¯•çš„åŠŸèƒ½åŒºåŸŸ
- æ¢ç´¢éå¸¸è§„çš„ç”¨æˆ·äº¤äº’è·¯å¾„
- è¯†åˆ«æ½œåœ¨çš„åˆ›æ–°æµ‹è¯•æœºä¼š
- è®¾è®¡çªç ´æ€§çš„æµ‹è¯•æ–¹æ³•
""",
            'balanced': """
## âš–ï¸ å¹³è¡¡æ¢ç´¢ç­–ç•¥æ¿€æ´»
**åˆ†æé‡ç‚¹**ï¼š
- ç»¼åˆè€ƒè™‘ç¨³å®šæ€§å’Œåˆ›æ–°æ€§
- å¹³è¡¡æ·±åº¦éªŒè¯å’Œå¹¿åº¦æ¢ç´¢
- å…¼é¡¾å·²çŸ¥åŠŸèƒ½å’ŒæœªçŸ¥é£é™©
- åˆ¶å®šå…¨é¢çš„æµ‹è¯•ç­–ç•¥
""",
            'risk_focused': """
## âš ï¸ é£é™©å¯¼å‘æ¢ç´¢ç­–ç•¥æ¿€æ´»
**åˆ†æé‡ç‚¹**ï¼š
- ä¸“æ³¨è¯†åˆ«æ½œåœ¨çš„å®‰å…¨é£é™©ç‚¹
- åˆ†æè¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸åœºæ™¯
- è¯„ä¼°é”™è¯¯å¤„ç†å’Œå®¹é”™èƒ½åŠ›
- è®¾è®¡é£é™©æ¢æµ‹æµ‹è¯•æ–¹æ¡ˆ
"""
        }
        
        current_strategy_guidance = strategy_guidance.get(exploration_strategy, strategy_guidance['balanced'])
        
        # ğŸ¯ æ„å»ºå¤šæ ·æ€§å¢å¼ºçš„R1æ¢ç´¢prompt
        exploration_prompt = f"""
{professional_knowledge}

{similar_states_context}

{analysis_experience}

{diversity_feedback}

{current_strategy_guidance}

ğŸ” **R1æ·±åº¦æ¢ç´¢ä»»åŠ¡** - æ¢ç´¢ç¼–å· #{self.exploration_count} | ç­–ç•¥: {exploration_strategy.upper()}

ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Webæµ‹è¯•ä¸“å®¶ï¼Œæ­£åœ¨ä½¿ç”¨ **{exploration_strategy}** æ¢ç´¢ç­–ç•¥å¯¹å½“å‰é¡µé¢è¿›è¡Œæ·±åº¦åˆ†æã€‚
è¯·å……åˆ†åˆ©ç”¨ä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ã€ç›¸ä¼¼é¡µé¢ç»éªŒã€å†å²åˆ†æç»éªŒå’Œå¤šæ ·æ€§åé¦ˆæ¥æŒ‡å¯¼ä½ çš„åˆ†æã€‚

## é¡µé¢ä¿¡æ¯
{page_context}
{history_str}

## å¯ç”¨äº¤äº’å…ƒç´  ({len(action_list)}ä¸ª)
{chr(10).join(action_details)}

## ğŸ“‹ ç­–ç•¥å¯¼å‘çš„æ·±åº¦æ¢ç´¢ä»»åŠ¡
åŸºäº **{exploration_strategy}** ç­–ç•¥ï¼Œè¯·è¿›è¡Œä»¥ä¸‹åˆ†æï¼š

### 1. **ç­–ç•¥åŒ–é¡µé¢åŠŸèƒ½åˆ†æ**
- æ ¹æ®{exploration_strategy}ç­–ç•¥ï¼Œæ·±åº¦åˆ†æé¡µé¢çš„æ ¸å¿ƒåŠŸèƒ½å’ŒæŠ€æœ¯ç‰¹ç‚¹
- è¯†åˆ«ä¸å½“å‰ç­–ç•¥æœ€åŒ¹é…çš„åŠŸèƒ½åŒºåŸŸå’Œæµ‹è¯•æœºä¼š
- è¯„ä¼°é¡µé¢å¤æ‚åº¦å’Œæµ‹è¯•ä¼˜å…ˆçº§ï¼ˆç­–ç•¥å¯¼å‘ï¼‰

### 2. **å¤šæ ·æ€§æµ‹è¯•ç­–ç•¥åˆ¶å®š**  
- åŸºäºå½“å‰å¤šæ ·æ€§çŠ¶æ€ï¼Œåˆ¶å®šé’ˆå¯¹æ€§æµ‹è¯•ç­–ç•¥
- å‚è€ƒå†å²ç»éªŒå’Œä¸“ä¸šçŸ¥è¯†ï¼Œç¡®å®šå…³é”®éªŒè¯ç‚¹
- è®¾è®¡å¤šå±‚æ¬¡æµ‹è¯•è·¯å¾„ï¼š
  * **{exploration_strategy}å¯¼å‘è·¯å¾„**ï¼šç¬¦åˆå½“å‰ç­–ç•¥çš„ä¸»è¦æµ‹è¯•æ–¹å‘
  * **å¤šæ ·æ€§è¡¥å……è·¯å¾„**ï¼šå¢å¼ºæµ‹è¯•è¦†ç›–é¢çš„è¾…åŠ©æ–¹å‘
  * **åˆ›æ–°æ¢ç´¢è·¯å¾„**ï¼šå°è¯•æ–°çš„æµ‹è¯•è§’åº¦å’Œæ–¹æ³•

### 3. **æ™ºèƒ½é£é™©è¯†åˆ«ä¸æœºä¼šå‘ç°**
- åˆ©ç”¨ä¸“ä¸šçŸ¥è¯†å’Œ{exploration_strategy}ç­–ç•¥è¯†åˆ«é£é™©ç‚¹
- åŸºäºç›¸ä¼¼é¡µé¢ç»éªŒé¢„æµ‹é—®é¢˜åŒºåŸŸ
- å‘ç°æ½œåœ¨çš„æµ‹è¯•æœºä¼šå’Œæœªè¦†ç›–åŒºåŸŸ

### 4. **ç­–ç•¥åŒ–åŠ¨ä½œä¼˜å…ˆçº§å»ºè®®**
è¯·ä»ç°æœ‰{len(action_list)}ä¸ªåŠ¨ä½œä¸­ï¼ŒåŸºäº{exploration_strategy}ç­–ç•¥ç¡®å®šä¼˜å…ˆçº§ï¼š
- **ç­–ç•¥ä¼˜å…ˆåŠ¨ä½œ** (ç´¢å¼•å’Œ{exploration_strategy}ç†ç”±)
- **å¤šæ ·æ€§å¢å¼ºåŠ¨ä½œ** (ç´¢å¼•å’Œå¤šæ ·æ€§åˆ†æ)
- **é£é™©æ¢æµ‹åŠ¨ä½œ** (ç´¢å¼•å’Œé£é™©è¯„ä¼°)
- **åˆ›æ–°æ¢ç´¢åŠ¨ä½œ** (ç´¢å¼•å’Œåˆ›æ–°ä»·å€¼)

### 5. **å¤šæ ·åŒ–æµ‹è¯•æ•°æ®å»ºè®®**
åŸºäº{exploration_strategy}ç­–ç•¥å’Œwebæµ‹è¯•ç»éªŒï¼Œä¸ºè¾“å…¥å­—æ®µå»ºè®®ï¼š
- **ç­–ç•¥å¯¼å‘æ•°æ®** (ç¬¦åˆ{exploration_strategy}çš„æµ‹è¯•æ•°æ®)
- **å¤šæ ·æ€§æµ‹è¯•æ•°æ®** (å¢åŠ æµ‹è¯•è¦†ç›–é¢çš„æ•°æ®)
- **è¾¹ç•Œæ¢ç´¢æ•°æ®** (è¾¹ç•Œå€¼å’Œå¼‚å¸¸æƒ…å†µ)
- **å®‰å…¨æµ‹è¯•æ•°æ®** (å®‰å…¨æ¼æ´æ£€æµ‹æ•°æ®)

### 6. **ç­–ç•¥åŒ–æ¢ç´¢æ€»ç»“ä¸è¿›åŒ–å»ºè®®**
åŸºäº{exploration_strategy}ç­–ç•¥å’Œå½“å‰åˆ†æï¼Œæ€»ç»“ï¼š
- æœ¬é¡µé¢åœ¨{exploration_strategy}ç­–ç•¥ä¸‹çš„æµ‹è¯•é‡ç‚¹å’Œéš¾ç‚¹
- ä¸å†å²ç›¸ä¼¼é¡µé¢çš„å·®å¼‚å’Œç‰¹æ®Šæ³¨æ„äº‹é¡¹
- ç­–ç•¥æ‰§è¡Œæ•ˆæœè¯„ä¼°å’Œè°ƒæ•´å»ºè®®
- åç»­æ¢ç´¢æ–¹å‘å’Œç­–ç•¥è¿›åŒ–å»ºè®®

**é‡è¦æé†’**ï¼šè¯·å……åˆ†ä½“ç°{exploration_strategy}ç­–ç•¥çš„ç‰¹è‰²ï¼ŒåŒæ—¶è€ƒè™‘å¤šæ ·æ€§å¢å¼ºå’Œæµ‹è¯•è¦†ç›–çš„å…¨é¢æ€§ã€‚
æä¾›ç»“æ„åŒ–ä¸”å…·æœ‰ç­–ç•¥é’ˆå¯¹æ€§çš„ä¸“ä¸šåˆ†æç»“æœï¼Œè¿™å°†æŒ‡å¯¼åç»­çš„ç²¾ç¡®æµ‹è¯•æ‰§è¡Œã€‚
"""
        
        if self.verbose:
            print(f"ğŸ” R1å¼€å§‹{exploration_strategy}ç­–ç•¥æ¢ç´¢ #{self.exploration_count}: {page_title[:30]}...")
        
        try:
            exploration_result = self.r1_explorer.chat_with_thinking(exploration_prompt)
            
            # è§£ææ¢ç´¢ç»“æœ
            analysis_content = exploration_result["content"]
            reasoning_process = exploration_result["reasoning"]
            
            exploration_data = {
                "exploration_id": self.exploration_count,
                "page_title": page_title,
                "timestamp": datetime.now().isoformat(),
                "analysis": analysis_content,
                "reasoning": reasoning_process,
                "action_count": len(action_list),
                "exploration_strategy": exploration_strategy,  # æ–°å¢ï¼šè®°å½•ä½¿ç”¨çš„ç­–ç•¥
                "diversity_score": self.diversity_tracker.action_diversity_score,  # æ–°å¢ï¼šå¤šæ ·æ€§åˆ†æ•°
                "exploration_prompt": exploration_prompt[:800] + "...",
                "model": "DeepSeek-R1",
                "rag_enhanced": True,
                "strategy_enhanced": True,  # æ–°å¢ï¼šç­–ç•¥å¢å¼ºæ ‡è®°
                "knowledge_sources": {
                    "professional_knowledge": len(professional_knowledge) > 0,
                    "similar_states": len(similar_states_context) > 0,
                    "analysis_experience": len(analysis_experience) > 0,
                    "diversity_feedback": len(diversity_feedback) > 0
                }
            }
            
            if self.verbose:
                print(f"âœ… R1{exploration_strategy}æ¢ç´¢å®Œæˆ #{self.exploration_count}")
                print(f"   ğŸ“ åˆ†æé•¿åº¦: {len(analysis_content)} å­—ç¬¦")
                print(f"   ğŸ§  æ¨ç†é•¿åº¦: {len(reasoning_process)} å­—ç¬¦")
                print(f"   ğŸ¯ ç­–ç•¥: {exploration_strategy}")
                print(f"   ğŸ² å¤šæ ·æ€§åˆ†æ•°: {self.diversity_tracker.action_diversity_score:.2f}")
            
            return exploration_data
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ R1{exploration_strategy}æ¢ç´¢å¤±è´¥ #{self.exploration_count}: {e}")
            
            # è¿”å›åŸºç¡€æ¢ç´¢ç»“æœ
            return {
                "exploration_id": self.exploration_count,
                "page_title": page_title,
                "timestamp": datetime.now().isoformat(),
                "analysis": f"ç­–ç•¥å¢å¼ºæ¢ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                "reasoning": "",
                "action_count": len(action_list),
                "exploration_strategy": exploration_strategy,
                "model": "DeepSeek-R1",
                "rag_enhanced": False,
                "strategy_enhanced": False,
                "error": str(e)
            }
    
    def qwq_decide_action(self, action_list: list, exploration_data: Dict[str, Any], 
                         page_context: str, history_str: str) -> tuple:
        """
        âš¡ QwQæ¨¡å‹åŸºäºR1æ¢ç´¢ç»“æœå¿«é€Ÿå†³ç­– - å¤šæ ·æ€§å¢å¼ºç‰ˆï¼šæ™ºèƒ½å†³ç­–æ¨¡å¼ + RAGç»éªŒå¢å¼º
        
        è¿”å›: (action_output, reasoning)
        """
        # æå–R1çš„å…³é”®å»ºè®®å’Œç­–ç•¥ä¿¡æ¯
        r1_analysis = exploration_data.get("analysis", "")
        r1_reasoning = exploration_data.get("reasoning", "")
        r1_strategy = exploration_data.get("exploration_strategy", "balanced")
        
        # ğŸ¯ æ™ºèƒ½é€‰æ‹©å†³ç­–æ¨¡å¼
        decision_mode = self.diversity_tracker.select_decision_mode()
        
        # ğŸš€ å¤šæ ·æ€§å¢å¼ºçš„RAGçŸ¥è¯†æ£€ç´¢
        if self.verbose:
            print(f"âš¡ QwQå†³ç­– - æ¨¡å¼: {decision_mode} | R1ç­–ç•¥: {r1_strategy}")
            print(f"   å¼€å§‹æ”¶é›†å¤šæ ·åŒ–å†³ç­–çŸ¥è¯†...")
        
        # 1. åŸºäºå†³ç­–æ¨¡å¼çš„å†å²æ¢ç´¢æ´å¯Ÿæ£€ç´¢
        exploration_insights = ""
        if self.exploration_kb:
            try:
                # åŸºäºå†³ç­–æ¨¡å¼çš„å¤šæ ·åŒ–æ´å¯ŸæŸ¥è¯¢
                insights_queries = {
                    'conservative': f"æˆåŠŸå†³ç­–æ¡ˆä¾‹ ç¨³å¥é€‰æ‹© {exploration_data.get('page_title', '')} éªŒè¯",
                    'exploratory': f"åˆ›æ–°å†³ç­– æ¢ç´¢è·¯å¾„ {exploration_data.get('page_title', '')} å‘ç°",
                    'balanced': f"å¹³è¡¡å†³ç­– ç»¼åˆç­–ç•¥ {exploration_data.get('page_title', '')} æ‰§è¡Œ"
                }
                
                insights_query = insights_queries.get(decision_mode, insights_queries['balanced'])
                exploration_insights = self.exploration_kb.retrieve_exploration_insights(insights_query, k=2)
                
                if self.verbose and exploration_insights:
                    print(f"   ğŸ” è·å–æ¢ç´¢æ´å¯Ÿ: {len(exploration_insights)} å­—ç¬¦ (æ¨¡å¼: {decision_mode})")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ æ¢ç´¢æ´å¯Ÿæ£€ç´¢å¤±è´¥: {e}")
        
        
        # 2. æ£€ç´¢ç›¸ä¼¼é¡µé¢çš„å†³ç­–ç»éªŒï¼ˆå¤šæ ·æ€§å¯¼å‘ï¼‰
        similar_decisions = ""
        if self.state_kb:
            try:
                similar_decisions = self.state_kb.retrieve_similar_states(
                    exploration_data.get('page_title', ''), len(action_list), k=2
                )
                
                # ğŸ² åŸºäºå†³ç­–æ¨¡å¼æ·»åŠ ç‰¹å®šç±»å‹çš„ç»éªŒ
                if decision_mode == 'exploratory' and random.random() < 0.3:
                    # æ¢ç´¢æ¨¡å¼ï¼š30%æ¦‚ç‡åŠ å…¥å¤±è´¥ä½†æœ‰ä»·å€¼çš„å°è¯•ç»éªŒ
                    if self.thinking_kb:
                        risk_query = f"å¤±è´¥å°è¯• æœ‰ä»·å€¼å‘ç° {exploration_data.get('page_title', '')} å­¦ä¹ "
                        risk_experience = self.thinking_kb.retrieve_relevant_thinking(risk_query, k=1)
                        if risk_experience:
                            similar_decisions += f"\n\n=== æ¢ç´¢å¤±è´¥ä½†æœ‰ä»·å€¼çš„ç»éªŒ ===\n{risk_experience}"
                
                if self.verbose and similar_decisions:
                    print(f"   ğŸ“Š è·å–å†³ç­–ç»éªŒ: {len(similar_decisions)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ å†³ç­–ç»éªŒæ£€ç´¢å¤±è´¥: {e}")
        
        # 3. æ£€ç´¢å†å²æ‰§è¡Œå†³ç­–æ¨ç†ï¼ˆæ¨¡å¼å¯¼å‘ï¼‰
        decision_experience = ""
        if self.thinking_kb:
            try:
                # åŸºäºå†³ç­–æ¨¡å¼çš„å¤šæ ·åŒ–å†³ç­–æŸ¥è¯¢
                decision_queries = {
                    'conservative': f"ç¨³å¥å†³ç­– æˆåŠŸæ‰§è¡Œ {exploration_data.get('page_title', '')} éªŒè¯",
                    'exploratory': f"æ¢ç´¢å†³ç­– åˆ›æ–°å°è¯• {exploration_data.get('page_title', '')} å‘ç°",
                    'balanced': f"å¹³è¡¡å†³ç­– ç»¼åˆè€ƒè™‘ {exploration_data.get('page_title', '')} æ‰§è¡Œ"
                }
                
                decision_query = decision_queries.get(decision_mode, decision_queries['balanced'])
                decision_experience = self.thinking_kb.retrieve_relevant_thinking(decision_query, k=2)
                
                if self.verbose and decision_experience:
                    print(f"   ğŸ§  è·å–å†³ç­–æ¨ç†: {len(decision_experience)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ å†³ç­–æ¨ç†æ£€ç´¢å¤±è´¥: {e}")
        
        # ğŸ¨ è·å–å†³ç­–å¢å¼ºä¸Šä¸‹æ–‡
        decision_enhancement = self.diversity_tracker.get_decision_enhancement_context(decision_mode)
        
        # ğŸ“Š è®¡ç®—åŠ¨ä½œå†å²å¤šæ ·æ€§
        action_history = [item.get('action', '') for item in self.diversity_tracker.exploration_history]
        diversity_feedback = self.diversity_tracker.get_diversity_feedback(action_history)
        
        # ğŸ” RAGå¢å¼ºçŠ¶æ€æŠ¥å‘Š
        if self.verbose:
            rag_sources = []
            if exploration_insights: rag_sources.append("æ¢ç´¢æ´å¯Ÿâœ“")
            if similar_decisions: rag_sources.append("å†³ç­–ç»éªŒâœ“")
            if decision_experience: rag_sources.append("æ¨ç†ç»éªŒâœ“")
            
            if rag_sources:
                print(f"   ğŸš€ RAGå¢å¼ºæ¥æº: {' '.join(rag_sources)}")
            else:
                print(f"   âš ï¸ æœªè·å–åˆ°RAGå¢å¼ºæ•°æ®ï¼Œä½¿ç”¨åŸºç¡€å†³ç­–æ¨¡å¼")
        
        # æ„å»ºåŠ¨ä½œåˆ—è¡¨ï¼ˆå¢åŠ å¤šæ ·æ€§åˆ†æï¼‰
        action_analysis = []
        action_types_count = {}
        
        for i, action in enumerate(action_list):
            action_simple = self.format_action_simple(action)
            action_type = action_simple.split()[0] if action_simple else "Unknown"
            action_types_count[action_type] = action_types_count.get(action_type, 0) + 1
            
            # è®¡ç®—è¯¥åŠ¨ä½œç±»å‹åœ¨å†å²ä¸­çš„ä½¿ç”¨é¢‘ç‡
            historical_usage = sum(1 for hist_action in action_history if hist_action.startswith(action_type))
            usage_indicator = "ğŸ”¥" if historical_usage > 3 else "ğŸ†•" if historical_usage == 0 else "ğŸ“Š"
            
            action_analysis.append(f"{i}. {action_simple} {usage_indicator}")
        
        action_list_str = "\n".join(action_analysis)
        
        # ğŸŒŸ æ„å»ºå†³ç­–æ¨¡å¼å¯¼å‘çš„å¤šæ ·æ€§åˆ†æ
        diversity_analysis = f"""
## ğŸ² å½“å‰å¤šæ ·æ€§çŠ¶æ€åˆ†æ
- **å¤šæ ·æ€§åˆ†æ•°**: {self.diversity_tracker.action_diversity_score:.2f}/1.0
- **å¯ç”¨åŠ¨ä½œç±»å‹**: {dict(action_types_count)}
- **å†å²ä½¿ç”¨é¢‘ç‡**: ğŸ”¥é¢‘ç¹ ğŸ“Šé€‚ä¸­ ğŸ†•æœªä½¿ç”¨
- **å†³ç­–æ¨¡å¼**: {decision_mode.upper()}
- **R1æ¢ç´¢ç­–ç•¥**: {r1_strategy.upper()}

{diversity_feedback}
"""
        
        # ğŸ¯ æ„å»ºå¤šæ ·æ€§å¢å¼ºçš„QwQå†³ç­–prompt
        decision_prompt = f"""
{exploration_insights}

{similar_decisions}

{decision_experience}

{decision_enhancement}

{diversity_analysis}

âš¡ **QwQæ™ºèƒ½å†³ç­–ä»»åŠ¡** - å†³ç­–æ¨¡å¼: {decision_mode.upper()}

åŸºäºR1æ¨¡å‹çš„{r1_strategy}ç­–ç•¥æ¢ç´¢åˆ†æå’Œå†å²å†³ç­–ç»éªŒï¼Œä½¿ç”¨{decision_mode}å†³ç­–æ¨¡å¼åšå‡ºæœ€ä¼˜é€‰æ‹©ã€‚
è¯·å……åˆ†åˆ©ç”¨ä¸Šè¿°æ¢ç´¢æ´å¯Ÿã€ç›¸ä¼¼å†³ç­–ç»éªŒã€å†å²æ¨ç†å’Œå¤šæ ·æ€§åˆ†ææ¥æŒ‡å¯¼ä½ çš„å†³ç­–ã€‚

## å½“å‰çŠ¶æ€
{page_context}
{history_str}

## R1æ·±åº¦æ¢ç´¢åˆ†æï¼ˆç­–ç•¥: {r1_strategy}ï¼‰
{r1_analysis[:1000]}...

## å¯é€‰åŠ¨ä½œåˆ†æ ({len(action_list)}ä¸ª)
{action_list_str}

## ğŸ¯ {decision_mode.upper()}æ¨¡å¼æ™ºèƒ½å†³ç­–
åŸºäº{decision_mode}å†³ç­–æ¨¡å¼ã€R1çš„{r1_strategy}ç­–ç•¥åˆ†æå’Œå¤šæ ·æ€§çŠ¶æ€ï¼Œé€‰æ‹©å½“å‰æœ€åˆé€‚çš„åŠ¨ä½œï¼š

### å†³ç­–ä¼˜å…ˆçº§æ¡†æ¶
1. **æ¨¡å¼å¯¼å‘ä¼˜å…ˆçº§** - ç¬¦åˆ{decision_mode}æ¨¡å¼çš„å†³ç­–åŸåˆ™
2. **R1ç­–ç•¥å¥‘åˆåº¦** - ä¸R1çš„{r1_strategy}ç­–ç•¥åˆ†æçš„ä¸€è‡´æ€§
3. **å¤šæ ·æ€§å¢å¼ºä»·å€¼** - å¯¹æå‡æµ‹è¯•å¤šæ ·æ€§çš„è´¡çŒ®
4. **å†å²ç»éªŒæŒ‡å¯¼** - ç›¸ä¼¼åœºæ™¯ä¸‹çš„æˆåŠŸç»éªŒå‚è€ƒ
5. **é£é™©æ”¶ç›Šå¹³è¡¡** - æµ‹è¯•ä»·å€¼ä¸æ‰§è¡Œé£é™©çš„æƒè¡¡

### å¤šæ ·æ€§å†³ç­–è€ƒè™‘å› ç´ 
- **åŠ¨ä½œç±»å‹å¤šæ ·æ€§**: é€‰æ‹©å†å²ä½¿ç”¨è¾ƒå°‘çš„åŠ¨ä½œç±»å‹ (ğŸ†• > ğŸ“Š > ğŸ”¥)
- **æ¢ç´¢è·¯å¾„åˆ›æ–°**: å°è¯•ä¸å†å²è·¯å¾„ä¸åŒçš„æµ‹è¯•æ–¹å‘
- **åŠŸèƒ½è¦†ç›–å‡è¡¡**: å¹³è¡¡ä¸åŒåŠŸèƒ½åŒºåŸŸçš„æµ‹è¯•è¦†ç›–
- **ç­–ç•¥æ¨¡å¼åè°ƒ**: {decision_mode}æ¨¡å¼ä¸{r1_strategy}ç­–ç•¥çš„æœ€ä½³ç»“åˆ

### {decision_mode.upper()}æ¨¡å¼ç‰¹å®šæŒ‡å¯¼
æ ¹æ®{decision_mode}å†³ç­–æ¨¡å¼ï¼š
- **Conservativeæ¨¡å¼**: ä¼˜å…ˆé€‰æ‹©å†å²æˆåŠŸç‡é«˜ã€é£é™©å¯æ§çš„åŠ¨ä½œ
- **Exploratoryæ¨¡å¼**: å‹‡äºå°è¯•æ–°è·¯å¾„ã€æœªä½¿ç”¨çš„åŠ¨ä½œç±»å‹
- **Balancedæ¨¡å¼**: åœ¨ç¨³å¥éªŒè¯å’Œåˆ›æ–°æ¢ç´¢ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹

### è¾“å‡ºè¦æ±‚
**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º**ï¼š
- ç‚¹å‡»åŠ¨ä½œï¼šç›´æ¥è¿”å›æ•°å­—ï¼Œå¦‚ "3"
- è¾“å…¥åŠ¨ä½œï¼šè¿”å›"æ•°å­—:æ–‡æœ¬"ï¼Œå¦‚ "5:test@example.com"

### å†³ç­–è¯´æ˜ï¼ˆç®€çŸ­ï¼‰
åœ¨ä¸€è¡Œå†…ç®€è¦è¯´æ˜é€‰æ‹©ç†ç”±ï¼Œæ ¼å¼ï¼š
"{decision_mode}æ¨¡å¼-{action_type}-ç†ç”±"

**å†³ç­–åŸåˆ™**ï¼š
- åŸºäº{decision_mode}æ¨¡å¼çš„ç‰¹å®šä¼˜åŠ¿å’ŒR1çš„{r1_strategy}ç­–ç•¥æ´å¯Ÿ
- ä¼˜åŒ–æµ‹è¯•å¤šæ ·æ€§å’Œè¦†ç›–é¢
- ç¡®ä¿å†³ç­–çš„åˆ›æ–°æ€§å’Œæ‰§è¡Œæ•ˆæœ

è¯·åŸºäºä¸Šè¿°å…¨é¢åˆ†æå¿«é€Ÿåšå‡ºç²¾å‡†å†³ç­–ï¼Œåªè¿”å›åŠ¨ä½œç´¢å¼•æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ã€‚
"""
        
        if self.verbose:
            print(f"âš¡ QwQå¼€å§‹{decision_mode}æ¨¡å¼æ™ºèƒ½å†³ç­–...")
        
        try:
            decision_result = self.qwq_decider.chat_with_thinking(decision_prompt)
            qwq_output = decision_result["content"]
            qwq_reasoning = decision_result["reasoning"]
            
            # ğŸ² æ›´æ–°å¤šæ ·æ€§è¿½è¸ª
            action_taken = f"{decision_mode}å†³ç­–æ¨¡å¼é€‰æ‹©"
            self.diversity_tracker.update_diversity_metrics(
                action_taken, r1_strategy, decision_mode
            )
            
            if self.verbose:
                print(f"âš¡ QwQ{decision_mode}å†³ç­–è¾“å‡º: {qwq_output}")
                print(f"ğŸ§  QwQæ¨ç†: {qwq_reasoning[:100]}...")
                print(f"ğŸ¯ æ¨¡å¼: {decision_mode} | R1ç­–ç•¥: {r1_strategy}")
                print(f"ğŸ² å¤šæ ·æ€§åˆ†æ•°: {self.diversity_tracker.action_diversity_score:.2f}")
            
            return qwq_output, qwq_reasoning
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ QwQ{decision_mode}å†³ç­–å¤±è´¥: {e}")
            return None, f"å¤šæ ·æ€§å¢å¼ºå†³ç­–é”™è¯¯: {str(e)}"
    
    def format_action_simple(self, action) -> str:
        """ç®€åŒ–çš„åŠ¨ä½œæ ¼å¼åŒ–"""
        if isinstance(action, ClickAction):
            return f"ç‚¹å‡» '{getattr(action, 'text', 'Unknown')}'"
        elif isinstance(action, RandomInputAction):
            return f"è¾“å…¥ '{getattr(action, 'text', 'Unknown')}'"
        elif isinstance(action, RandomSelectAction):
            return f"é€‰æ‹© '{getattr(action, 'text', 'Unknown')}'"
        else:
            return f"æ“ä½œ '{getattr(action, 'text', 'Unknown')}'"
    
    def get_dual_model_stats(self) -> dict:
        """è·å–åŒæ¨¡å‹ç³»ç»Ÿç»Ÿè®¡ï¼ˆåŒ…å«å¤šæ ·æ€§ä¿¡æ¯ï¼‰"""
        diversity_stats = self.diversity_tracker.get_diversity_stats()
        
        return {
            "total_explorations": self.exploration_count,
            "cached_states": len(self.explored_states),
            "cache_size": len(self.state_exploration_cache),
            "r1_session_id": self.r1_explorer.session_id[:8],
            "qwq_session_id": self.qwq_decider.session_id[:8],
            # ğŸ² å¤šæ ·æ€§ç»Ÿè®¡
            "diversity_metrics": diversity_stats,
            "current_diversity_score": diversity_stats.get('action_diversity_score', 0.0),
            "exploration_strategies_usage": diversity_stats.get('exploration_strategies_usage', {}),
            "decision_modes_usage": diversity_stats.get('decision_modes_usage', {})
        }


class ExplorationKnowledgeBase:
    """
    ğŸ” ä¸“é—¨å­˜å‚¨R1æ¢ç´¢ç»“æœçš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("exploration_collection_name", "exploration_knowledge")
        self.chunk_size = params.get("exploration_chunk_size", 1000)  # æ¢ç´¢ç»“æœè¾ƒå¤§
        self.chunk_overlap = params.get("exploration_chunk_overlap", 150)
        self.max_entries = params.get("max_exploration_entries", 200)
        self.persist_directory = params.get("exploration_persist_directory", "./exploration_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        if params.get("clear_exploration_on_init", True):
            self.clear_exploration_vectorstore()
    
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded exploration KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new exploration KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize exploration KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )
    
    def clear_exploration_vectorstore(self):
        """æ¸…ç©ºæ¢ç´¢çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing exploration KB...")
        
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="Exploration KB", verbose=self.verbose)
        self.vectorstore = None
        
        import gc
        gc.collect()
        
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Exploration KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear exploration KB: {e}")
        
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create exploration directory: {e}")
    
    def add_exploration_result(self, exploration_data: Dict[str, Any]):
        """æ·»åŠ R1æ¢ç´¢ç»“æœåˆ°çŸ¥è¯†åº“"""
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
            
            # æ„å»ºæ¢ç´¢æ–‡æ¡£å†…å®¹
            content = f"""
æ¢ç´¢ID: {exploration_data.get('exploration_id', 'Unknown')}
æ—¶é—´: {exploration_data.get('timestamp', 'Unknown')}
é¡µé¢: {exploration_data.get('page_title', 'Unknown')}
åŠ¨ä½œæ•°é‡: {exploration_data.get('action_count', 0)}
ä½¿ç”¨æ¨¡å‹: {exploration_data.get('model', 'Unknown')}

=== R1æ·±åº¦åˆ†æ ===
{exploration_data.get('analysis', '')}

=== R1æ¨ç†è¿‡ç¨‹ ===
{exploration_data.get('reasoning', '')}

=== æ¢ç´¢æ‘˜è¦ ===
è¿™æ˜¯ä¸€æ¬¡é’ˆå¯¹"{exploration_data.get('page_title', 'Unknown')}"é¡µé¢çš„æ·±åº¦æ¢ç´¢ï¼Œ
å‘ç°äº†{exploration_data.get('action_count', 0)}ä¸ªå¯äº¤äº’å…ƒç´ ï¼Œ
ç”±DeepSeek-R1æ¨¡å‹è¿›è¡Œä¸“ä¸šåˆ†æå’Œæµ‹è¯•ç­–ç•¥åˆ¶å®šã€‚
"""
            
            doc = Document(
                page_content=content,
                metadata={
                    "exploration_id": exploration_data.get('exploration_id'),
                    "timestamp": exploration_data.get('timestamp'),
                    "page_title": exploration_data.get('page_title', '')[:100],
                    "action_count": exploration_data.get('action_count', 0),
                    "model": exploration_data.get('model', ''),
                    "type": "r1_exploration_result"
                }
            )
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"ğŸ’¾ ä¿å­˜R1æ¢ç´¢ç»“æœ #{exploration_data.get('exploration_id')} ({len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Exploration KB", verbose=self.verbose)
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save exploration result: {e}")
    
    def retrieve_exploration_insights(self, query: str, k: int = 2) -> str:
        """æ£€ç´¢R1æ¢ç´¢æ´å¯Ÿ"""
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            insights = []
            for doc in results:
                insights.append(doc.page_content)
            
            exploration_context = "\n--- R1æ¢ç´¢æ´å¯Ÿ ---\n" + "\n\n".join(insights)
            return exploration_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve exploration insights: {e}")
            return ""


class rag_llm_agent(Agent):
    def __init__(self, params):
        self.params = params
        self.verbose = params.get("verbose", False)
        
        # ğŸš€ å…ˆåˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“ç³»ç»Ÿ
        self.retriever = RetrieverInterface(params, verbose=self.verbose)
        self.thinking_kb = ThinkingKnowledgeBase(params, verbose=self.verbose)
        self.state_kb = StateKnowledgeBase(params, verbose=self.verbose)
        self.exploration_kb = ExplorationKnowledgeBase(params, verbose=self.verbose)
        
        # ğŸ§  å°†æ‰€æœ‰çŸ¥è¯†åº“æ‰“åŒ…ä¼ é€’ç»™åŒæ¨¡å‹ç³»ç»Ÿ
        knowledge_bases = {
            'retriever': self.retriever,
            'state_kb': self.state_kb,
            'thinking_kb': self.thinking_kb,
            'exploration_kb': self.exploration_kb
        }
        
        # ğŸš€ åˆå§‹åŒ–åŒæ¨¡å‹åä½œç³»ç»Ÿ - ä¼ é€’çŸ¥è¯†åº“å®ä¾‹
        self.dual_model_system = DualModelSystem(params, knowledge_bases=knowledge_bases, verbose=self.verbose)
        
        self.app_name = params.get("app_name", "Web Testing")
        self.history = []
        self.max_history_length = params.get("max_history_length", 5)

        self.login_state = "none"  # none, detected, username_filled, password_filled, completed
        self.login_credentials = {
            "username": "Nefelibata-Zhu",
            "password": "han19780518"
        }
        self.login_attempts = 0
        self.max_login_attempts = 3

        self.explored_pages = set()
        self.executed_actions = {}
        self.page_action_history = {}
        self.bug_indicators = []

        if params.get("reset_dual_model_on_init", True):
            if self.verbose:
                print("Resetting dual model system on init...")
            self.reset_dual_model_session()

        if params.get("clear_rag_on_init", True):
            if self.verbose:
                print("Clearing all RAG databases on init...")
            self.clear_all_rag_databases()

        if self.verbose:
            print(f"ğŸš€ åŒæ¨¡å‹RAG Agent initialized for {self.app_name}")
            stats = self.dual_model_system.get_dual_model_stats()
            print(f"   ğŸ“¡ R1ä¼šè¯: {stats['r1_session_id']}")
            print(f"   âš¡ QwQä¼šè¯: {stats['qwq_session_id']}")
            print("ğŸ§  R1æ¢ç´¢ + QwQå†³ç­– åä½œç³»ç»Ÿå·²å¯ç”¨")
            print("ğŸš€ å››å±‚RAGçŸ¥è¯†åº“ç³»ç»Ÿå·²å¯ç”¨:")
            print("   ğŸ“– RetrieverKB: ä¸“ä¸šæµ‹è¯•çŸ¥è¯†æ–‡æ¡£")
            print("   ğŸ§  ThinkingKB: æ¨¡å‹æ¨ç†è¿‡ç¨‹è®°å½•")
            print("   ğŸ“Š StateKB: é¡µé¢çŠ¶æ€å’Œäº¤äº’å†å²")
            print("   ğŸ” ExplorationKB: R1æ¢ç´¢ç»“æœä¸“ç”¨å­˜å‚¨")

    def reset_login_state(self):
        self.login_state = "none"
        self.login_attempts = 0
        if self.verbose:
            print("ç™»å½•çŠ¶æ€å·²é‡ç½®")

    def set_login_credentials(self, username: str, password: str):
        """
        è®¾ç½®ç™»å½•å‡­è¯
        
        Args:
            username: ç”¨æˆ·åæˆ–é‚®ç®±
            password: å¯†ç 
        """
        self.login_credentials["username"] = username
        self.login_credentials["password"] = password
        if self.verbose:
            print(f"ğŸ” ç™»å½•å‡­è¯å·²æ›´æ–° - ç”¨æˆ·å: {username}")

    def handle_smart_login(self, action_list, page_title: str = "") -> WebAction:
        """
        ğŸ” æ™ºèƒ½ç™»å½•çŠ¶æ€æœº - è‡ªåŠ¨å®Œæˆç™»å½•æµç¨‹
        """
        if self.verbose:
            print(f"ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - å½“å‰çŠ¶æ€: {self.login_state}")

        # åˆ†æå¯ç”¨åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append((i, action))
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append((i, action))
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append((i, action))

        # çŠ¶æ€æœºé€»è¾‘
        if self.login_state == "none" or self.login_state == "detected":
            # ç¬¬ä¸€æ­¥ï¼šå¡«å†™ç”¨æˆ·å
            if username_actions:
                self.login_state = "username_filling"
                action_index, selected_action = username_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["username"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥ç”¨æˆ·å: {self.login_credentials['username']}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤1: å¡«å…¥ç”¨æˆ·å - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Username input")
                
                self.login_state = "username_filled"
                return selected_action

        elif self.login_state == "username_filled":
            # ç¬¬äºŒæ­¥ï¼šå¡«å†™å¯†ç 
            if password_actions:
                self.login_state = "password_filling"
                action_index, selected_action = password_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["password"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥å¯†ç : {'*' * len(self.login_credentials['password'])}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤2: å¡«å…¥å¯†ç  - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Password input")
                
                self.login_state = "password_filled"
                return selected_action

        elif self.login_state == "password_filled":
            # ç¬¬ä¸‰æ­¥ï¼šç‚¹å‡»ç™»å½•æŒ‰é’®
            if login_button_actions:
                action_index, selected_action = login_button_actions[0]
                
                action_description = "ğŸ” è‡ªåŠ¨ç‚¹å‡»ç™»å½•æŒ‰é’®"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤3: ç‚¹å‡»ç™»å½•æŒ‰é’® - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Click login button")
                
                self.login_state = "completed"
                return selected_action

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„åŠ¨ä½œï¼Œå¢åŠ å°è¯•æ¬¡æ•°
        self.login_attempts += 1
        if self.login_attempts >= self.max_login_attempts:
            if self.verbose:
                print(f"ğŸ” ç™»å½•å°è¯•å¤±è´¥ {self.max_login_attempts} æ¬¡ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼")
            self.login_state = "completed"  # å¼ºåˆ¶å®Œæˆï¼Œä½¿ç”¨æ™®é€šé€»è¾‘
            return None
        
        # è¿”å› None è¡¨ç¤ºç»§ç»­å°è¯•
        return None

    def clear_rag_database(self):
        """
        æ¸…ç©ºä¸‰ä¸ªRAGæ•°æ®åº“
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_llm_session(self):
        """
        é‡ç½®LLMä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.dual_model_system.r1_explorer.reset_session()
            self.dual_model_system.qwq_decider.reset_session()
            if self.verbose:
                print("LLM session reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset LLM session: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - ç¡®ä¿å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
        """
        if self.verbose:
            print("Resetting agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€
        self.reset_dual_model_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬çŠ¶æ€çŸ¥è¯†åº“ï¼‰
        self.clear_rag_database()
        
        if self.verbose:
            print(f"Agent reset complete - New session: {self.dual_model_system.r1_explorer.session_id[:8]}")

    def format_action_info(self, action):
        """æ ¼å¼åŒ–åŠ¨ä½œä¿¡æ¯"""
        if isinstance(action, ClickAction):
            operation_name = "Click"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'unknown')
            addition_info = getattr(action, 'addition_info', '')
            details = f"Widget text: '{action.text}', type: {action_type}, info: {addition_info}"
        elif isinstance(action, RandomInputAction):
            operation_name = "Input"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'input')
            details = f"Input field: '{action.text}', type: {action_type}"
        elif isinstance(action, RandomSelectAction):
            operation_name = "Select"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'select')
            options = getattr(action, 'options', 'N/A')
            details = f"Select field: '{action.text}', type: {action_type}, options: {options}"
        else:
            operation_name = "UnknownOperation"
            # å®‰å…¨åœ°è·å–textå±æ€§
            text = getattr(action, 'text', 'Unknown')
            details = f"Widget: '{text}'"

        return f"'{operation_name}' on {details}"

    def detect_login_page(self, action_list, html: str = "", page_title: str = "") -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        """
        # æ£€æŸ¥é¡µé¢æ ‡é¢˜
        login_title_keywords = [
            "sign in", "login", "log in", "ç™»å½•", "ç™»å…¥"
        ]
        
        if page_title:
            title_lower = page_title.lower()
            for keyword in login_title_keywords:
                if keyword in title_lower:
                    return True
        
        # æ£€æŸ¥HTMLå†…å®¹
        if html:
            html_lower = html.lower()
            if "sign in to github" in html_lower or "github login" in html_lower:
                return True
        
        # æ£€æŸ¥åŠ¨ä½œåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ç™»å½•ç›¸å…³çš„è¾“å…¥å­—æ®µ
        login_field_keywords = [
            "username", "email", "password", "login", "sign in"
        ]
        
        input_fields = [action for action in action_list if isinstance(action, RandomInputAction)]
        login_field_count = 0
        
        for action in input_fields:
            field_text = action.text.lower()
            for keyword in login_field_keywords:
                if keyword in field_text:
                    login_field_count += 1
                    break
        
        # å¦‚æœæœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„ç™»å½•ç›¸å…³å­—æ®µï¼Œè®¤ä¸ºæ˜¯ç™»å½•é¡µé¢
        return login_field_count >= 2

    def get_action_signature(self, action) -> str:
        """
        ç”ŸæˆåŠ¨ä½œçš„å”¯ä¸€ç­¾åï¼Œç”¨äºå»é‡
        """
        if hasattr(action, 'text') and hasattr(action, 'location'):
            return f"{type(action).__name__}_{action.text}_{action.location}"
        elif hasattr(action, 'text'):
            return f"{type(action).__name__}_{action.text}"
        else:
            return f"{type(action).__name__}_{str(action)}"

    def update_exploration_history(self, current_url: str, selected_action, action_index: int):
        """
        æ›´æ–°æ¢ç´¢å†å²è®°å½•
        """
        # è®°å½•è®¿é—®çš„é¡µé¢
        self.explored_pages.add(current_url)
        
        # è®°å½•æ‰§è¡Œçš„åŠ¨ä½œ
        if current_url not in self.executed_actions:
            self.executed_actions[current_url] = {}
        
        action_signature = self.get_action_signature(selected_action)
        if action_signature not in self.executed_actions[current_url]:
            self.executed_actions[current_url][action_signature] = 0
        self.executed_actions[current_url][action_signature] += 1
        
        # è®°å½•é¡µé¢åŠ¨ä½œå†å²
        if current_url not in self.page_action_history:
            self.page_action_history[current_url] = []
        
        self.page_action_history[current_url].append({
            "action_text": getattr(selected_action, 'text', 'Unknown'),
            "action_type": type(selected_action).__name__,
            "action_index": action_index,
            "timestamp": datetime.now().isoformat(),
            "execution_count": self.executed_actions[current_url][action_signature]
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.page_action_history[current_url]) > 20:
            self.page_action_history[current_url] = self.page_action_history[current_url][-20:]

    def generate_login_focused_prompt(self, action_list, page_context: str, history_str: str, page_title: str = "") -> str:
        """
        ç”Ÿæˆä¸“æ³¨äºç™»å½•çš„æç¤ºè¯
        """
        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)
        
        # è¯†åˆ«ç™»å½•ç›¸å…³çš„åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append(i)
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append(i)
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append(i)
        
        login_suggestions = ""
        if username_actions:
            login_suggestions += f"\nç”¨æˆ·åè¾“å…¥å­—æ®µç´¢å¼•: {username_actions} (è¾“å…¥: Nefelibata-Zhu)"
        if password_actions:
            login_suggestions += f"\nå¯†ç è¾“å…¥å­—æ®µç´¢å¼•: {password_actions} (è¾“å…¥: han19780518)"
        if login_button_actions:
            login_suggestions += f"\nç™»å½•æŒ‰é’®ç´¢å¼•: {login_button_actions}"
        
        return f"""
æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼è¯·ç«‹å³å®Œæˆç™»å½•æµç¨‹ã€‚
        
        {page_context}
        {history_str}
        
        å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ æœ‰:
        {action_descriptions_str}
        
ç™»å½•æ“ä½œå»ºè®®ï¼š{login_suggestions}
        
ç™»å½•æ­¥éª¤ï¼ˆè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼‰ï¼š
        1. æ‰¾åˆ°ç”¨æˆ·å/é‚®ç®±è¾“å…¥å­—æ®µ â†’ è¾“å…¥"Nefelibata-Zhu"
        2. æ‰¾åˆ°å¯†ç è¾“å…¥å­—æ®µ â†’ è¾“å…¥"han19780518"
        3. ç‚¹å‡»"Sign in"ç™»å½•æŒ‰é’®ï¼ˆé¿å…æ³¨å†ŒæŒ‰é’®ï¼‰
        
é‡è¦æé†’ï¼š
        - ä¼˜å…ˆå®Œæˆç™»å½•ï¼Œä¸è¦è¿›è¡Œå…¶ä»–æ“ä½œ
        - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‡­æ®æ ¼å¼
        - é¿å…ç‚¹å‡»æ³¨å†Œç›¸å…³æŒ‰é’®
        
        è¯·è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå¯¹åº”ä¸Šé¢åˆ—è¡¨ä¸­åŠ¨ä½œçš„ç´¢å¼•ã€‚
        å¦‚æœé€‰æ‹©è¾“å…¥åŠ¨ä½œï¼Œæ ¼å¼ä¸º"ç´¢å¼•:æ–‡æœ¬"ã€‚
        ä¾‹å¦‚ï¼šç”¨æˆ·åå­—æ®µè¾“å…¥ï¼Œè¿”å›"{username_actions[0] if username_actions else 'X'}:Nefelibata-Zhu"
        
        åªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–è§£é‡Šã€‚
        """.strip()

    def get_action(self, web_state: WebState, html: str) -> WebAction:
        """
        ğŸš€ åŒæ¨¡å‹åä½œå†³ç­–æ–¹æ³• - R1æ¢ç´¢ + QwQå†³ç­–
        """
        action_list = web_state.get_action_list()
        if self.verbose:
            print(f"Available actions: {len(action_list)}")
        if not action_list:
            if self.verbose:
                print("Warning: No available actions")
            return None

        # è·å–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯
        page_context = ""
        page_title = ""
        current_url = ""
        if html:
            title_match = re.search(r"<title>(.*?)</title>", html, re.IGNORECASE)
            if title_match:
                page_title = title_match.group(1)
                page_context = f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}\n"
        
        if hasattr(web_state, 'url'):
            current_url = web_state.url
        elif page_title:
            current_url = page_title

        # æ„å»ºå†å²è®°å½•å­—ç¬¦ä¸²
        history_str = ""
        if self.history:
            history_str = "æœ€è¿‘çš„æ“ä½œå†å²:\n" + "\n".join([f"- {h}" for h in self.history[-self.max_history_length:]])

        # æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        is_login_page = self.detect_login_page(action_list, html, page_title)
        
        # ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - ä¼˜å…ˆä½¿ç”¨çŠ¶æ€æœº
        if is_login_page and self.login_state != "completed":
            if self.login_state == "none":
                self.login_state = "detected"
                print("ğŸ” æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œå¯åŠ¨æ™ºèƒ½ç™»å½•çŠ¶æ€æœº")
            
            smart_login_action = self.handle_smart_login(action_list, page_title)
            if smart_login_action is not None:
                return smart_login_action
            elif self.login_state == "completed":
                print("ğŸ” ç™»å½•æµç¨‹å·²å®Œæˆï¼Œåˆ‡æ¢åˆ°åŒæ¨¡å‹æµ‹è¯•æ¨¡å¼")
                self.reset_login_state()
        
        if not is_login_page and self.login_state != "none":
            if self.verbose:
                print("ğŸ” ç¦»å¼€ç™»å½•é¡µé¢ï¼Œé‡ç½®ç™»å½•çŠ¶æ€")
            self.reset_login_state()

        # ğŸš€ åŒæ¨¡å‹åä½œå†³ç­–
        print("ğŸš€ ä½¿ç”¨åŒæ¨¡å‹åä½œç³»ç»Ÿè¿›è¡Œå†³ç­–")
        
        try:
            # 1. ç”ŸæˆçŠ¶æ€ç­¾å
            state_signature = self.dual_model_system.generate_state_signature(
                page_title, action_list, html[:500]  # åªä½¿ç”¨å‰500å­—ç¬¦é¿å…è¿‡é•¿
            )
            
            # 2. æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çŠ¶æ€
            is_new_state = self.dual_model_system.is_new_state(state_signature)
            
            if is_new_state:
                # 3a. æ–°çŠ¶æ€ï¼šä½¿ç”¨R1è¿›è¡Œæ·±åº¦æ¢ç´¢
                print(f"ğŸ” æ£€æµ‹åˆ°æ–°çŠ¶æ€ï¼Œå¯åŠ¨R1æ·±åº¦æ¢ç´¢")
                
                exploration_data = self.dual_model_system.r1_explore_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    page_context=page_context,
                    history_str=history_str,
                    html=html
                )
                
                # ä¿å­˜æ¢ç´¢ç»“æœåˆ°ä¸“ç”¨çŸ¥è¯†åº“
                self.exploration_kb.add_exploration_result(exploration_data)
                
                # æ ‡è®°çŠ¶æ€ä¸ºå·²æ¢ç´¢
                self.dual_model_system.explored_states.add(state_signature)
                self.dual_model_system.state_exploration_cache[state_signature] = exploration_data
                
                # 3b. åŸºäºR1æ¢ç´¢ç»“æœï¼Œä½¿ç”¨QwQå¿«é€Ÿå†³ç­–
                qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                    action_list=action_list,
                    exploration_data=exploration_data,
                    page_context=page_context,
                    history_str=history_str
                )
                
                combined_reasoning = f"R1æ¢ç´¢: {exploration_data.get('reasoning', '')[:200]}... | QwQå†³ç­–: {qwq_reasoning[:200]}..."
                
            else:
                # 4. å·²çŸ¥çŠ¶æ€ï¼šç›´æ¥ä½¿ç”¨QwQåŸºäºç¼“å­˜çš„æ¢ç´¢ç»“æœå†³ç­–
                print(f"âš¡ å·²çŸ¥çŠ¶æ€ï¼Œä½¿ç”¨QwQå¿«é€Ÿå†³ç­–")
                
                cached_exploration = self.dual_model_system.state_exploration_cache.get(state_signature)
                if cached_exploration:
                    qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                        action_list=action_list,
                        exploration_data=cached_exploration,
                        page_context=page_context,
                        history_str=history_str
                    )
                else:
                    # ç¼“å­˜ä¸¢å¤±ï¼Œå¿«é€Ÿç”ŸæˆåŸºç¡€æ¢ç´¢ä¿¡æ¯
                    basic_exploration = {
                        "analysis": f"åŸºç¡€çŠ¶æ€åˆ†æï¼šé¡µé¢æœ‰{len(action_list)}ä¸ªå¯äº¤äº’å…ƒç´ ",
                        "reasoning": "ä½¿ç”¨åŸºç¡€æ¢ç´¢ä¿¡æ¯è¿›è¡Œå¿«é€Ÿå†³ç­–"
                    }
                    qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                        action_list=action_list,
                        exploration_data=basic_exploration,
                        page_context=page_context,
                        history_str=history_str
                    )
                
                combined_reasoning = f"ç¼“å­˜å†³ç­–: {qwq_reasoning[:300]}..."

            if self.verbose:
                print(f"åŒæ¨¡å‹è¾“å‡º: {qwq_output}")

            # 5. è§£æQwQè¾“å‡º
            action_index, input_text = self.parse_output(qwq_output, len(action_list))

            if action_index is not None and 0 <= action_index < len(action_list):
                # å†³ç­–æœ‰æ•ˆ
                selected_action = action_list[action_index]
                
                if isinstance(selected_action, RandomInputAction) and input_text:
                    if hasattr(selected_action, 'set_input_text'):
                        selected_action.set_input_text(input_text)

                # æ›´æ–°æ¢ç´¢å†å²è®°å½•
                self.update_exploration_history(current_url, selected_action, action_index)
                
                action_description = self.format_action_info(selected_action)
                if input_text:
                    action_description += f" with input: '{input_text}'"
                
                self.history.append(action_description)

                # ä¿å­˜çŸ¥è¯†åº“ä¿¡æ¯
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=action_index,
                    reasoning=combined_reasoning
                )

                self.thinking_kb.add_thinking(
                    prompt=f"åŒæ¨¡å‹åä½œ: æ–°çŠ¶æ€={is_new_state}",
                    reasoning=combined_reasoning,
                    action_taken=action_description
                )

                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]

                # æ˜¾ç¤ºå†³ç­–ç»“æœ
                model_info = "ğŸ”R1+âš¡QwQ" if is_new_state else "âš¡QwQ"
                if self.verbose:
                    print(f"âœ… {model_info}é€‰æ‹© [{action_index}]: {action_description}")
                    # ğŸ² æ˜¾ç¤ºå¤šæ ·æ€§ç»Ÿè®¡
                    diversity_stats = self.dual_model_system.get_dual_model_stats()
                    print(f"ğŸ² å¤šæ ·æ€§åˆ†æ•°: {diversity_stats['current_diversity_score']:.2f}")
                    print(f"ğŸ¯ æ¢ç´¢ç­–ç•¥ä½¿ç”¨: {diversity_stats['exploration_strategies_usage']}")
                    print(f"âš¡ å†³ç­–æ¨¡å¼ä½¿ç”¨: {diversity_stats['decision_modes_usage']}")
                else:
                    print(f"Action [{action_index}]: {self.format_action_info(selected_action)} ({model_info})")
                
                return selected_action
            else:
                # å†³ç­–æ— æ•ˆï¼Œéšæœºå›é€€
                if self.verbose:
                    print(f"âš ï¸ åŒæ¨¡å‹é€‰æ‹© {action_index} æ— æ•ˆï¼Œä½¿ç”¨éšæœºå›é€€ç­–ç•¥")
                
                import random
                fallback_index = random.randint(0, len(action_list) - 1)
                fallback_action = action_list[fallback_index]
                
                self.update_exploration_history(current_url, fallback_action, fallback_index)
                
                fallback_description = f"Random Fallback: {self.format_action_info(fallback_action)} ğŸ²"
                
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=fallback_index,
                    reasoning=f"åŒæ¨¡å‹é€‰æ‹©æ— æ•ˆï¼Œéšæœºå›é€€: {combined_reasoning if 'combined_reasoning' in locals() else 'Random selection'}"
                )

                if 'combined_reasoning' in locals():
                    self.thinking_kb.add_thinking(
                        prompt="åŒæ¨¡å‹å†³ç­–å¤±è´¥",
                        reasoning=combined_reasoning,
                        action_taken=fallback_description
                    )

                self.history.append(fallback_description)
                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]
                
                return fallback_action

        except Exception as e:
            if self.verbose:
                print(f"âŒ åŒæ¨¡å‹åä½œå¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºå›é€€")
            
            # éšæœºå›é€€
            import random
            fallback_index = random.randint(0, len(action_list) - 1)
            fallback_action = action_list[fallback_index]
            
            self.update_exploration_history(current_url, fallback_action, fallback_index)
            
            error_description = f"Error Fallback: {self.format_action_info(fallback_action)} âŒ"
            
            self.state_kb.add_page_state(
                page_title=page_title or "Unknown Page",
                action_list=action_list,
                selected_action_index=fallback_index,
                reasoning=f"åŒæ¨¡å‹ç³»ç»Ÿé”™è¯¯: {str(e)}ï¼Œéšæœºé€‰æ‹©åŠ¨ä½œ"
            )
            
            self.thinking_kb.add_thinking(
                prompt="åŒæ¨¡å‹ç³»ç»Ÿé”™è¯¯",
                reasoning=f"Error: {str(e)}",
                action_taken=error_description
            )

            self.history.append(error_description)
            if len(self.history) > self.max_history_length:
                self.history = self.history[-self.max_history_length:]
            
            return fallback_action

    def parse_output(self, output: str, num_actions: int) -> tuple:
        """
        è§£æLLMè¾“å‡ºï¼Œæå–åŠ¨ä½œç´¢å¼•å’Œå¯èƒ½çš„è¾“å…¥æ–‡æœ¬
        è¿”å›ä¸€ä¸ªå…ƒç»„ (åŠ¨ä½œç´¢å¼•, è¾“å…¥æ–‡æœ¬)ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥æ–‡æœ¬åˆ™ä¸ºNone
        """
        # å†…éƒ¨å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå»é™¤ ANSI è½¬ä¹‰åºåˆ—
        def remove_ansi(text: str) -> str:
            ansi_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            return ansi_pattern.sub('', text)

        cleaned_output = remove_ansi(output).strip()

        # å°è¯•åŒ¹é…"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼
        input_pattern = re.compile(r'^(\d+):(.+)$', re.DOTALL)
        match = input_pattern.match(cleaned_output)

        if match:
            index_str, input_text = match.groups()
            try:
                index = int(index_str)
                if 0 <= index < num_actions:
                    return index, input_text.strip()
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {index_str}")
                return None, None

        # å°è¯•ç›´æ¥æ‰¾å‡ºæ•°å­—
        number_match = re.search(r'^\d+', cleaned_output)
        if number_match:
            try:
                index = int(number_match.group())
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {number_match.group()}")
                return None, None

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–æœ€åä¸€ä¸ªæ•°å­—ä½œä¸ºç´¢å¼•
        numbers = re.findall(r'\d+', cleaned_output)
        if numbers:
            try:
                index = int(numbers[-1])
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {numbers[-1]}")
                return None, None

        if self.verbose:
            print(f"Failed to parse output: {cleaned_output[:50]}...")
        return None, None

    def get_exploration_stats(self) -> dict:
        """
        è·å–æ¢ç´¢ç»Ÿè®¡ä¿¡æ¯
        """
        total_pages = len(self.explored_pages)
        total_unique_actions = sum(len(actions) for actions in self.executed_actions.values())
        
        # è®¡ç®—é‡å¤åŠ¨ä½œç»Ÿè®¡
        overused_count = 0
        new_actions_available = 0
        
        for url, actions in self.executed_actions.items():
            for action_sig, count in actions.items():
                if count > 2:  # å›ºå®šé˜ˆå€¼ï¼Œä¹‹å‰çš„max_action_repeatsé»˜è®¤å€¼
                    overused_count += 1
        
        # è®¡ç®—æœ€æ´»è·ƒçš„é¡µé¢
        most_active_page = ""
        max_actions = 0
        for url, actions in self.executed_actions.items():
            if len(actions) > max_actions:
                max_actions = len(actions)
                most_active_page = url
        
        return {
            "explored_pages": total_pages,
            "unique_actions_executed": total_unique_actions,
            "overused_actions": overused_count,
            "most_active_page": most_active_page,
            "max_actions_on_page": max_actions,
            "explored_pages_list": list(self.explored_pages)
        }

    def print_exploration_summary(self):
        """
        æ‰“å°æ¢ç´¢æ‘˜è¦
        """
        stats = self.get_exploration_stats()
        print("\n" + "="*50)
        print("ğŸ¯ æ™ºèƒ½æ¢ç´¢ç³»ç»Ÿ - ç»Ÿè®¡æ‘˜è¦")
        print("="*50)
        print(f"ğŸ“Š å·²æ¢ç´¢é¡µé¢æ•°é‡: {stats['explored_pages']}")
        print(f"ğŸ® æ‰§è¡Œçš„å”¯ä¸€åŠ¨ä½œ: {stats['unique_actions_executed']}")
        print(f"âš ï¸ è¿‡åº¦ä½¿ç”¨çš„åŠ¨ä½œ: {stats['overused_actions']}")
        print(f"ğŸ† æœ€æ´»è·ƒé¡µé¢: {stats['most_active_page'][:50]}...")
        print(f"ğŸ”¥ è¯¥é¡µé¢åŠ¨ä½œæ•°: {stats['max_actions_on_page']}")
        
        if self.bug_indicators:
            print(f"ğŸ› æ½œåœ¨BugæŒ‡æ ‡: {len(self.bug_indicators)}")
            for indicator in self.bug_indicators[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3ä¸ª
                print(f"   - {indicator}")
        
        print("="*50)

    def debug_show_final_prompt(self, final_prompt: str):
        """
        è°ƒè¯•æ–¹æ³•ï¼šæ˜¾ç¤ºæœ€ç»ˆå‘é€ç»™LLMçš„å®Œæ•´promptç»“æ„
        """
        if not self.verbose:
            return
            
        print("\n" + "ğŸ” DEBUG: æœ€ç»ˆPromptç»“æ„" + "="*30)
        
        # å°è¯•åˆ†æpromptçš„å„ä¸ªéƒ¨åˆ†
        sections = final_prompt.split("\n\n")
        
        for i, section in enumerate(sections[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ªéƒ¨åˆ†é¿å…è¿‡é•¿
            if len(section.strip()) > 0:
                # è¯†åˆ«ä¸åŒç±»å‹çš„å†…å®¹
                if "ä¸“ä¸šçŸ¥è¯†åº“" in section:
                    print(f"\nğŸ“š ç¬¬{i+1}éƒ¨åˆ† - RAGçŸ¥è¯†å¢å¼º:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ" in section:
                    print(f"\nğŸ§  ç¬¬{i+1}éƒ¨åˆ† - ThinkingçŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ" in section:
                    print(f"\nğŸ“Š ç¬¬{i+1}éƒ¨åˆ† - çŠ¶æ€çŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif any(keyword in section for keyword in ["å¯æ“ä½œçš„ç•Œé¢å…ƒç´ ", "æ¢ç´¢ç­–ç•¥", "ç™»å½•æ­¥éª¤"]):
                    print(f"\nğŸ¯ ç¬¬{i+1}éƒ¨åˆ† - åŸºç¡€Prompt:")
                    print("â”€" * 40)
                    print(section[:500] + "..." if len(section) > 500 else section)
                    
                else:
                    print(f"\nğŸ“ ç¬¬{i+1}éƒ¨åˆ† - å…¶ä»–å†…å®¹:")
                    print("â”€" * 40)
                    print(section[:200] + "..." if len(section) > 200 else section)
        
        print(f"\nğŸ’¾ å®Œæ•´Promptæ€»é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        print("ğŸ” DEBUG: Promptç»“æ„åˆ†æå®Œæˆ" + "="*25 + "\n")

    def improve_action_selection_randomness(self, action_list, exploration_scores, current_url: str) -> str:
        """
        å·²åºŸå¼ƒçš„æ–¹æ³• - æ”¹ä¸ºçº¯LLMå†³ç­–åä¸å†ä½¿ç”¨
        """
        # æ­¤æ–¹æ³•å·²è¢«åˆ é™¤ï¼Œæ”¹ä¸ºçº¯LLMå†³ç­–
        return ""

    def reset_dual_model_session(self):
        """
        é‡ç½®åŒæ¨¡å‹ä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.dual_model_system.reset_for_new_test()
            if self.verbose:
                print("Dual model system reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset dual model system: {e}")

    def clear_all_rag_databases(self):
        """
        æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬æ–°çš„æ¢ç´¢çŸ¥è¯†åº“ï¼‰
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            self.exploration_kb.clear_exploration_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - åŒæ¨¡å‹ç‰ˆæœ¬
        """
        if self.verbose:
            print("Resetting dual-model agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€
        self.reset_dual_model_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“
        self.clear_all_rag_databases()
        
        if self.verbose:
            stats = self.dual_model_system.get_dual_model_stats()
            print(f"Agent reset complete - R1: {stats['r1_session_id']}, QwQ: {stats['qwq_session_id']}")


def main():
    """ğŸš€ å¤šæ ·æ€§å¢å¼ºåŒæ¨¡å‹åä½œRAG Agentæµ‹è¯• - R1æ™ºèƒ½æ¢ç´¢ + QwQå¤šæ ·æ€§å†³ç­–"""
    # æµ‹è¯•å‚æ•°
    test_params = {
        "api_key": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "embedding_token": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "app_name": "Enhanced Dual Model Web Testing",
        "verbose": True,  # æµ‹è¯•æ—¶å¯ç”¨è¯¦ç»†è¾“å‡º
        "max_tokens": 1024,  # åŸºç¡€é…ç½®ï¼Œä¼šè¢«å„æ¨¡å‹è¦†ç›–
        "temperature": 0.7,
        "clear_rag_on_init": True,
        "clear_thinking_on_init": True,
        "clear_state_on_init": True,
        "clear_exploration_on_init": True,
        "reset_dual_model_on_init": True,
    }

    print("ğŸš€ å¤šæ ·æ€§å¢å¼ºåŒæ¨¡å‹åä½œRAG Agent - R1æ™ºèƒ½æ¢ç´¢ + QwQå¤šæ ·æ€§å†³ç­–")
    print("=" * 70)
    
    try:
        # æµ‹è¯•Agentåˆå§‹åŒ–
        agent = rag_llm_agent(test_params)
        print("âœ“ å¤šæ ·æ€§å¢å¼ºåŒæ¨¡å‹Agentåˆå§‹åŒ–æˆåŠŸ")
        
        # ğŸ² æµ‹è¯•å¤šæ ·æ€§è·Ÿè¸ªå™¨åŠŸèƒ½
        diversity_tracker = agent.dual_model_system.diversity_tracker
        print("\nğŸ² å¤šæ ·æ€§è·Ÿè¸ªå™¨æµ‹è¯•:")
        
        # æµ‹è¯•æ¢ç´¢ç­–ç•¥é€‰æ‹©
        for i in range(5):
            strategy = diversity_tracker.select_exploration_strategy()
            print(f"  ğŸ¯ æ¢ç´¢ç­–ç•¥é€‰æ‹© #{i+1}: {strategy}")
        
        # æµ‹è¯•å†³ç­–æ¨¡å¼é€‰æ‹©
        for i in range(5):
            mode = diversity_tracker.select_decision_mode()
            print(f"  âš¡ å†³ç­–æ¨¡å¼é€‰æ‹© #{i+1}: {mode}")
        
        # æµ‹è¯•å¤šæ ·æ€§åˆ†æ
        sample_actions = ["ç‚¹å‡»ç™»å½•", "è¾“å…¥ç”¨æˆ·å", "ç‚¹å‡»æœç´¢", "é€‰æ‹©é€‰é¡¹", "ç‚¹å‡»ç™»å½•", "è¾“å…¥å¯†ç "]
        diversity_score = diversity_tracker.calculate_action_diversity(sample_actions)
        print(f"  ğŸ“Š æ ·æœ¬åŠ¨ä½œå¤šæ ·æ€§åˆ†æ•°: {diversity_score:.2f}")
        
        diversity_feedback = diversity_tracker.get_diversity_feedback(sample_actions)
        print(f"  ğŸ“ å¤šæ ·æ€§åé¦ˆ: {diversity_feedback.strip()}")
        
        # ğŸš€ æµ‹è¯•å¢å¼ºæŸ¥è¯¢ç”Ÿæˆ
        print("\nğŸ” å¢å¼ºæŸ¥è¯¢ç”Ÿæˆæµ‹è¯•:")
        for strategy in ['conservative', 'innovative', 'balanced', 'risk_focused']:
            queries = diversity_tracker.get_exploration_enhancement_queries("ç™»å½•é¡µé¢", strategy)
            print(f"  ğŸ¯ {strategy}ç­–ç•¥æŸ¥è¯¢: {queries[0][:50]}...")
        
        # âš¡ æµ‹è¯•å†³ç­–å¢å¼ºä¸Šä¸‹æ–‡
        print("\nâš¡ å†³ç­–å¢å¼ºä¸Šä¸‹æ–‡æµ‹è¯•:")
        for mode in ['conservative', 'exploratory', 'balanced']:
            context = diversity_tracker.get_decision_enhancement_context(mode)
            print(f"  ğŸ¯ {mode}æ¨¡å¼: {context[:100].replace(chr(10), ' ')}...")
        
        # æµ‹è¯•åŒæ¨¡å‹ç³»ç»Ÿç»Ÿè®¡ï¼ˆåŒ…å«å¤šæ ·æ€§ä¿¡æ¯ï¼‰
        stats = agent.dual_model_system.get_dual_model_stats()
        print(f"\nâœ“ å¢å¼ºåŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€:")
        print(f"  ğŸ“¡ R1ä¼šè¯ID: {stats['r1_session_id']}")
        print(f"  âš¡ QwQä¼šè¯ID: {stats['qwq_session_id']}")
        print(f"  ğŸ“Š æ¢ç´¢æ¬¡æ•°: {stats['total_explorations']}")
        print(f"  ğŸ’¾ ç¼“å­˜çŠ¶æ€: {stats['cached_states']}")
        print(f"  ğŸ² å½“å‰å¤šæ ·æ€§åˆ†æ•°: {stats['current_diversity_score']:.2f}")
        print(f"  ğŸ¯ æ¢ç´¢ç­–ç•¥ä½¿ç”¨: {stats['exploration_strategies_usage']}")
        print(f"  âš¡ å†³ç­–æ¨¡å¼ä½¿ç”¨: {stats['decision_modes_usage']}")
        
        # æµ‹è¯•é‡ç½®åŠŸèƒ½
        original_r1_session = stats['r1_session_id']
        original_qwq_session = stats['qwq_session_id']
        
        agent.reset_for_new_test()
        new_stats = agent.dual_model_system.get_dual_model_stats()
        
        reset_success = (
            original_r1_session != new_stats['r1_session_id'] and
            original_qwq_session != new_stats['qwq_session_id']
        )
        print(f"\nâœ“ é‡ç½®æµ‹è¯•: {'Success' if reset_success else 'Failed'}")
        
        # å±•ç¤ºå¢å¼ºæ¶æ„ç‰¹æ€§
        print("\nğŸš€ å¤šæ ·æ€§å¢å¼ºåŒæ¨¡å‹åä½œæ¶æ„:")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚  ğŸ² å¤šæ ·æ€§è·Ÿè¸ªå™¨ (DiversityTracker)                        â”‚")
        print("â”‚  â”œâ”€ æ™ºèƒ½ç­–ç•¥é€‰æ‹©: 4ç§æ¢ç´¢ç­–ç•¥åŠ¨æ€å¹³è¡¡                      â”‚")
        print("â”‚  â”œâ”€ å¤šæ ·æ€§å†³ç­–: 3ç§å†³ç­–æ¨¡å¼è‡ªé€‚åº”åˆ‡æ¢                      â”‚")
        print("â”‚  â”œâ”€ å®æ—¶ç›‘æ§: åŠ¨ä½œå¤šæ ·æ€§åˆ†æ•°å®æ—¶è®¡ç®—                       â”‚")
        print("â”‚  â””â”€ åé¦ˆä¼˜åŒ–: åŸºäºä½¿ç”¨é¢‘ç‡åŠ¨æ€è°ƒæ•´æƒé‡                     â”‚")
        print("â”‚                                                             â”‚")
        print("â”‚  ğŸ” å¢å¼ºR1æ¨¡å‹ (DeepSeek-R1)                               â”‚")
        print("â”‚  â”œâ”€ ç­–ç•¥å¯¼å‘æ¢ç´¢: åŸºäºé€‰å®šç­–ç•¥çš„æ·±åº¦åˆ†æ                   â”‚")
        print("â”‚  â”œâ”€ å¤šæ ·åŒ–RAGæ£€ç´¢: ç­–ç•¥ç›¸å…³çš„å¤šè§’åº¦çŸ¥è¯†è·å–                â”‚")
        print("â”‚  â”œâ”€ åå‘å­¦ä¹ : 20%æ¦‚ç‡åŠ å…¥å¤±è´¥æ¡ˆä¾‹å­¦ä¹                       â”‚")
        print("â”‚  â””â”€ è¾“å‡º: ç­–ç•¥åŒ–é¡µé¢åˆ†æã€å¤šæ ·æ€§æµ‹è¯•å»ºè®®                   â”‚")
        print("â”‚                                                             â”‚")
        print("â”‚  âš¡ å¢å¼ºQwQæ¨¡å‹ (Qwen/QwQ-32B-Preview)                      â”‚")
        print("â”‚  â”œâ”€ æ¨¡å¼å¯¼å‘å†³ç­–: åŸºäºé€‰å®šæ¨¡å¼çš„æ™ºèƒ½é€‰æ‹©                   â”‚")
        print("â”‚  â”œâ”€ å¤šæ ·æ€§åˆ†æ: åŠ¨ä½œç±»å‹ä½¿ç”¨é¢‘ç‡å®æ—¶è¯„ä¼°                   â”‚")
        print("â”‚  â”œâ”€ å†å²ä¼˜åŒ–: ä¼˜å…ˆé€‰æ‹©è¾ƒå°‘ä½¿ç”¨çš„åŠ¨ä½œç±»å‹                   â”‚")
        print("â”‚  â””â”€ è¾“å‡º: å¤šæ ·æ€§ä¼˜åŒ–çš„å…·ä½“åŠ¨ä½œé€‰æ‹©                         â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        print("\nğŸ”„ å¢å¼ºå·¥ä½œæµç¨‹:")
        print("1. ğŸ² å¤šæ ·æ€§è¯„ä¼° â†’ åˆ†æå½“å‰æµ‹è¯•å¤šæ ·æ€§çŠ¶æ€")
        print("2. ğŸ¯ ç­–ç•¥é€‰æ‹© â†’ æ™ºèƒ½é€‰æ‹©R1æ¢ç´¢ç­–ç•¥ (conservative/innovative/balanced/risk_focused)")
        print("3. ğŸ” ç­–ç•¥æ¢ç´¢ â†’ R1åŸºäºç­–ç•¥è¿›è¡Œå¤šæ ·åŒ–RAGå¢å¼ºæ·±åº¦åˆ†æ")
        print("4. ğŸ’¾ çŸ¥è¯†å­˜å‚¨ â†’ æ¢ç´¢ç»“æœå­˜å‚¨åˆ°ExplorationKB")
        print("5. âš¡ æ¨¡å¼å†³ç­– â†’ QwQé€‰æ‹©å†³ç­–æ¨¡å¼ (conservative/exploratory/balanced)")
        print("6. ğŸ¨ å¤šæ ·æ€§å†³ç­– â†’ åŸºäºå¤šæ ·æ€§åˆ†æå’Œå†å²ä½¿ç”¨é¢‘ç‡æ™ºèƒ½é€‰æ‹©åŠ¨ä½œ")
        print("7. ğŸ“Š åé¦ˆæ›´æ–° â†’ æ›´æ–°å¤šæ ·æ€§æŒ‡æ ‡å’Œç­–ç•¥æƒé‡")
        
        print("\nğŸ“š å¢å¼ºå››å±‚çŸ¥è¯†åº“ç³»ç»Ÿ:")
        print("â€¢ ğŸ” ExplorationKB: R1ç­–ç•¥åŒ–æ¢ç´¢ç»“æœ + å¤šæ ·æ€§æ´å¯Ÿ")
        print("â€¢ ğŸ“Š StateKB: é¡µé¢çŠ¶æ€ + å¤šæ ·æ€§å†³ç­–å†å²")
        print("â€¢ ğŸ§  ThinkingKB: æ¨¡å‹æ¨ç† + å¤±è´¥æ¡ˆä¾‹åå‘å­¦ä¹ ")
        print("â€¢ ğŸ“– RetrieverKB: ä¸“ä¸šçŸ¥è¯† + ç­–ç•¥å¯¼å‘å¤šæ ·åŒ–æ£€ç´¢")
        
        print("\nğŸ¯ å¤šæ ·æ€§å¢å¼ºç­–ç•¥:")
        print("ğŸ”„ **æ¢ç´¢ç­–ç•¥ (R1)**:")
        print("  â€¢ Conservative: åŸºäºæˆåŠŸç»éªŒçš„ç¨³å¥æ¢ç´¢")
        print("  â€¢ Innovative: å¯»æ‰¾æœªæµ‹è¯•åŒºåŸŸçš„åˆ›æ–°æ¢ç´¢")
        print("  â€¢ Balanced: ç¨³å®šæ€§ä¸åˆ›æ–°æ€§çš„å¹³è¡¡æ¢ç´¢")
        print("  â€¢ Risk-focused: ä¸“æ³¨è¾¹ç•Œå’Œé£é™©çš„å¯¼å‘æ¢ç´¢")
        
        print("\nâš¡ **å†³ç­–æ¨¡å¼ (QwQ)**:")
        print("  â€¢ Conservative: ä¼˜é€‰å†å²æˆåŠŸç‡é«˜çš„å®‰å…¨åŠ¨ä½œ")
        print("  â€¢ Exploratory: å‹‡äºå°è¯•æ–°è·¯å¾„å’Œæœªä½¿ç”¨åŠ¨ä½œ")
        print("  â€¢ Balanced: ç¨³å¥éªŒè¯ä¸åˆ›æ–°æ¢ç´¢çš„æœ€ä½³å¹³è¡¡")
        
        print("\nğŸ’¡ æ ¸å¿ƒåˆ›æ–°äº®ç‚¹:")
        print("ğŸ¯ **æ™ºèƒ½ç­–ç•¥é€‰æ‹©**: åŠ¨æ€å¹³è¡¡4ç§æ¢ç´¢ç­–ç•¥ï¼Œé¿å…å•ä¸€æ¨¡å¼")
        print("ğŸ² **å¤šæ ·æ€§é©±åŠ¨**: å®æ—¶ç›‘æ§æµ‹è¯•å¤šæ ·æ€§ï¼Œä¼˜åŒ–åŠ¨ä½œé€‰æ‹©")
        print("ğŸ“Š **ä½¿ç”¨é¢‘ç‡ä¼˜åŒ–**: ğŸ†•ä¼˜äºğŸ“Šä¼˜äºğŸ”¥ï¼Œé¼“åŠ±å°è¯•æ–°åŠ¨ä½œç±»å‹")
        print("ğŸ”„ **è‡ªé€‚åº”æƒé‡**: åŸºäºä½¿ç”¨é¢‘ç‡åŠ¨æ€è°ƒæ•´ç­–ç•¥æƒé‡")
        print("ğŸ§  **åå‘å­¦ä¹ **: ä»å¤±è´¥æ¡ˆä¾‹ä¸­å­¦ä¹ ï¼Œé¿å…é‡å¤é”™è¯¯")
        print("âš–ï¸ **ç­–ç•¥åè°ƒ**: R1æ¢ç´¢ç­–ç•¥ä¸QwQå†³ç­–æ¨¡å¼çš„æ™ºèƒ½é…åˆ")
        
        print("\nğŸš€ æ€§èƒ½ä¼˜åŠ¿:")
        print("ğŸ’° **æˆæœ¬æ•ˆç‡**: æ™ºèƒ½ç¼“å­˜ + ç­–ç•¥åŒ–æ¢ç´¢å¤§å¹…é™ä½tokenæ¶ˆè€—")
        print("ğŸ¨ **æµ‹è¯•è¦†ç›–**: å¤šæ ·æ€§é©±åŠ¨æ˜¾è‘—æå‡æµ‹è¯•è·¯å¾„è¦†ç›–é¢")
        print("ğŸ” **æ·±åº¦æ´å¯Ÿ**: ç­–ç•¥å¯¼å‘çš„RAGæ£€ç´¢æä¾›æ›´ç²¾å‡†çš„ä¸“ä¸šæŒ‡å¯¼")
        print("âš¡ **å“åº”é€Ÿåº¦**: æ¨¡å¼åŒ–å†³ç­–åŠ é€ŸåŠ¨ä½œé€‰æ‹©è¿‡ç¨‹")
        print("ğŸ›¡ï¸ **ç³»ç»Ÿç¨³å®š**: å¤šå±‚å›é€€æœºåˆ¶ä¿éšœæç«¯æƒ…å†µä¸‹çš„å¯ç”¨æ€§")
        
        print("\n" + "=" * 70)
        print("âœ… å¤šæ ·æ€§å¢å¼ºåŒæ¨¡å‹åä½œç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
        print("\nğŸŒŸ ç³»ç»Ÿç‰¹è‰²æ€»ç»“:")
        print("â€¢ ğŸ² **æ™ºèƒ½å¤šæ ·æ€§**: é¦–ä¸ªé›†æˆå¤šæ ·æ€§è·Ÿè¸ªçš„Webæµ‹è¯•AIç³»ç»Ÿ")
        print("â€¢ ğŸ¯ **ç­–ç•¥åŒ–æ¢ç´¢**: R1æ¨¡å‹çš„4ç§æ¢ç´¢ç­–ç•¥è‡ªé€‚åº”é€‰æ‹©")
        print("â€¢ âš¡ **æ¨¡å¼åŒ–å†³ç­–**: QwQæ¨¡å‹çš„3ç§å†³ç­–æ¨¡å¼åŠ¨æ€å¹³è¡¡")
        print("â€¢ ğŸ“Š **å®æ—¶ä¼˜åŒ–**: åŸºäºä½¿ç”¨é¢‘ç‡çš„åŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶")
        print("â€¢ ğŸ§  **ç»éªŒå­¦ä¹ **: æˆåŠŸæ¡ˆä¾‹ + å¤±è´¥æ¡ˆä¾‹çš„åŒå‘å­¦ä¹ èƒ½åŠ›")
        print("â€¢ ğŸš€ **RAGå¢å¼º**: å››å±‚çŸ¥è¯†åº“çš„ç­–ç•¥å¯¼å‘æ£€ç´¢ç³»ç»Ÿ")
        
        print(f"\nğŸ‰ ç°åœ¨è¿è¡Œ python main.py ä½“éªŒå¤šæ ·æ€§å¢å¼ºçš„æ™ºèƒ½Webæµ‹è¯•!")
        print(f"ğŸ”¥ æœŸå¾…çœ‹åˆ° {stats['exploration_strategies_usage']} ç­–ç•¥å’Œ {stats['decision_modes_usage']} æ¨¡å¼çš„åä½œæ•ˆæœ!")
            
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # åªæœ‰åœ¨ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰æ‰§è¡Œæµ‹è¯•
    main()
