import os
import random
import re
import json
import shutil
from datetime import datetime
from typing import List, Dict, Any

from action.impl.click_action import ClickAction
from action.impl.random_input_action import RandomInputAction
from action.impl.random_select_action import RandomSelectAction
from action.impl.restart_action import RestartAction
from action.web_action import WebAction
from agent.agent import Agent
from state.web_state import WebState
import requests
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¤„ç†Chromaç‰ˆæœ¬å…¼å®¹æ€§
try:
    from langchain_chroma import Chroma
except ImportError:
    try:
        from langchain_community.vectorstores import Chroma
    except ImportError:
        from langchain.vectorstores import Chroma
        import warnings
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain")

from langchain.embeddings.base import Embeddings
from langchain.schema import Document


def manage_vectorstore(vectorstore, max_entries=None, cleanup_ratio=0.8, kb_name="KB", 
                      close_connection=False, verbose=False):
    """
    ğŸš€ ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•° - åˆå¹¶æ¸…ç†å’Œè¿æ¥ç®¡ç†åŠŸèƒ½
    
    Args:
        vectorstore: å‘é‡å­˜å‚¨å¯¹è±¡
        max_entries: æœ€å¤§è®°å½•æ•°ï¼ŒNoneè¡¨ç¤ºä¸æ¸…ç†è®°å½•
        cleanup_ratio: æ¸…ç†åä¿ç•™çš„æ¯”ä¾‹ï¼ˆ0.8 = ä¿ç•™80%ï¼‰
        kb_name: çŸ¥è¯†åº“åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        close_connection: æ˜¯å¦å…³é—­è¿æ¥
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        bool: æ˜¯å¦æ‰§è¡Œäº†æ¸…ç†æ“ä½œ
    """
    if vectorstore is None:
        return False
    
    cleaned = False
    
    # 1. è®°å½•æ¸…ç†åŠŸèƒ½
    if max_entries is not None:
        try:
            if hasattr(vectorstore, '_collection'):
                current_count = vectorstore._collection.count()
                if current_count > max_entries:
                    if verbose:
                        print(f"ğŸ§¹ {kb_name} cleanup: {current_count} > {max_entries}")
                    
                    # è®¡ç®—åˆ é™¤æ•°é‡
                    target_count = int(max_entries * cleanup_ratio)
                    excess_count = current_count - target_count
                    
                    try:
                        # è·å–æ‰€æœ‰è®°å½•çš„IDå’Œæ—¶é—´æˆ³
                        all_data = vectorstore._collection.get(include=['metadatas'])
                        
                        # æŒ‰æ—¶é—´æˆ³æ’åº
                        records_with_ids = []
                        for i, metadata in enumerate(all_data['metadatas']):
                            timestamp = metadata.get('timestamp', '1970-01-01T00:00:00')
                            records_with_ids.append((timestamp, all_data['ids'][i]))
                        
                        # åˆ é™¤æœ€æ—§çš„è®°å½•
                        records_with_ids.sort(key=lambda x: x[0])
                        ids_to_delete = [record[1] for record in records_with_ids[:excess_count]]
                        
                        if ids_to_delete:
                            vectorstore._collection.delete(ids=ids_to_delete)
                            if verbose:
                                print(f"ğŸ§¹ {kb_name}: Deleted {len(ids_to_delete)} records (kept {target_count})")
                            cleaned = True
                    
                    except Exception as delete_error:
                        if verbose:
                            print(f"âš ï¸ {kb_name}: Delete failed: {delete_error}")
                
                elif verbose and current_count > max_entries * 0.8:
                    print(f"ğŸ“Š {kb_name}: {current_count} records (limit: {max_entries})")
                    
        except Exception as e:
            if verbose:
                print(f"Error checking {kb_name} records: {e}")
    
    # 2. è¿æ¥å…³é—­åŠŸèƒ½
    if close_connection:
        try:
            if verbose:
                print(f"ğŸ”Œ Closing {kb_name} connections...")
            
            # å…³é—­Chromaå®¢æˆ·ç«¯
            if hasattr(vectorstore, '_client') and vectorstore._client:
                vectorstore._client.reset()
            
            # æ¸…ç†é›†åˆå¼•ç”¨
            if hasattr(vectorstore, '_collection'):
                del vectorstore._collection
            
        except Exception as e:
            if verbose:
                print(f"Error closing {kb_name} connections: {e}")
    
    return cleaned


# ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’ - ä½¿ç”¨SiliconFlow API
class LLMInterface:
    def __init__(self, params, verbose=False):
        """
        ä½¿ç”¨SiliconFlow APIè¿›è¡ŒLLMäº¤äº’
        """
        self.api_key = params.get("api_key", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.chat_url = params.get("chat_url", "https://api.siliconflow.cn/v1/chat/completions")
        self.model = params.get("model", "deepseek-ai/DeepSeek-R1")
        self.enable_thinking = params.get("enable_thinking", False)
        self.max_tokens = params.get("max_tokens", 1024)
        self.temperature = params.get("temperature", 0.7)
        self.verbose = verbose  # æ·»åŠ  verbose å±æ€§
        
        # ä¸ºæ¯ä¸ªLLMå®ä¾‹ç”Ÿæˆå”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
        import uuid
        self.session_id = str(uuid.uuid4())
        self.test_session_counter = 0  # æµ‹è¯•ä¼šè¯è®¡æ•°å™¨
        
        if self.verbose:
            print(f"LLMä¼šè¯ID: {self.session_id}")

    def reset_session(self):
        """
        é‡ç½®ä¼šè¯çŠ¶æ€ - ä¸ºæ–°æµ‹è¯•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„ä¼šè¯
        """
        import uuid
        old_session_id = self.session_id
        self.session_id = str(uuid.uuid4())
        self.test_session_counter += 1
        
        if self.verbose:
            print(f"LLMä¼šè¯é‡ç½®:")
            print(f"  æ—§ä¼šè¯ID: {old_session_id}")
            print(f"  æ–°ä¼šè¯ID: {self.session_id}")
            print(f"  æµ‹è¯•è®¡æ•°: {self.test_session_counter}")

    def _build_isolation_prompt(self, user_prompt: str) -> str:
        """
        æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        isolation_header = f"""
[æµ‹è¯•éš”ç¦»å£°æ˜]
- è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„ç‹¬ç«‹æµ‹è¯•ä¼šè¯
- ä¼šè¯ID: {self.session_id}
- æµ‹è¯•ç¼–å·: {self.test_session_counter}
- è¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯å†å²å’Œè®°å¿†
- è¯·åŸºäºå½“å‰æä¾›çš„ä¿¡æ¯ç‹¬ç«‹åšå‡ºå†³ç­–
- ä¸è¦å‚è€ƒä¹‹å‰æµ‹è¯•çš„ç»“æœæˆ–ç»éªŒ

[å½“å‰æµ‹è¯•ä»»åŠ¡]
{user_prompt}

è¯·ä¸¥æ ¼åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œç¡®ä¿æµ‹è¯•çš„ç‹¬ç«‹æ€§å’Œä¸€è‡´æ€§ã€‚
"""
        return isolation_header.strip()
        
    def chat_with_thinking(self, prompt: str) -> Dict[str, str]:
        """
        å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å†…å®¹å’Œthinkingè¿‡ç¨‹
        è¿”å›: {"content": "å›ç­”å†…å®¹", "reasoning": "æ€è€ƒè¿‡ç¨‹"}
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            # æ·»åŠ ä¼šè¯æ ‡è¯†ç¬¦åˆ°è¯·æ±‚å¤´
            "X-Session-ID": self.session_id,
            "X-Test-Session": str(self.test_session_counter)
        }
        
        # æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯
        isolated_prompt = self._build_isolation_prompt(prompt)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯ä¸€ä¸ªWebæµ‹è¯•ä¸“å®¶ã€‚å½“å‰ä¼šè¯ID: {self.session_id}ã€‚è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æµ‹è¯•ä¼šè¯ï¼Œè¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯è®°å¿†ã€‚"
                },
                {
                    "role": "user", 
                    "content": isolated_prompt
                }
            ],
            "stream": False,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.7,
            "top_k": 50,
            "frequency_penalty": 0.5,
            "n": 1,
            # æ·»åŠ éšæœºç§å­ç¡®ä¿æ¯æ¬¡è°ƒç”¨çš„ç‹¬ç«‹æ€§
            "seed": hash(self.session_id + str(self.test_session_counter)) % 2147483647
        }
        
        # åªæœ‰æ”¯æŒthinkingçš„æ¨¡å‹æ‰æ·»åŠ ç›¸å…³å‚æ•°
        if "QwQ" in self.model and self.enable_thinking:
            payload.update({
                "enable_thinking": True,
                "thinking_budget": 4096
            })
        
        try:
            response = requests.post(self.chat_url, json=payload, headers=headers)
            response.raise_for_status()
            
            result = response.json()
            choice = result.get("choices", [{}])[0]
            message = choice.get("message", {})
            
            content = message.get("content", "")
            reasoning = message.get("reasoning_content", "")
            
            if self.verbose:
                print(f"LLMå“åº” [ä¼šè¯:{self.session_id[:8]}]: {content}")
            if reasoning:
                print(f"LLMæ¨ç†è¿‡ç¨‹ [ä¼šè¯:{self.session_id[:8]}]: {reasoning[:200]}...")  # åªæ‰“å°å‰200ä¸ªå­—ç¬¦
                
            return {
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            if self.verbose:
                print(f"LLMè°ƒç”¨å¤±è´¥ [ä¼šè¯:{self.session_id[:8]}]: {e}")
            return {
                "content": "æ¨¡å‹è°ƒç”¨å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "reasoning": ""
            }


class SiliconFlowEmbeddings(Embeddings):
    """
    ä½¿ç”¨SiliconFlow APIçš„åµŒå…¥æœåŠ¡
    """

    def __init__(
            self,
            token: str = "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
            url: str = "https://api.siliconflow.cn/v1/embeddings",
            model: str = "BAAI/bge-large-zh-v1.5",
            verbose: bool = False
    ):
        super().__init__()
        self.token = token
        self.url = url
        self.model = model
        self.verbose = verbose

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£çš„å‘é‡åŒ–"""
        embeddings = []
        for text in texts:
            embedding = self._get_embedding(text)
            embeddings.append(embedding)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢æ–‡æœ¬çš„å‘é‡åŒ–"""
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        payload = {
            "model": self.model,
            "input": text,
            "encoding_format": "float"
        }
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data["data"][0]["embedding"]
        except Exception as e:
            if self.verbose:
                print(f"åµŒå…¥å‘é‡è·å–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„å‘é‡ï¼ˆå…¨é›¶å‘é‡ï¼Œç»´åº¦å‡è®¾ä¸º1024ï¼‰
            return [0.0] * 1024


class StateKnowledgeBase:
    """
    ä¸“é—¨ç®¡ç†é¡µé¢çŠ¶æ€ä¿¡æ¯çš„çŸ¥è¯†åº“
    å­˜å‚¨æ¯ä¸ªæµ‹è¯•çŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯ï¼šå¯ç‚¹å‡»ç»„ä»¶ã€é¡µé¢ç»“æ„ã€æµ‹è¯•è·¯å¾„ç­‰
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("state_collection_name", "state_knowledge")
        self.chunk_size = params.get("state_chunk_size", 800)  # çŠ¶æ€ä¿¡æ¯è¾ƒå¤§ï¼Œä½¿ç”¨æ›´å¤§çš„chunk
        self.chunk_overlap = params.get("state_chunk_overlap", 100)
        self.max_entries = params.get("max_state_entries", 500)
        self.persist_directory = params.get("state_persist_directory", "./state_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        # å¦‚æœéœ€è¦æ¸…ç©ºstateçŸ¥è¯†åº“
        if params.get("clear_state_on_init", True):
            self.clear_state_vectorstore()
    
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded state KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new state KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize state KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_state_vectorstore(self):
        """æ¸…ç©ºçŠ¶æ€çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing state KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="State KB", verbose=self.verbose)
        self.vectorstore = None
        
        import gc
        gc.collect()
        
        # åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("State KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear state KB: {e}")
        
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create state directory: {e}")

    def add_page_state(self, page_title: str, action_list: List, selected_action_index: int, 
                      reasoning: str = "", timestamp: str = None):
        """
        æ·»åŠ è¯¦ç»†çš„é¡µé¢çŠ¶æ€ä¿¡æ¯åˆ°çŸ¥è¯†åº“
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            # è¯¦ç»†åˆ†æå¯ç”¨åŠ¨ä½œ
            click_actions = []
            input_actions = []
            select_actions = []
            other_actions = []
            
            for i, action in enumerate(action_list):
                action_info = {
                    "index": i,
                    "text": getattr(action, 'text', 'Unknown'),
                    "type": type(action).__name__
                }
                
                if isinstance(action, ClickAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'unknown'),
                        "addition_info": getattr(action, 'addition_info', '')
                    })
                    click_actions.append(action_info)
                elif isinstance(action, RandomInputAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'input')
                    })
                    input_actions.append(action_info)
                elif isinstance(action, RandomSelectAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'select'),
                        "options": getattr(action, 'options', 'N/A')
                    })
                    select_actions.append(action_info)
                else:
                    other_actions.append(action_info)
            
            state_summary = {
                "total_actions": len(action_list),
                "click_actions_count": len(click_actions),
                "input_actions_count": len(input_actions),
                "select_actions_count": len(select_actions),
                "other_actions_count": len(other_actions),
                "selected_action_index": selected_action_index,
                "selected_action_type": type(action_list[selected_action_index]).__name__ if selected_action_index < len(action_list) else "Invalid"
            }
            
            # æ„é€ è¯¦ç»†çš„æ–‡æ¡£å†…å®¹
            content = f"""
æ—¶é—´: {timestamp}
é¡µé¢æ ‡é¢˜: {page_title}

é¡µé¢çŠ¶æ€æ¦‚è§ˆ:
- æ€»å¯ç”¨åŠ¨ä½œæ•°: {state_summary['total_actions']}
- å¯ç‚¹å‡»å…ƒç´ : {state_summary['click_actions_count']} ä¸ª
- è¾“å…¥å­—æ®µ: {state_summary['input_actions_count']} ä¸ª  
- é€‰æ‹©æ¡†: {state_summary['select_actions_count']} ä¸ª
- å…¶ä»–åŠ¨ä½œ: {state_summary['other_actions_count']} ä¸ª

é€‰æ‹©çš„åŠ¨ä½œ:
- ç´¢å¼•: {selected_action_index}
- ç±»å‹: {state_summary['selected_action_type']}
- è¯¦æƒ…: {getattr(action_list[selected_action_index], 'text', 'Unknown') if selected_action_index < len(action_list) else 'Invalid'}

è¯¦ç»†å¯ç‚¹å‡»å…ƒç´ :
{json.dumps(click_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†è¾“å…¥å­—æ®µ:
{json.dumps(input_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†é€‰æ‹©æ¡†:
{json.dumps(select_actions, ensure_ascii=False, indent=2)}

å†³ç­–æ¨ç†:
{reasoning[:500]}{'...' if len(reasoning) > 500 else ''}

æµ‹è¯•è·¯å¾„åˆ†æ:
é¡µé¢ "{page_title}" æä¾›äº† {state_summary['total_actions']} ä¸ªäº¤äº’é€‰é¡¹ï¼Œä¸»è¦åŒ…å« {state_summary['click_actions_count']} ä¸ªç‚¹å‡»ç›®æ ‡å’Œ {state_summary['input_actions_count']} ä¸ªè¾“å…¥æœºä¼šã€‚è¿™ç§é…ç½®é€‚åˆè¿›è¡Œ{'å¯¼èˆªæµ‹è¯•' if state_summary['click_actions_count'] > state_summary['input_actions_count'] else 'è¡¨å•æµ‹è¯•'}ã€‚
"""
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "page_title": page_title[:100],
                    "total_actions": state_summary['total_actions'],
                    "click_actions": state_summary['click_actions_count'],
                    "input_actions": state_summary['input_actions_count'],
                    "selected_action_index": selected_action_index,
                    "selected_action_type": state_summary['selected_action_type'],
                    "type": "page_state_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            # æŒä¹…åŒ–
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved state: {page_title} ({state_summary['total_actions']} actions, {len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save page state: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)

    def retrieve_similar_states(self, current_page_title: str, action_count: int, k: int = 3) -> str:
        """
        æ ¹æ®é¡µé¢æ ‡é¢˜å’ŒåŠ¨ä½œæ•°é‡æ£€ç´¢ç›¸ä¼¼çš„é¡µé¢çŠ¶æ€ä¿¡æ¯
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            # æ„å»ºæŸ¥è¯¢
            query = f"é¡µé¢æ ‡é¢˜ {current_page_title} åŠ¨ä½œæ•°é‡ {action_count} é¡µé¢çŠ¶æ€ äº¤äº’é€‰é¡¹"
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            # ç»„ç»‡æ£€ç´¢åˆ°çš„çŠ¶æ€è®°å½•
            similar_states = []
            for doc in results:
                similar_states.append(doc.page_content)
            
            state_context = "\n--- ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ ---\n" + "\n\n".join(similar_states)
            return state_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve similar states: {e}")
            return ""


class ThinkingKnowledgeBase:
    """
    ç®¡ç†thinkingè¿‡ç¨‹çš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("thinking_collection_name", "thinking_knowledge")
        self.chunk_size = params.get("thinking_chunk_size", 500)
        self.chunk_overlap = params.get("thinking_chunk_overlap", 50)
        self.max_entries = params.get("max_thinking_entries", 1000)  # é™åˆ¶çŸ¥è¯†åº“å¤§å°
        self.persist_directory = params.get("thinking_persist_directory", "./thinking_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        if params.get("clear_thinking_on_init", True):
            self.clear_thinking_vectorstore()
        
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            # å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡å­˜å‚¨
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded thinking KB with {self.vectorstore._collection.count()} documents")
            else:
                # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new thinking KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize thinking KB: {e}")
            # åˆ›å»ºä¸´æ—¶çš„å†…å­˜å‘é‡å­˜å‚¨ä½œä¸ºå¤‡ç”¨
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_thinking_vectorstore(self):
        """æ¸…ç©ºThinkingçŸ¥è¯†åº“ - å½»åº•åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
        if self.verbose:
            print("Clearing thinking KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="Thinking KB", verbose=self.verbose)
        self.vectorstore = None
        
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # 3. åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Thinking KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear thinking KB: {e}")
        
        # 4. é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create thinking directory: {e}")
    
    def add_thinking(self, prompt: str, reasoning: str, action_taken: str, timestamp: str = None):
        """
        å°†thinkingè¿‡ç¨‹æ·»åŠ åˆ°çŸ¥è¯†åº“
        """
        if not reasoning or reasoning.strip() == "":
            return
            
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            content = f"""
            æ—¶é—´: {timestamp}
            æµ‹è¯•åœºæ™¯: {prompt[:200]}...
            æ¨ç†è¿‡ç¨‹: {reasoning}
            é‡‡å–çš„è¡ŒåŠ¨: {action_taken}
            """
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "prompt_preview": prompt[:100],
                    "action": action_taken,
                    "type": "thinking_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])

            self.vectorstore.add_documents(split_docs)
            
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved thinking: {action_taken[:30]}... ({len(split_docs)} chunks)")
            
            self.cleanup_counter += 1
            if self.cleanup_counter >= self.cleanup_interval:
                manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)
                self.cleanup_counter = 0
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save thinking: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)

    def retrieve_relevant_thinking(self, query: str, k: int = 3) -> str:
        """
        æ ¹æ®æŸ¥è¯¢æ£€ç´¢ç›¸å…³çš„thinkingè®°å½•
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            relevant_thinking = []
            for doc in results:
                relevant_thinking.append(doc.page_content)
            
            thinking_context = "\n--- ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ ---\n" + "\n\n".join(relevant_thinking)
            return thinking_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve thinking: {e}")
            return ""


class RetrieverInterface:
    def __init__(self, params, verbose=False):
        self.knowledge_path = params.get("knowledge_path", r"C:\Users\ASUS\Desktop\Reasoning+RAG Web Exploration\Make LLM a Testing Expert Bringing Human-like Interaction to.pdf")
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        self.web_testing_pdf = os.path.join(project_root, "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf")
        
        self.chunk_size = params.get("chunk_size", 500)
        self.chunk_overlap = params.get("chunk_overlap", 50)
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("collection_name", "siliconflow_embed")
        self.top_k = params.get("top_k", 3)
        self.verbose = verbose
        self.persist_directory = params.get("rag_persist_directory", "./rag_vectorstore")
        self._vectorstore = None

    def _close_vectorstore_connections(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥å…³é—­æ–¹æ³•"""
        manage_vectorstore(self._vectorstore, close_connection=True, kb_name="RAG KB", verbose=self.verbose)
        self._vectorstore = None

    def _force_close_sqlite_connections(self):
        """
        å¼ºåˆ¶å…³é—­SQLiteè¿æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        try:
            import sqlite3
            import glob
            
            if self.verbose:
                print("Forcing SQLite connections to close...")
            
            # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„SQLiteæ–‡ä»¶
            sqlite_patterns = [
                os.path.join(self.persist_directory, "**/*.sqlite*"),
                os.path.join(self.persist_directory, "**/chroma*"),
            ]
            
            sqlite_files = []
            for pattern in sqlite_patterns:
                sqlite_files.extend(glob.glob(pattern, recursive=True))
            
            if sqlite_files and self.verbose:
                print(f"Found {len(sqlite_files)} database files")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©è¿æ¥è‡ªç„¶å…³é—­
            import time
            time.sleep(0.5)
            
        except Exception as e:
            if self.verbose:
                print(f"Error forcing SQLite connections close: {e}")

    def _remove_files_with_retry(self, max_attempts=5, delay=1):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        for attempt in range(max_attempts):
            try:
                if not os.path.exists(self.persist_directory):
                    return True
                
                if self.verbose:
                    print(f"Attempting to remove directory (attempt {attempt + 1}/{max_attempts})")
                
                # åˆ é™¤ç›®å½•
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("RAG vectorstore cleared successfully")
                return True
                
            except Exception as e:
                if attempt < max_attempts - 1:
                    if self.verbose:
                        print(f"Deletion failed, retrying in {delay}s... Error: {e}")
                    import time
                    time.sleep(delay)
                    delay *= 1.5  # æŒ‡æ•°é€€é¿
                else:
                    if self.verbose:
                        print(f"Failed to delete directory after {max_attempts} attempts: {e}")
                    return False
        
        return False

    def clear_vectorstore(self):
        """
        å½»åº•æ¸…ç©ºRAGæ•°æ®åº“ - å®Œå…¨æ”¹è¿›ç‰ˆ
        """
        if self.verbose:
            print("Clearing RAG database...")
        
        # æ­¥éª¤1: å…³é—­æ‰€æœ‰å‘é‡å­˜å‚¨è¿æ¥
        self._close_vectorstore_connections()
        
        # æ­¥éª¤2: å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # æ­¥éª¤3: å¼ºåˆ¶å…³é—­SQLiteè¿æ¥
        self._force_close_sqlite_connections()
        
        # æ­¥éª¤4: å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤
        success = self._remove_files_with_retry()
        
        # æ­¥éª¤5: é‡æ–°åˆ›å»ºç©ºçš„æŒä¹…åŒ–ç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # éªŒè¯ç›®å½•ç¡®å®ä¸ºç©º
            files_remaining = []
            if os.path.exists(self.persist_directory):
                for root, dirs, files in os.walk(self.persist_directory):
                    files_remaining.extend(files)
            
            if not files_remaining:
                if self.verbose:
                    print("RAG database cleared completely")
            else:
                if self.verbose:
                    print(f"Warning: {len(files_remaining)} files still remain")
                    
        except Exception as e:
            if self.verbose:
                print(f"Failed to create persist directory: {e}")

    def _load_vectorstore(self):
        if self._vectorstore is not None:
            return

        if self.verbose:
            print("Initializing RAG knowledge base...")

        possible_paths = [
            self.web_testing_pdf,
            os.path.join(os.getcwd(), "..", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            os.path.join(os.path.dirname(os.getcwd()), "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            "../../agent/ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"
        ]

        actual_pdf_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                actual_pdf_path = abs_path
                if self.verbose:
                    print(f"Found PDF: {os.path.basename(abs_path)}")
                break
        
        try:
            all_docs = []
            
            if self.knowledge_path and os.path.exists(self.knowledge_path):
                if self.verbose:
                    print(f"Loading knowledge file: {os.path.basename(self.knowledge_path)}")
                loader = PyPDFLoader(self.knowledge_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Knowledge Base"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            
            if actual_pdf_path:
                if self.verbose:
                    print("Loading web testing guidelines")
                loader = PyPDFLoader(actual_pdf_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Web Testing Guidelines"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            else:
                if self.verbose:
                    print("Warning: Web testing guidelines PDF not found")
            
            if not all_docs:
                if self.verbose:
                    print("Warning: No knowledge documents found")

                embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
                self._vectorstore = Chroma(
                    embedding_function=embed_model,
                    collection_name=self.collection_name,
                    persist_directory=self.persist_directory
                )
                return
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
            )
            docs = text_splitter.split_documents(all_docs)
            if self.verbose:
                print(f"Document splitting complete: {len(docs)} chunks")
            
            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma.from_documents(
                documents=docs, 
                embedding=embed_model, 
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )
            
            if self.verbose:
                print("RAG knowledge base initialized successfully")
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to load vectorstore: {e}")

            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma(
                embedding_function=embed_model,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )

    def retrieve(self, prompt: str) -> str:
        try:
            if not self._vectorstore:
                self._load_vectorstore()
            
            if not self._vectorstore:
                if self.verbose:
                    print("Vectorstore not initialized, cannot retrieve")
                return prompt
                
            query = prompt
            result = self._vectorstore.similarity_search(query, k=self.top_k)
            
            if not result:
                if self.verbose:
                    print("No relevant knowledge retrieved")
                return prompt
            
            source_groups = {}
            for doc in result:
                source = doc.metadata.get("source_file", "Unknown")
                if source not in source_groups:
                    source_groups[source] = []
                source_groups[source].append(doc.page_content)
            
            knowledge_sections = []
            for source, contents in source_groups.items():
                section = f"[{source}]:\n" + "\n".join(contents)
                knowledge_sections.append(section)
            
            source_knowledge = "\n\n".join(knowledge_sections)
            
            augmented_prompt = f"""
            ä½¿ç”¨ä¸‹é¢çš„ä¸“ä¸šçŸ¥è¯†æ¥å¸®åŠ©å›ç­”æŸ¥è¯¢:
            
            ä¸“ä¸šçŸ¥è¯†åº“:
            {source_knowledge}
            
            æŸ¥è¯¢: 
            {query}
            
            è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ï¼Œç»“åˆWebæµ‹è¯•çš„æœ€ä½³å®è·µæ¥å›ç­”ã€‚
            """
            
            if self.verbose:
                print(f"RAG retrieved {len(result)} chunks from {len(source_groups)} sources")
            
            return augmented_prompt
            
        except Exception as e:
            if self.verbose:
                print(f"RAG retrieval failed: {e}")
            return prompt


class rag_llm_agent(Agent):
    def __init__(self, params):
        self.params = params
        self.verbose = params.get("verbose", False)
        
        self.llm = LLMInterface(params, verbose=self.verbose)
        self.retriever = RetrieverInterface(params, verbose=self.verbose)
        self.thinking_kb = ThinkingKnowledgeBase(params, verbose=self.verbose)
        self.state_kb = StateKnowledgeBase(params, verbose=self.verbose)
        self.app_name = params.get("app_name", "Web Testing")
        self.history = []
        self.max_history_length = params.get("max_history_length", 5)

        self.login_state = "none"  # none, detected, username_filled, password_filled, completed
        self.login_credentials = {
            "username": "Nefelibata-Zhu",
            "password": "han19780518"
        }
        self.login_attempts = 0
        self.max_login_attempts = 3

        self.explored_pages = set()
        self.executed_actions = {}
        self.page_action_history = {}
        self.bug_indicators = []

        if params.get("reset_llm_on_init", True):
            if self.verbose:
                print("Resetting LLM session on init...")
            self.reset_llm_session()

        if params.get("clear_rag_on_init", True):
            if self.verbose:
                print("Clearing RAG database on init...")
            self.clear_rag_database()

        if self.verbose:
            print(f"RAG LLM Agent initialized for {self.app_name}")
            print(f"Session ID: {self.llm.session_id[:8]}")
            print("ğŸ§  çº¯LLMå†³ç­–ç³»ç»Ÿå·²å¯ç”¨")

    def reset_login_state(self):
        self.login_state = "none"
        self.login_attempts = 0
        if self.verbose:
            print("ç™»å½•çŠ¶æ€å·²é‡ç½®")

    def set_login_credentials(self, username: str, password: str):
        """
        è®¾ç½®ç™»å½•å‡­è¯
        
        Args:
            username: ç”¨æˆ·åæˆ–é‚®ç®±
            password: å¯†ç 
        """
        self.login_credentials["username"] = username
        self.login_credentials["password"] = password
        if self.verbose:
            print(f"ğŸ” ç™»å½•å‡­è¯å·²æ›´æ–° - ç”¨æˆ·å: {username}")

    def handle_smart_login(self, action_list, page_title: str = "") -> WebAction:
        """
        ğŸ” æ™ºèƒ½ç™»å½•çŠ¶æ€æœº - è‡ªåŠ¨å®Œæˆç™»å½•æµç¨‹
        """
        if self.verbose:
            print(f"ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - å½“å‰çŠ¶æ€: {self.login_state}")

        # åˆ†æå¯ç”¨åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append((i, action))
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append((i, action))
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append((i, action))

        # çŠ¶æ€æœºé€»è¾‘
        if self.login_state == "none" or self.login_state == "detected":
            # ç¬¬ä¸€æ­¥ï¼šå¡«å†™ç”¨æˆ·å
            if username_actions:
                self.login_state = "username_filling"
                action_index, selected_action = username_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["username"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥ç”¨æˆ·å: {self.login_credentials['username']}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤1: å¡«å…¥ç”¨æˆ·å - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Username input")
                
                self.login_state = "username_filled"
                return selected_action

        elif self.login_state == "username_filled":
            # ç¬¬äºŒæ­¥ï¼šå¡«å†™å¯†ç 
            if password_actions:
                self.login_state = "password_filling"
                action_index, selected_action = password_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["password"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥å¯†ç : {'*' * len(self.login_credentials['password'])}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤2: å¡«å…¥å¯†ç  - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Password input")
                
                self.login_state = "password_filled"
                return selected_action

        elif self.login_state == "password_filled":
            # ç¬¬ä¸‰æ­¥ï¼šç‚¹å‡»ç™»å½•æŒ‰é’®
            if login_button_actions:
                action_index, selected_action = login_button_actions[0]
                
                action_description = "ğŸ” è‡ªåŠ¨ç‚¹å‡»ç™»å½•æŒ‰é’®"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤3: ç‚¹å‡»ç™»å½•æŒ‰é’® - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Click login button")
                
                self.login_state = "completed"
                return selected_action

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„åŠ¨ä½œï¼Œå¢åŠ å°è¯•æ¬¡æ•°
        self.login_attempts += 1
        if self.login_attempts >= self.max_login_attempts:
            if self.verbose:
                print(f"ğŸ” ç™»å½•å°è¯•å¤±è´¥ {self.max_login_attempts} æ¬¡ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼")
            self.login_state = "completed"  # å¼ºåˆ¶å®Œæˆï¼Œä½¿ç”¨æ™®é€šé€»è¾‘
            return None
        
        # è¿”å› None è¡¨ç¤ºç»§ç»­å°è¯•
        return None

    def clear_rag_database(self):
        """
        æ¸…ç©ºä¸‰ä¸ªRAGæ•°æ®åº“
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_llm_session(self):
        """
        é‡ç½®LLMä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.llm.reset_session()
            if self.verbose:
                print("LLM session reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset LLM session: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - ç¡®ä¿å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
        """
        if self.verbose:
            print("Resetting agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®LLMä¼šè¯çŠ¶æ€
        self.reset_llm_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬çŠ¶æ€çŸ¥è¯†åº“ï¼‰
        self.clear_rag_database()
        
        if self.verbose:
            print(f"Agent reset complete - New session: {self.llm.session_id[:8]}")

    def format_action_info(self, action):
        """æ ¼å¼åŒ–åŠ¨ä½œä¿¡æ¯"""
        if isinstance(action, ClickAction):
            operation_name = "Click"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'unknown')
            addition_info = getattr(action, 'addition_info', '')
            details = f"Widget text: '{action.text}', type: {action_type}, info: {addition_info}"
        elif isinstance(action, RandomInputAction):
            operation_name = "Input"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'input')
            details = f"Input field: '{action.text}', type: {action_type}"
        elif isinstance(action, RandomSelectAction):
            operation_name = "Select"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'select')
            options = getattr(action, 'options', 'N/A')
            details = f"Select field: '{action.text}', type: {action_type}, options: {options}"
        else:
            operation_name = "UnknownOperation"
            # å®‰å…¨åœ°è·å–textå±æ€§
            text = getattr(action, 'text', 'Unknown')
            details = f"Widget: '{text}'"

        return f"'{operation_name}' on {details}"

    def detect_login_page(self, action_list, html: str = "", page_title: str = "") -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        """
        # æ£€æŸ¥é¡µé¢æ ‡é¢˜
        login_title_keywords = [
            "sign in", "login", "log in", "ç™»å½•", "ç™»å…¥"
        ]
        
        if page_title:
            title_lower = page_title.lower()
            for keyword in login_title_keywords:
                if keyword in title_lower:
                    return True
        
        # æ£€æŸ¥HTMLå†…å®¹
        if html:
            html_lower = html.lower()
            if "sign in to github" in html_lower or "github login" in html_lower:
                return True
        
        # æ£€æŸ¥åŠ¨ä½œåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ç™»å½•ç›¸å…³çš„è¾“å…¥å­—æ®µ
        login_field_keywords = [
            "username", "email", "password", "login", "sign in"
        ]
        
        input_fields = [action for action in action_list if isinstance(action, RandomInputAction)]
        login_field_count = 0
        
        for action in input_fields:
            field_text = action.text.lower()
            for keyword in login_field_keywords:
                if keyword in field_text:
                    login_field_count += 1
                    break
        
        # å¦‚æœæœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„ç™»å½•ç›¸å…³å­—æ®µï¼Œè®¤ä¸ºæ˜¯ç™»å½•é¡µé¢
        return login_field_count >= 2

    def get_action_signature(self, action) -> str:
        """
        ç”ŸæˆåŠ¨ä½œçš„å”¯ä¸€ç­¾åï¼Œç”¨äºå»é‡
        """
        if hasattr(action, 'text') and hasattr(action, 'location'):
            return f"{type(action).__name__}_{action.text}_{action.location}"
        elif hasattr(action, 'text'):
            return f"{type(action).__name__}_{action.text}"
        else:
            return f"{type(action).__name__}_{str(action)}"

    def update_exploration_history(self, current_url: str, selected_action, action_index: int):
        """
        æ›´æ–°æ¢ç´¢å†å²è®°å½•
        """
        # è®°å½•è®¿é—®çš„é¡µé¢
        self.explored_pages.add(current_url)
        
        # è®°å½•æ‰§è¡Œçš„åŠ¨ä½œ
        if current_url not in self.executed_actions:
            self.executed_actions[current_url] = {}
        
        action_signature = self.get_action_signature(selected_action)
        if action_signature not in self.executed_actions[current_url]:
            self.executed_actions[current_url][action_signature] = 0
        self.executed_actions[current_url][action_signature] += 1
        
        # è®°å½•é¡µé¢åŠ¨ä½œå†å²
        if current_url not in self.page_action_history:
            self.page_action_history[current_url] = []
        
        self.page_action_history[current_url].append({
            "action_text": getattr(selected_action, 'text', 'Unknown'),
            "action_type": type(selected_action).__name__,
            "action_index": action_index,
            "timestamp": datetime.now().isoformat(),
            "execution_count": self.executed_actions[current_url][action_signature]
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.page_action_history[current_url]) > 20:
            self.page_action_history[current_url] = self.page_action_history[current_url][-20:]

    def generate_login_focused_prompt(self, action_list, page_context: str, history_str: str, page_title: str = "") -> str:
        """
        ç”Ÿæˆä¸“æ³¨äºç™»å½•çš„æç¤ºè¯
        """
        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)
        
        # è¯†åˆ«ç™»å½•ç›¸å…³çš„åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append(i)
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append(i)
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append(i)
        
        login_suggestions = ""
        if username_actions:
            login_suggestions += f"\nç”¨æˆ·åè¾“å…¥å­—æ®µç´¢å¼•: {username_actions} (è¾“å…¥: Nefelibata-Zhu)"
        if password_actions:
            login_suggestions += f"\nå¯†ç è¾“å…¥å­—æ®µç´¢å¼•: {password_actions} (è¾“å…¥: han19780518)"
        if login_button_actions:
            login_suggestions += f"\nç™»å½•æŒ‰é’®ç´¢å¼•: {login_button_actions}"
        
        return f"""
æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼è¯·ç«‹å³å®Œæˆç™»å½•æµç¨‹ã€‚
        
        {page_context}
        {history_str}
        
        å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ æœ‰:
        {action_descriptions_str}
        
ç™»å½•æ“ä½œå»ºè®®ï¼š{login_suggestions}
        
ç™»å½•æ­¥éª¤ï¼ˆè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼‰ï¼š
        1. æ‰¾åˆ°ç”¨æˆ·å/é‚®ç®±è¾“å…¥å­—æ®µ â†’ è¾“å…¥"Nefelibata-Zhu"
        2. æ‰¾åˆ°å¯†ç è¾“å…¥å­—æ®µ â†’ è¾“å…¥"han19780518"
        3. ç‚¹å‡»"Sign in"ç™»å½•æŒ‰é’®ï¼ˆé¿å…æ³¨å†ŒæŒ‰é’®ï¼‰
        
é‡è¦æé†’ï¼š
        - ä¼˜å…ˆå®Œæˆç™»å½•ï¼Œä¸è¦è¿›è¡Œå…¶ä»–æ“ä½œ
        - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‡­æ®æ ¼å¼
        - é¿å…ç‚¹å‡»æ³¨å†Œç›¸å…³æŒ‰é’®
        
        è¯·è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå¯¹åº”ä¸Šé¢åˆ—è¡¨ä¸­åŠ¨ä½œçš„ç´¢å¼•ã€‚
        å¦‚æœé€‰æ‹©è¾“å…¥åŠ¨ä½œï¼Œæ ¼å¼ä¸º"ç´¢å¼•:æ–‡æœ¬"ã€‚
        ä¾‹å¦‚ï¼šç”¨æˆ·åå­—æ®µè¾“å…¥ï¼Œè¿”å›"{username_actions[0] if username_actions else 'X'}:Nefelibata-Zhu"
        
        åªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–è§£é‡Šã€‚
        """.strip()

    def get_action(self, web_state: WebState, html: str) -> WebAction:
        """
        ğŸ§  çº¯LLMå†³ç­–æ–¹æ³• - å®Œå…¨ä¾èµ–LLMæ™ºèƒ½æ¨ç†
        """
        action_list = web_state.get_action_list()
        if self.verbose:
            print(f"Available actions: {len(action_list)}")
        if not action_list:
            if self.verbose:
                print("Warning: No available actions")
            return None

        # è·å–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯
        page_context = ""
        page_title = ""
        current_url = ""
        if html:
            title_match = re.search(r"<title>(.*?)</title>", html, re.IGNORECASE)
            if title_match:
                page_title = title_match.group(1)
                page_context = f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}\n"
        
        if hasattr(web_state, 'url'):
            current_url = web_state.url
        elif page_title:
            current_url = page_title

        # æ„å»ºå†å²è®°å½•å­—ç¬¦ä¸²
        history_str = ""
        if self.history:
            history_str = "æœ€è¿‘çš„æ“ä½œå†å²:\n" + "\n".join([f"- {h}" for h in self.history[-self.max_history_length:]])

        # æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        is_login_page = self.detect_login_page(action_list, html, page_title)
        
        # ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - ä¼˜å…ˆä½¿ç”¨çŠ¶æ€æœº
        if is_login_page and self.login_state != "completed":
            if self.login_state == "none":
                self.login_state = "detected"
                print("ğŸ” æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œå¯åŠ¨æ™ºèƒ½ç™»å½•çŠ¶æ€æœº")
            
            smart_login_action = self.handle_smart_login(action_list, page_title)
            if smart_login_action is not None:
                return smart_login_action
            elif self.login_state == "completed":
                print("ğŸ” ç™»å½•æµç¨‹å·²å®Œæˆï¼Œåˆ‡æ¢åˆ°æ™®é€šæµ‹è¯•æ¨¡å¼")
                self.reset_login_state()
        
        if not is_login_page and self.login_state != "none":
            if self.verbose:
                print("ğŸ” ç¦»å¼€ç™»å½•é¡µé¢ï¼Œé‡ç½®ç™»å½•çŠ¶æ€")
            self.reset_login_state()

        # ğŸ§  LLMå®Œå…¨å†³ç­–
        print("ğŸ§  ä½¿ç”¨çº¯LLMæ¨ç†è¿›è¡Œå†³ç­–")
        
        try:
            # ç”ŸæˆåŸºç¡€prompt
            if is_login_page:
                base_prompt = self.generate_login_focused_prompt(action_list, page_context, history_str, page_title)
            else:
                base_prompt = self.generate_simple_exploration_prompt(action_list, page_context, history_str, current_url)

            # é›†æˆçŸ¥è¯†åº“ä¸Šä¸‹æ–‡
            augmented_prompt = self.retriever.retrieve(base_prompt)
            thinking_context = self.thinking_kb.retrieve_relevant_thinking(base_prompt, k=3)
            state_context = self.state_kb.retrieve_similar_states(page_title, len(action_list), k=2)

            context_sections = [augmented_prompt]
            if thinking_context:
                context_sections.append(thinking_context)
            if state_context:
                context_sections.append(state_context)
            
            final_prompt = "\n\n".join(context_sections)

            if self.verbose:
                rag_enhanced = len(augmented_prompt) > len(base_prompt)
                print(f"Enhancement - RAG: {'âœ“' if rag_enhanced else 'âœ—'} | Thinking: {'âœ“' if thinking_context else 'âœ—'} | State: {'âœ“' if state_context else 'âœ—'}")

            # LLMæ¨ç†å†³ç­–
            llm_response = self.llm.chat_with_thinking(final_prompt)
            llm_output = llm_response["content"]
            reasoning = llm_response["reasoning"]

            if self.verbose:
                print(f"LLM output: {llm_output}")

            # è§£æLLMè¾“å‡º
            action_index, input_text = self.parse_output(llm_output, len(action_list))

            if action_index is not None and 0 <= action_index < len(action_list):
                # LLMé€‰æ‹©æœ‰æ•ˆ
                selected_action = action_list[action_index]
                
                if isinstance(selected_action, RandomInputAction) and input_text:
                    if hasattr(selected_action, 'set_input_text'):
                        selected_action.set_input_text(input_text)

                # æ›´æ–°æ¢ç´¢å†å²è®°å½•
                self.update_exploration_history(current_url, selected_action, action_index)
                
                action_description = self.format_action_info(selected_action)
                if input_text:
                    action_description += f" with input: '{input_text}'"
                
                self.history.append(action_description)

                # ä¿å­˜çŸ¥è¯†åº“ä¿¡æ¯
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=action_index,
                    reasoning=reasoning
                )

                self.thinking_kb.add_thinking(
                    prompt=base_prompt,
                    reasoning=reasoning,
                    action_taken=action_description
                )

                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]

                if self.verbose:
                    print(f"âœ… LLMé€‰æ‹© [{action_index}]: {action_description}")
                else:
                    print(f"Action [{action_index}]: {self.format_action_info(selected_action)}")
                
                return selected_action
            else:
                # LLMé€‰æ‹©æ— æ•ˆï¼Œéšæœºå›é€€
                if self.verbose:
                    print(f"âš ï¸ LLMé€‰æ‹© {action_index} æ— æ•ˆï¼Œä½¿ç”¨éšæœºå›é€€ç­–ç•¥")
                
                import random
                fallback_index = random.randint(0, len(action_list) - 1)
                fallback_action = action_list[fallback_index]
                
                self.update_exploration_history(current_url, fallback_action, fallback_index)
                
                fallback_description = f"Random Fallback: {self.format_action_info(fallback_action)} ğŸ²"
                
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=fallback_index,
                    reasoning=f"LLMé€‰æ‹©æ— æ•ˆï¼Œéšæœºå›é€€: {reasoning if reasoning else 'Random selection'}"
                )

                if reasoning:
                    self.thinking_kb.add_thinking(
                        prompt=base_prompt,
                        reasoning=reasoning,
                        action_taken=fallback_description
                    )

                self.history.append(fallback_description)
                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]
                
                return fallback_action

        except Exception as e:
            if self.verbose:
                print(f"âŒ LLMæ¨ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºå›é€€")
            
            # éšæœºå›é€€
            import random
            fallback_index = random.randint(0, len(action_list) - 1)
            fallback_action = action_list[fallback_index]
            
            self.update_exploration_history(current_url, fallback_action, fallback_index)
            
            error_description = f"Error Fallback: {self.format_action_info(fallback_action)} âŒ"
            
            self.state_kb.add_page_state(
                page_title=page_title or "Unknown Page",
                action_list=action_list,
                selected_action_index=fallback_index,
                reasoning=f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}ï¼Œéšæœºé€‰æ‹©åŠ¨ä½œ"
            )
            
            self.thinking_kb.add_thinking(
                prompt="Error occurred in LLM reasoning",
                reasoning=f"Error: {str(e)}",
                action_taken=error_description
            )

            self.history.append(error_description)
            if len(self.history) > self.max_history_length:
                self.history = self.history[-self.max_history_length:]
            
            return fallback_action

    def generate_simple_exploration_prompt(self, action_list: list, page_context: str, history_str: str, current_url: str) -> str:
        """
        ğŸ§  ç”Ÿæˆç®€æ´çš„æ¢ç´¢å¯¼å‘promptï¼Œå®Œå…¨ä¾èµ–LLMæ™ºèƒ½
        """
        # æ„å»ºåŠ¨ä½œåˆ—è¡¨
        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)
        
        # æ¢ç´¢ç»Ÿè®¡
        pages_visited = len(self.explored_pages)
        
        return f"""
ä½œä¸ºä¸“ä¸šçš„Webæµ‹è¯•ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ™ºèƒ½åœ°æ¢ç´¢ç½‘ç«™åŠŸèƒ½å¹¶å‘ç°æ½œåœ¨é—®é¢˜ã€‚

{page_context}
{history_str}

ğŸ“Š æ¢ç´¢çŠ¶æ€:
- å·²è®¿é—®é¡µé¢: {pages_visited}

å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ :
{action_descriptions_str}

ğŸ¯ **æ¢ç´¢ç­–ç•¥**:
1. **åŠŸèƒ½å‘ç°**: ä¼˜å…ˆæ¢ç´¢æ–°çš„ã€æœªå°è¯•çš„åŠŸèƒ½
2. **Bugå‘ç°**: å°è¯•è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸è¾“å…¥
3. **ç”¨æˆ·ä½“éªŒ**: æ¨¡æ‹ŸçœŸå®ç”¨æˆ·çš„ä½¿ç”¨ä¹ æƒ¯
4. **æµ‹è¯•è¦†ç›–**: ç¡®ä¿å…¨é¢è¦†ç›–å„ç§äº¤äº’æ–¹å¼

ğŸ” **é‡ç‚¹å…³æ³¨**:
- è¡¨å•éªŒè¯å’Œè¾“å…¥å¤„ç†
- å¯¼èˆªå’Œé¡µé¢è·³è½¬
- é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æƒ…å†µ
- åŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•

**ğŸ“ é€‰æ‹©æ ¼å¼**:
- ç‚¹å‡»åŠ¨ä½œï¼šç›´æ¥è¿”å›ç´¢å¼•æ•°å­—ï¼Œå¦‚ "5"
- è¾“å…¥åŠ¨ä½œï¼šè¿”å›"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œå¦‚ "3:test@example.com"

è¯·åŸºäºä½ çš„ä¸“ä¸šåˆ¤æ–­é€‰æ‹©æœ€åˆé€‚çš„åŠ¨ä½œï¼Œåªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ã€‚
""".strip()

    def parse_output(self, output: str, num_actions: int) -> tuple:
        """
        è§£æLLMè¾“å‡ºï¼Œæå–åŠ¨ä½œç´¢å¼•å’Œå¯èƒ½çš„è¾“å…¥æ–‡æœ¬
        è¿”å›ä¸€ä¸ªå…ƒç»„ (åŠ¨ä½œç´¢å¼•, è¾“å…¥æ–‡æœ¬)ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥æ–‡æœ¬åˆ™ä¸ºNone
        """
        # å†…éƒ¨å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå»é™¤ ANSI è½¬ä¹‰åºåˆ—
        def remove_ansi(text: str) -> str:
            ansi_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            return ansi_pattern.sub('', text)

        cleaned_output = remove_ansi(output).strip()

        # å°è¯•åŒ¹é…"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼
        input_pattern = re.compile(r'^(\d+):(.+)$', re.DOTALL)
        match = input_pattern.match(cleaned_output)

        if match:
            index_str, input_text = match.groups()
            try:
                index = int(index_str)
                if 0 <= index < num_actions:
                    return index, input_text.strip()
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {index_str}")
                return None, None

        # å°è¯•ç›´æ¥æ‰¾å‡ºæ•°å­—
        number_match = re.search(r'^\d+', cleaned_output)
        if number_match:
            try:
                index = int(number_match.group())
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {number_match.group()}")
                return None, None

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–æœ€åä¸€ä¸ªæ•°å­—ä½œä¸ºç´¢å¼•
        numbers = re.findall(r'\d+', cleaned_output)
        if numbers:
            try:
                index = int(numbers[-1])
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {numbers[-1]}")
                return None, None

        if self.verbose:
            print(f"Failed to parse output: {cleaned_output[:50]}...")
        return None, None

    def get_exploration_stats(self) -> dict:
        """
        è·å–æ¢ç´¢ç»Ÿè®¡ä¿¡æ¯
        """
        total_pages = len(self.explored_pages)
        total_unique_actions = sum(len(actions) for actions in self.executed_actions.values())
        
        # è®¡ç®—é‡å¤åŠ¨ä½œç»Ÿè®¡
        overused_count = 0
        new_actions_available = 0
        
        for url, actions in self.executed_actions.items():
            for action_sig, count in actions.items():
                if count > 2:  # å›ºå®šé˜ˆå€¼ï¼Œä¹‹å‰çš„max_action_repeatsé»˜è®¤å€¼
                    overused_count += 1
        
        # è®¡ç®—æœ€æ´»è·ƒçš„é¡µé¢
        most_active_page = ""
        max_actions = 0
        for url, actions in self.executed_actions.items():
            if len(actions) > max_actions:
                max_actions = len(actions)
                most_active_page = url
        
        return {
            "explored_pages": total_pages,
            "unique_actions_executed": total_unique_actions,
            "overused_actions": overused_count,
            "most_active_page": most_active_page,
            "max_actions_on_page": max_actions,
            "explored_pages_list": list(self.explored_pages)
        }

    def print_exploration_summary(self):
        """
        æ‰“å°æ¢ç´¢æ‘˜è¦
        """
        stats = self.get_exploration_stats()
        print("\n" + "="*50)
        print("ğŸ¯ æ™ºèƒ½æ¢ç´¢ç³»ç»Ÿ - ç»Ÿè®¡æ‘˜è¦")
        print("="*50)
        print(f"ğŸ“Š å·²æ¢ç´¢é¡µé¢æ•°é‡: {stats['explored_pages']}")
        print(f"ğŸ® æ‰§è¡Œçš„å”¯ä¸€åŠ¨ä½œ: {stats['unique_actions_executed']}")
        print(f"âš ï¸ è¿‡åº¦ä½¿ç”¨çš„åŠ¨ä½œ: {stats['overused_actions']}")
        print(f"ğŸ† æœ€æ´»è·ƒé¡µé¢: {stats['most_active_page'][:50]}...")
        print(f"ğŸ”¥ è¯¥é¡µé¢åŠ¨ä½œæ•°: {stats['max_actions_on_page']}")
        
        if self.bug_indicators:
            print(f"ğŸ› æ½œåœ¨BugæŒ‡æ ‡: {len(self.bug_indicators)}")
            for indicator in self.bug_indicators[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3ä¸ª
                print(f"   - {indicator}")
        
        print("="*50)

    def debug_show_final_prompt(self, final_prompt: str):
        """
        è°ƒè¯•æ–¹æ³•ï¼šæ˜¾ç¤ºæœ€ç»ˆå‘é€ç»™LLMçš„å®Œæ•´promptç»“æ„
        """
        if not self.verbose:
            return
            
        print("\n" + "ğŸ” DEBUG: æœ€ç»ˆPromptç»“æ„" + "="*30)
        
        # å°è¯•åˆ†æpromptçš„å„ä¸ªéƒ¨åˆ†
        sections = final_prompt.split("\n\n")
        
        for i, section in enumerate(sections[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ªéƒ¨åˆ†é¿å…è¿‡é•¿
            if len(section.strip()) > 0:
                # è¯†åˆ«ä¸åŒç±»å‹çš„å†…å®¹
                if "ä¸“ä¸šçŸ¥è¯†åº“" in section:
                    print(f"\nğŸ“š ç¬¬{i+1}éƒ¨åˆ† - RAGçŸ¥è¯†å¢å¼º:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ" in section:
                    print(f"\nğŸ§  ç¬¬{i+1}éƒ¨åˆ† - ThinkingçŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ" in section:
                    print(f"\nğŸ“Š ç¬¬{i+1}éƒ¨åˆ† - çŠ¶æ€çŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif any(keyword in section for keyword in ["å¯æ“ä½œçš„ç•Œé¢å…ƒç´ ", "æ¢ç´¢ç­–ç•¥", "ç™»å½•æ­¥éª¤"]):
                    print(f"\nğŸ¯ ç¬¬{i+1}éƒ¨åˆ† - åŸºç¡€Prompt:")
                    print("â”€" * 40)
                    print(section[:500] + "..." if len(section) > 500 else section)
                    
                else:
                    print(f"\nğŸ“ ç¬¬{i+1}éƒ¨åˆ† - å…¶ä»–å†…å®¹:")
                    print("â”€" * 40)
                    print(section[:200] + "..." if len(section) > 200 else section)
        
        print(f"\nğŸ’¾ å®Œæ•´Promptæ€»é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        print("ğŸ” DEBUG: Promptç»“æ„åˆ†æå®Œæˆ" + "="*25 + "\n")

    def improve_action_selection_randomness(self, action_list, exploration_scores, current_url: str) -> str:
        """
        å·²åºŸå¼ƒçš„æ–¹æ³• - æ”¹ä¸ºçº¯LLMå†³ç­–åä¸å†ä½¿ç”¨
        """
        # æ­¤æ–¹æ³•å·²è¢«åˆ é™¤ï¼Œæ”¹ä¸ºçº¯LLMå†³ç­–
        return ""


def main():
    """ğŸ§  çº¯LLMå†³ç­–RAG Agentæµ‹è¯• - å®Œå…¨ä¾èµ–æ™ºèƒ½æ¨ç†"""
    # æµ‹è¯•å‚æ•°
    test_params = {
        "api_key": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "embedding_token": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "app_name": "Demo Website Testing",
        "verbose": True,  # æµ‹è¯•æ—¶å¯ç”¨è¯¦ç»†è¾“å‡º
        "max_tokens": 512,
        "temperature": 0.7,
        "clear_rag_on_init": True,
        "clear_thinking_on_init": True,
        "clear_state_on_init": True,
        "reset_llm_on_init": True,
    }

    print("ğŸ§  çº¯LLMå†³ç­–RAG Agent - å®Œå…¨ä¾èµ–æ™ºèƒ½æ¨ç†")
    print("=" * 50)
    
    try:
        # æµ‹è¯•Agentåˆå§‹åŒ–
        agent = rag_llm_agent(test_params)
        print("âœ“ Agent initialized successfully")
        
        # æµ‹è¯•é‡ç½®åŠŸèƒ½
        original_session = agent.llm.session_id
        agent.reset_for_new_test()
        new_session = agent.llm.session_id
        
        print(f"âœ“ Reset test: {'Success' if original_session != new_session else 'Failed'}")
        
        # æµ‹è¯•çº¯LLMç³»ç»Ÿ
        print("\nğŸ§  çº¯LLMå†³ç­–æ¶æ„æµ‹è¯•:")
        print("âœ“ å†³ç­–ç­–ç•¥: å®Œå…¨ä¾èµ–LLMæ™ºèƒ½æ¨ç†")
        print("âœ“ çŸ¥è¯†å¢å¼º: RAG + Thinking + StateçŸ¥è¯†åº“")
        print("âœ“ å›é€€æœºåˆ¶: éšæœºé€‰æ‹©ä¿éšœç³»ç»Ÿç¨³å®šæ€§")
        print("âœ“ æ¢ç´¢ç­–ç•¥: LLMè‡ªä¸»åˆ¤æ–­å’Œå­¦ä¹ ")
        
        # æµ‹è¯•æ¢ç´¢ç»Ÿè®¡
        print("\nğŸ“Š åˆå§‹æ¢ç´¢ç»Ÿè®¡:")
        agent.print_exploration_summary()
        
        print("=" * 50)
        print("âœ… çº¯LLMå†³ç­–ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
        print("\nğŸ§  æ¶æ„ç‰¹ç‚¹:")
        print("â€¢ ğŸ¯ å®Œå…¨LLMå†³ç­–: æ— é¢„è®¾è§„åˆ™ï¼Œå®Œå…¨æ™ºèƒ½æ¨ç†")
        print("â€¢ ğŸ“š çŸ¥è¯†åº“å¢å¼º: å¤šå±‚æ¬¡ä¸Šä¸‹æ–‡ä¿¡æ¯é›†æˆ")
        print("â€¢ ğŸ”„ å­¦ä¹ èƒ½åŠ›: é€šè¿‡å†å²ç»éªŒä¸æ–­æ”¹è¿›")
        print("â€¢ ğŸ›¡ï¸ ç®€å•å›é€€: éšæœºç­–ç•¥ä¿éšœç¨³å®šè¿è¡Œ")
        print("â€¢ ğŸ¨ çµæ´»é€‚åº”: é€‚åº”å„ç§é¡µé¢å’Œåœºæ™¯")
        print("\nğŸ’¡ ç°åœ¨è¿è¡Œ python main.py ä½“éªŒçº¯LLMå†³ç­–!")
            
    except Exception as e:
        print(f"âœ— Test failed: {e}")


if __name__ == "__main__":
    # åªæœ‰åœ¨ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰æ‰§è¡Œæµ‹è¯•
    main()
