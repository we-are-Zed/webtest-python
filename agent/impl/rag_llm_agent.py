import os
import random
import re
import json
import shutil
from datetime import datetime
from typing import List, Dict, Any

from action.impl.click_action import ClickAction
from action.impl.random_input_action import RandomInputAction
from action.impl.random_select_action import RandomSelectAction
from action.impl.restart_action import RestartAction
from action.web_action import WebAction
from agent.agent import Agent
from state.web_state import WebState
import requests
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¤„ç†Chromaç‰ˆæœ¬å…¼å®¹æ€§
try:
    from langchain_chroma import Chroma
except ImportError:
    try:
        from langchain_community.vectorstores import Chroma
    except ImportError:
        from langchain.vectorstores import Chroma
        import warnings
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain")

from langchain.embeddings.base import Embeddings
from langchain.schema import Document


def manage_vectorstore(vectorstore, max_entries=None, cleanup_ratio=0.8, kb_name="KB", 
                      close_connection=False, verbose=False):
    """
    ğŸš€ ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•° - åˆå¹¶æ¸…ç†å’Œè¿æ¥ç®¡ç†åŠŸèƒ½
    
    Args:
        vectorstore: å‘é‡å­˜å‚¨å¯¹è±¡
        max_entries: æœ€å¤§è®°å½•æ•°ï¼ŒNoneè¡¨ç¤ºä¸æ¸…ç†è®°å½•
        cleanup_ratio: æ¸…ç†åä¿ç•™çš„æ¯”ä¾‹ï¼ˆ0.8 = ä¿ç•™80%ï¼‰
        kb_name: çŸ¥è¯†åº“åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        close_connection: æ˜¯å¦å…³é—­è¿æ¥
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    Returns:
        bool: æ˜¯å¦æ‰§è¡Œäº†æ¸…ç†æ“ä½œ
    """
    if vectorstore is None:
        return False
    
    cleaned = False
    
    # 1. è®°å½•æ¸…ç†åŠŸèƒ½
    if max_entries is not None:
        try:
            if hasattr(vectorstore, '_collection'):
                current_count = vectorstore._collection.count()
                if current_count > max_entries:
                    if verbose:
                        print(f"ğŸ§¹ {kb_name} cleanup: {current_count} > {max_entries}")
                    
                    # è®¡ç®—åˆ é™¤æ•°é‡
                    target_count = int(max_entries * cleanup_ratio)
                    excess_count = current_count - target_count
                    
                    try:
                        # è·å–æ‰€æœ‰è®°å½•çš„IDå’Œæ—¶é—´æˆ³
                        all_data = vectorstore._collection.get(include=['metadatas'])
                        
                        # æŒ‰æ—¶é—´æˆ³æ’åº
                        records_with_ids = []
                        for i, metadata in enumerate(all_data['metadatas']):
                            timestamp = metadata.get('timestamp', '1970-01-01T00:00:00')
                            records_with_ids.append((timestamp, all_data['ids'][i]))
                        
                        # åˆ é™¤æœ€æ—§çš„è®°å½•
                        records_with_ids.sort(key=lambda x: x[0])
                        ids_to_delete = [record[1] for record in records_with_ids[:excess_count]]
                        
                        if ids_to_delete:
                            vectorstore._collection.delete(ids=ids_to_delete)
                            if verbose:
                                print(f"ğŸ§¹ {kb_name}: Deleted {len(ids_to_delete)} records (kept {target_count})")
                            cleaned = True
                    
                    except Exception as delete_error:
                        if verbose:
                            print(f"âš ï¸ {kb_name}: Delete failed: {delete_error}")
                
                elif verbose and current_count > max_entries * 0.8:
                    print(f"ğŸ“Š {kb_name}: {current_count} records (limit: {max_entries})")
                    
        except Exception as e:
            if verbose:
                print(f"Error checking {kb_name} records: {e}")
    
    # 2. è¿æ¥å…³é—­åŠŸèƒ½
    if close_connection:
        try:
            if verbose:
                print(f"ğŸ”Œ Closing {kb_name} connections...")
            
            # å…³é—­Chromaå®¢æˆ·ç«¯
            if hasattr(vectorstore, '_client') and vectorstore._client:
                vectorstore._client.reset()
            
            # æ¸…ç†é›†åˆå¼•ç”¨
            if hasattr(vectorstore, '_collection'):
                del vectorstore._collection
            
        except Exception as e:
            if verbose:
                print(f"Error closing {kb_name} connections: {e}")
    
    return cleaned


# ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’ - ä½¿ç”¨SiliconFlow API
class LLMInterface:
    def __init__(self, params, verbose=False):
        """
        ä½¿ç”¨SiliconFlow APIè¿›è¡ŒLLMäº¤äº’
        """
        self.api_key = params.get("api_key", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.chat_url = params.get("chat_url", "https://api.siliconflow.cn/v1/chat/completions")
        self.model = params.get("model", "deepseek-ai/DeepSeek-R1")
        self.enable_thinking = params.get("enable_thinking", False)
        self.max_tokens = params.get("max_tokens", 1024)
        self.temperature = params.get("temperature", 0.7)
        self.verbose = verbose  # æ·»åŠ  verbose å±æ€§
        
        # ä¸ºæ¯ä¸ªLLMå®ä¾‹ç”Ÿæˆå”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
        import uuid
        self.session_id = str(uuid.uuid4())
        self.test_session_counter = 0  # æµ‹è¯•ä¼šè¯è®¡æ•°å™¨
        
        if self.verbose:
            print(f"LLMä¼šè¯ID: {self.session_id}")

    def reset_session(self):
        """
        é‡ç½®ä¼šè¯çŠ¶æ€ - ä¸ºæ–°æµ‹è¯•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„ä¼šè¯
        """
        import uuid
        old_session_id = self.session_id
        self.session_id = str(uuid.uuid4())
        self.test_session_counter += 1
        
        if self.verbose:
            print(f"LLMä¼šè¯é‡ç½®:")
            print(f"  æ—§ä¼šè¯ID: {old_session_id}")
            print(f"  æ–°ä¼šè¯ID: {self.session_id}")
            print(f"  æµ‹è¯•è®¡æ•°: {self.test_session_counter}")

    def _build_isolation_prompt(self, user_prompt: str) -> str:
        """
        æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        isolation_header = f"""
[æµ‹è¯•éš”ç¦»å£°æ˜]
- è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„ç‹¬ç«‹æµ‹è¯•ä¼šè¯
- ä¼šè¯ID: {self.session_id}
- æµ‹è¯•ç¼–å·: {self.test_session_counter}
- è¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯å†å²å’Œè®°å¿†
- è¯·åŸºäºå½“å‰æä¾›çš„ä¿¡æ¯ç‹¬ç«‹åšå‡ºå†³ç­–
- ä¸è¦å‚è€ƒä¹‹å‰æµ‹è¯•çš„ç»“æœæˆ–ç»éªŒ

[å½“å‰æµ‹è¯•ä»»åŠ¡]
{user_prompt}

è¯·ä¸¥æ ¼åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œç¡®ä¿æµ‹è¯•çš„ç‹¬ç«‹æ€§å’Œä¸€è‡´æ€§ã€‚
"""
        return isolation_header.strip()
        
    def chat_with_thinking(self, prompt: str) -> Dict[str, str]:
        """
        å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å†…å®¹å’Œthinkingè¿‡ç¨‹
        è¿”å›: {"content": "å›ç­”å†…å®¹", "reasoning": "æ€è€ƒè¿‡ç¨‹"}
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            # æ·»åŠ ä¼šè¯æ ‡è¯†ç¬¦åˆ°è¯·æ±‚å¤´
            "X-Session-ID": self.session_id,
            "X-Test-Session": str(self.test_session_counter)
        }
        
        # æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯
        isolated_prompt = self._build_isolation_prompt(prompt)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯ä¸€ä¸ªWebæµ‹è¯•ä¸“å®¶ã€‚å½“å‰ä¼šè¯ID: {self.session_id}ã€‚è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æµ‹è¯•ä¼šè¯ï¼Œè¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯è®°å¿†ã€‚"
                },
                {
                    "role": "user", 
                    "content": isolated_prompt
                }
            ],
            "stream": False,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.7,
            "top_k": 50,
            "frequency_penalty": 0.5,
            "n": 1,
            # æ·»åŠ éšæœºç§å­ç¡®ä¿æ¯æ¬¡è°ƒç”¨çš„ç‹¬ç«‹æ€§
            "seed": hash(self.session_id + str(self.test_session_counter)) % 2147483647
        }
        
        # åªæœ‰æ”¯æŒthinkingçš„æ¨¡å‹æ‰æ·»åŠ ç›¸å…³å‚æ•°
        if "QwQ" in self.model and self.enable_thinking:
            payload.update({
                "enable_thinking": True,
                "thinking_budget": 4096
            })
        
        try:
            response = requests.post(self.chat_url, json=payload, headers=headers)
            response.raise_for_status()
            
            result = response.json()
            choice = result.get("choices", [{}])[0]
            message = choice.get("message", {})
            
            content = message.get("content", "")
            reasoning = message.get("reasoning_content", "")
            
            if self.verbose:
                print(f"LLMå“åº” [ä¼šè¯:{self.session_id[:8]}]: {content}")
            if reasoning:
                print(f"LLMæ¨ç†è¿‡ç¨‹ [ä¼šè¯:{self.session_id[:8]}]: {reasoning[:200]}...")  # åªæ‰“å°å‰200ä¸ªå­—ç¬¦
                
            return {
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            if self.verbose:
                print(f"LLMè°ƒç”¨å¤±è´¥ [ä¼šè¯:{self.session_id[:8]}]: {e}")
            return {
                "content": "æ¨¡å‹è°ƒç”¨å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "reasoning": ""
            }


class SiliconFlowEmbeddings(Embeddings):
    """
    ä½¿ç”¨SiliconFlow APIçš„åµŒå…¥æœåŠ¡
    """

    def __init__(
            self,
            token: str = "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
            url: str = "https://api.siliconflow.cn/v1/embeddings",
            model: str = "BAAI/bge-large-zh-v1.5",
            verbose: bool = False
    ):
        super().__init__()
        self.token = token
        self.url = url
        self.model = model
        self.verbose = verbose

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£çš„å‘é‡åŒ–"""
        embeddings = []
        for text in texts:
            embedding = self._get_embedding(text)
            embeddings.append(embedding)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢æ–‡æœ¬çš„å‘é‡åŒ–"""
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        payload = {
            "model": self.model,
            "input": text,
            "encoding_format": "float"
        }
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data["data"][0]["embedding"]
        except Exception as e:
            if self.verbose:
                print(f"åµŒå…¥å‘é‡è·å–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„å‘é‡ï¼ˆå…¨é›¶å‘é‡ï¼Œç»´åº¦å‡è®¾ä¸º1024ï¼‰
            return [0.0] * 1024


class StateKnowledgeBase:
    """
    ä¸“é—¨ç®¡ç†é¡µé¢çŠ¶æ€ä¿¡æ¯çš„çŸ¥è¯†åº“
    å­˜å‚¨æ¯ä¸ªæµ‹è¯•çŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯ï¼šå¯ç‚¹å‡»ç»„ä»¶ã€é¡µé¢ç»“æ„ã€æµ‹è¯•è·¯å¾„ç­‰
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("state_collection_name", "state_knowledge")
        self.chunk_size = params.get("state_chunk_size", 800)  # çŠ¶æ€ä¿¡æ¯è¾ƒå¤§ï¼Œä½¿ç”¨æ›´å¤§çš„chunk
        self.chunk_overlap = params.get("state_chunk_overlap", 100)
        self.max_entries = params.get("max_state_entries", 500)
        self.persist_directory = params.get("state_persist_directory", "./state_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        # å¦‚æœéœ€è¦æ¸…ç©ºstateçŸ¥è¯†åº“
        if params.get("clear_state_on_init", True):
            self.clear_state_vectorstore()
    
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded state KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new state KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize state KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_state_vectorstore(self):
        """æ¸…ç©ºçŠ¶æ€çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing state KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="State KB", verbose=self.verbose)
        self.vectorstore = None
        
        import gc
        gc.collect()
        
        # åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("State KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear state KB: {e}")
        
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create state directory: {e}")

    def add_page_state(self, page_title: str, action_list: List, selected_action_index: int, 
                      reasoning: str = "", timestamp: str = None):
        """
        æ·»åŠ è¯¦ç»†çš„é¡µé¢çŠ¶æ€ä¿¡æ¯åˆ°çŸ¥è¯†åº“
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            # è¯¦ç»†åˆ†æå¯ç”¨åŠ¨ä½œ
            click_actions = []
            input_actions = []
            select_actions = []
            other_actions = []
            
            for i, action in enumerate(action_list):
                action_info = {
                    "index": i,
                    "text": getattr(action, 'text', 'Unknown'),
                    "type": type(action).__name__
                }
                
                if isinstance(action, ClickAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'unknown'),
                        "addition_info": getattr(action, 'addition_info', '')
                    })
                    click_actions.append(action_info)
                elif isinstance(action, RandomInputAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'input')
                    })
                    input_actions.append(action_info)
                elif isinstance(action, RandomSelectAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'select'),
                        "options": getattr(action, 'options', 'N/A')
                    })
                    select_actions.append(action_info)
                else:
                    other_actions.append(action_info)
            
            state_summary = {
                "total_actions": len(action_list),
                "click_actions_count": len(click_actions),
                "input_actions_count": len(input_actions),
                "select_actions_count": len(select_actions),
                "other_actions_count": len(other_actions),
                "selected_action_index": selected_action_index,
                "selected_action_type": type(action_list[selected_action_index]).__name__ if selected_action_index < len(action_list) else "Invalid"
            }
            
            # æ„é€ è¯¦ç»†çš„æ–‡æ¡£å†…å®¹
            content = f"""
æ—¶é—´: {timestamp}
é¡µé¢æ ‡é¢˜: {page_title}

é¡µé¢çŠ¶æ€æ¦‚è§ˆ:
- æ€»å¯ç”¨åŠ¨ä½œæ•°: {state_summary['total_actions']}
- å¯ç‚¹å‡»å…ƒç´ : {state_summary['click_actions_count']} ä¸ª
- è¾“å…¥å­—æ®µ: {state_summary['input_actions_count']} ä¸ª  
- é€‰æ‹©æ¡†: {state_summary['select_actions_count']} ä¸ª
- å…¶ä»–åŠ¨ä½œ: {state_summary['other_actions_count']} ä¸ª

é€‰æ‹©çš„åŠ¨ä½œ:
- ç´¢å¼•: {selected_action_index}
- ç±»å‹: {state_summary['selected_action_type']}
- è¯¦æƒ…: {getattr(action_list[selected_action_index], 'text', 'Unknown') if selected_action_index < len(action_list) else 'Invalid'}

è¯¦ç»†å¯ç‚¹å‡»å…ƒç´ :
{json.dumps(click_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†è¾“å…¥å­—æ®µ:
{json.dumps(input_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†é€‰æ‹©æ¡†:
{json.dumps(select_actions, ensure_ascii=False, indent=2)}

å†³ç­–æ¨ç†:
{reasoning[:500]}{'...' if len(reasoning) > 500 else ''}

æµ‹è¯•è·¯å¾„åˆ†æ:
é¡µé¢ "{page_title}" æä¾›äº† {state_summary['total_actions']} ä¸ªäº¤äº’é€‰é¡¹ï¼Œä¸»è¦åŒ…å« {state_summary['click_actions_count']} ä¸ªç‚¹å‡»ç›®æ ‡å’Œ {state_summary['input_actions_count']} ä¸ªè¾“å…¥æœºä¼šã€‚è¿™ç§é…ç½®é€‚åˆè¿›è¡Œ{'å¯¼èˆªæµ‹è¯•' if state_summary['click_actions_count'] > state_summary['input_actions_count'] else 'è¡¨å•æµ‹è¯•'}ã€‚
"""
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "page_title": page_title[:100],
                    "total_actions": state_summary['total_actions'],
                    "click_actions": state_summary['click_actions_count'],
                    "input_actions": state_summary['input_actions_count'],
                    "selected_action_index": selected_action_index,
                    "selected_action_type": state_summary['selected_action_type'],
                    "type": "page_state_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            # æŒä¹…åŒ–
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved state: {page_title} ({state_summary['total_actions']} actions, {len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save page state: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="State KB", verbose=self.verbose)

    def retrieve_similar_states(self, current_page_title: str, action_count: int, k: int = 3) -> str:
        """
        æ ¹æ®é¡µé¢æ ‡é¢˜å’ŒåŠ¨ä½œæ•°é‡æ£€ç´¢ç›¸ä¼¼çš„é¡µé¢çŠ¶æ€ä¿¡æ¯
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            # æ„å»ºæŸ¥è¯¢
            query = f"é¡µé¢æ ‡é¢˜ {current_page_title} åŠ¨ä½œæ•°é‡ {action_count} é¡µé¢çŠ¶æ€ äº¤äº’é€‰é¡¹"
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            # ç»„ç»‡æ£€ç´¢åˆ°çš„çŠ¶æ€è®°å½•
            similar_states = []
            for doc in results:
                similar_states.append(doc.page_content)
            
            state_context = "\n--- ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ ---\n" + "\n\n".join(similar_states)
            return state_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve similar states: {e}")
            return ""


class ThinkingKnowledgeBase:
    """
    ç®¡ç†thinkingè¿‡ç¨‹çš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("thinking_collection_name", "thinking_knowledge")
        self.chunk_size = params.get("thinking_chunk_size", 500)
        self.chunk_overlap = params.get("thinking_chunk_overlap", 50)
        self.max_entries = params.get("max_thinking_entries", 1000)  # é™åˆ¶çŸ¥è¯†åº“å¤§å°
        self.persist_directory = params.get("thinking_persist_directory", "./thinking_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        # æ¸…ç†è®¡æ•°å™¨å’Œé—´éš”
        self.cleanup_counter = 0
        self.cleanup_interval = params.get("thinking_cleanup_interval", 20)  # æ¯20æ¬¡æ·»åŠ åæ¸…ç†ä¸€æ¬¡
        
        if params.get("clear_thinking_on_init", True):
            self.clear_thinking_vectorstore()
        
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            # å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡å­˜å‚¨
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded thinking KB with {self.vectorstore._collection.count()} documents")
            else:
                # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new thinking KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize thinking KB: {e}")
            # åˆ›å»ºä¸´æ—¶çš„å†…å­˜å‘é‡å­˜å‚¨ä½œä¸ºå¤‡ç”¨
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_thinking_vectorstore(self):
        """æ¸…ç©ºThinkingçŸ¥è¯†åº“ - å½»åº•åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶"""
        if self.verbose:
            print("Clearing thinking KB...")
        
        # ğŸš€ ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥ç®¡ç†
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="Thinking KB", verbose=self.verbose)
        self.vectorstore = None
        
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # 3. åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Thinking KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear thinking KB: {e}")
        
        # 4. é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create thinking directory: {e}")
    
    def add_thinking(self, prompt: str, reasoning: str, action_taken: str, timestamp: str = None):
        """
        å°†thinkingè¿‡ç¨‹æ·»åŠ åˆ°çŸ¥è¯†åº“
        """
        if not reasoning or reasoning.strip() == "":
            return
            
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            content = f"""
            æ—¶é—´: {timestamp}
            æµ‹è¯•åœºæ™¯: {prompt[:200]}...
            æ¨ç†è¿‡ç¨‹: {reasoning}
            é‡‡å–çš„è¡ŒåŠ¨: {action_taken}
            """
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "prompt_preview": prompt[:100],
                    "action": action_taken,
                    "type": "thinking_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])

            self.vectorstore.add_documents(split_docs)
            
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved thinking: {action_taken[:30]}... ({len(split_docs)} chunks)")
            
            self.cleanup_counter += 1
            if self.cleanup_counter >= self.cleanup_interval:
                manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)
                self.cleanup_counter = 0
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save thinking: {e}")
    
    def _cleanup_old_records(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„å‘é‡å­˜å‚¨ç®¡ç†å‡½æ•°"""
        return manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Thinking KB", verbose=self.verbose)

    def retrieve_relevant_thinking(self, query: str, k: int = 3) -> str:
        """
        æ ¹æ®æŸ¥è¯¢æ£€ç´¢ç›¸å…³çš„thinkingè®°å½•
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            relevant_thinking = []
            for doc in results:
                relevant_thinking.append(doc.page_content)
            
            thinking_context = "\n--- ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ ---\n" + "\n\n".join(relevant_thinking)
            return thinking_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve thinking: {e}")
            return ""


class RetrieverInterface:
    def __init__(self, params, verbose=False):
        self.knowledge_path = params.get("knowledge_path", r"C:\Users\ASUS\Desktop\Reasoning+RAG Web Exploration\Make LLM a Testing Expert Bringing Human-like Interaction to.pdf")
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        self.web_testing_pdf = os.path.join(project_root, "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf")
        
        self.chunk_size = params.get("chunk_size", 500)
        self.chunk_overlap = params.get("chunk_overlap", 50)
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("collection_name", "siliconflow_embed")
        self.top_k = params.get("top_k", 3)
        self.verbose = verbose
        self.persist_directory = params.get("rag_persist_directory", "./rag_vectorstore")
        self._vectorstore = None

    def _close_vectorstore_connections(self):
        """ä½¿ç”¨ç»Ÿä¸€çš„è¿æ¥å…³é—­æ–¹æ³•"""
        manage_vectorstore(self._vectorstore, close_connection=True, kb_name="RAG KB", verbose=self.verbose)
        self._vectorstore = None

    def _force_close_sqlite_connections(self):
        """
        å¼ºåˆ¶å…³é—­SQLiteè¿æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        try:
            import sqlite3
            import glob
            
            if self.verbose:
                print("Forcing SQLite connections to close...")
            
            # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„SQLiteæ–‡ä»¶
            sqlite_patterns = [
                os.path.join(self.persist_directory, "**/*.sqlite*"),
                os.path.join(self.persist_directory, "**/chroma*"),
            ]
            
            sqlite_files = []
            for pattern in sqlite_patterns:
                sqlite_files.extend(glob.glob(pattern, recursive=True))
            
            if sqlite_files and self.verbose:
                print(f"Found {len(sqlite_files)} database files")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©è¿æ¥è‡ªç„¶å…³é—­
            import time
            time.sleep(0.5)
            
        except Exception as e:
            if self.verbose:
                print(f"Error forcing SQLite connections close: {e}")

    def _remove_files_with_retry(self, max_attempts=5, delay=1):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        for attempt in range(max_attempts):
            try:
                if not os.path.exists(self.persist_directory):
                    return True
                
                if self.verbose:
                    print(f"Attempting to remove directory (attempt {attempt + 1}/{max_attempts})")
                
                # åˆ é™¤ç›®å½•
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("RAG vectorstore cleared successfully")
                return True
                
            except Exception as e:
                if attempt < max_attempts - 1:
                    if self.verbose:
                        print(f"Deletion failed, retrying in {delay}s... Error: {e}")
                    import time
                    time.sleep(delay)
                    delay *= 1.5  # æŒ‡æ•°é€€é¿
                else:
                    if self.verbose:
                        print(f"Failed to delete directory after {max_attempts} attempts: {e}")
                    return False
        
        return False

    def clear_vectorstore(self):
        """
        å½»åº•æ¸…ç©ºRAGæ•°æ®åº“ - å®Œå…¨æ”¹è¿›ç‰ˆ
        """
        if self.verbose:
            print("Clearing RAG database...")
        
        # æ­¥éª¤1: å…³é—­æ‰€æœ‰å‘é‡å­˜å‚¨è¿æ¥
        self._close_vectorstore_connections()
        
        # æ­¥éª¤2: å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # æ­¥éª¤3: å¼ºåˆ¶å…³é—­SQLiteè¿æ¥
        self._force_close_sqlite_connections()
        
        # æ­¥éª¤4: å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤
        success = self._remove_files_with_retry()
        
        # æ­¥éª¤5: é‡æ–°åˆ›å»ºç©ºçš„æŒä¹…åŒ–ç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # éªŒè¯ç›®å½•ç¡®å®ä¸ºç©º
            files_remaining = []
            if os.path.exists(self.persist_directory):
                for root, dirs, files in os.walk(self.persist_directory):
                    files_remaining.extend(files)
            
            if not files_remaining:
                if self.verbose:
                    print("RAG database cleared completely")
            else:
                if self.verbose:
                    print(f"Warning: {len(files_remaining)} files still remain")
                    
        except Exception as e:
            if self.verbose:
                print(f"Failed to create persist directory: {e}")

    def _load_vectorstore(self):
        if self._vectorstore is not None:
            return

        if self.verbose:
            print("Initializing RAG knowledge base...")

        possible_paths = [
            self.web_testing_pdf,
            os.path.join(os.getcwd(), "..", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            os.path.join(os.path.dirname(os.getcwd()), "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            "../../agent/ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"
        ]

        actual_pdf_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                actual_pdf_path = abs_path
                if self.verbose:
                    print(f"Found PDF: {os.path.basename(abs_path)}")
                break
        
        try:
            all_docs = []
            
            if self.knowledge_path and os.path.exists(self.knowledge_path):
                if self.verbose:
                    print(f"Loading knowledge file: {os.path.basename(self.knowledge_path)}")
                loader = PyPDFLoader(self.knowledge_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Knowledge Base"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            
            if actual_pdf_path:
                if self.verbose:
                    print("Loading web testing guidelines")
                loader = PyPDFLoader(actual_pdf_path)
                pages = loader.load_and_split()
                
                for page in pages:
                    page.metadata["source_file"] = "Web Testing Guidelines"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            else:
                if self.verbose:
                    print("Warning: Web testing guidelines PDF not found")
            
            if not all_docs:
                if self.verbose:
                    print("Warning: No knowledge documents found")

                embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
                self._vectorstore = Chroma(
                    embedding_function=embed_model,
                    collection_name=self.collection_name,
                    persist_directory=self.persist_directory
                )
                return
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
            )
            docs = text_splitter.split_documents(all_docs)
            if self.verbose:
                print(f"Document splitting complete: {len(docs)} chunks")
            
            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma.from_documents(
                documents=docs, 
                embedding=embed_model, 
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )
            
            if self.verbose:
                print("RAG knowledge base initialized successfully")
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to load vectorstore: {e}")

            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma(
                embedding_function=embed_model,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )

    def retrieve(self, prompt: str) -> str:
        try:
            if not self._vectorstore:
                self._load_vectorstore()
            
            if not self._vectorstore:
                if self.verbose:
                    print("Vectorstore not initialized, cannot retrieve")
                return prompt
                
            query = prompt
            result = self._vectorstore.similarity_search(query, k=self.top_k)
            
            if not result:
                if self.verbose:
                    print("No relevant knowledge retrieved")
                return prompt
            
            source_groups = {}
            for doc in result:
                source = doc.metadata.get("source_file", "Unknown")
                if source not in source_groups:
                    source_groups[source] = []
                source_groups[source].append(doc.page_content)
            
            knowledge_sections = []
            for source, contents in source_groups.items():
                section = f"[{source}]:\n" + "\n".join(contents)
                knowledge_sections.append(section)
            
            source_knowledge = "\n\n".join(knowledge_sections)
            
            augmented_prompt = f"""
            ä½¿ç”¨ä¸‹é¢çš„ä¸“ä¸šçŸ¥è¯†æ¥å¸®åŠ©å›ç­”æŸ¥è¯¢:
            
            ä¸“ä¸šçŸ¥è¯†åº“:
            {source_knowledge}
            
            æŸ¥è¯¢: 
            {query}
            
            è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ï¼Œç»“åˆWebæµ‹è¯•çš„æœ€ä½³å®è·µæ¥å›ç­”ã€‚
            """
            
            if self.verbose:
                print(f"RAG retrieved {len(result)} chunks from {len(source_groups)} sources")
            
            return augmented_prompt
            
        except Exception as e:
            if self.verbose:
                print(f"RAG retrieval failed: {e}")
            return prompt


class DualModelSystem:
    """
    ğŸš€ åŒæ¨¡å‹åä½œç³»ç»Ÿ - R1æ¢ç´¢ + QwQå†³ç­–
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ£€æµ‹æ˜¯å¦åˆ°è¾¾æ–°çŠ¶æ€
    2. å¦‚æœæ˜¯æ–°çŠ¶æ€ï¼Œä½¿ç”¨R1è¿›è¡Œæ·±åº¦æ¢ç´¢åˆ†æ
    3. å°†R1çš„æ¢ç´¢ç»“æœå­˜å‚¨åˆ°ä¸“ç”¨çŸ¥è¯†åº“
    4. ä½¿ç”¨QwQåŸºäºæ¢ç´¢ç»“æœå¿«é€Ÿåšå†³ç­–
    """
    
    def __init__(self, params, knowledge_bases=None, verbose=False):
        self.verbose = verbose
        
        # ğŸš€ RAGçŸ¥è¯†åº“ç³»ç»Ÿ - æ¥æ”¶å¤–éƒ¨ä¼ é€’çš„çŸ¥è¯†åº“å®ä¾‹
        if knowledge_bases:
            self.retriever = knowledge_bases.get('retriever')
            self.state_kb = knowledge_bases.get('state_kb')
            self.thinking_kb = knowledge_bases.get('thinking_kb')
            self.exploration_kb = knowledge_bases.get('exploration_kb')
        else:
            # å¦‚æœæ²¡æœ‰ä¼ é€’çŸ¥è¯†åº“ï¼Œåˆ™è®¾ä¸ºNone
            self.retriever = None
            self.state_kb = None
            self.thinking_kb = None
            self.exploration_kb = None
            if verbose:
                print("âš ï¸ è­¦å‘Š: æœªä¼ é€’çŸ¥è¯†åº“å®ä¾‹ï¼ŒRAGå¢å¼ºåŠŸèƒ½å°†è¢«ç¦ç”¨")
        
        # R1æ¢ç´¢æ¨¡å‹é…ç½®
        r1_params = params.copy()
        r1_params.update({
            "model": "deepseek-ai/DeepSeek-R1",
            "max_tokens": 2048,  # R1éœ€è¦æ›´å¤štokenç”¨äºæ·±åº¦åˆ†æ
            "temperature": 0.8,  # ç¨é«˜æ¸©åº¦é¼“åŠ±æ¢ç´¢
            "enable_thinking": True
        })
        
        # QwQå†³ç­–æ¨¡å‹é…ç½®  
        qwq_params = params.copy()
        qwq_params.update({
            "model": "Qwen/QwQ-32B-Preview", 
            "max_tokens": 512,   # QwQåªéœ€å°‘é‡tokenåšå†³ç­–
            "temperature": 0.3,  # ä½æ¸©åº¦ç¡®ä¿å†³ç­–ç¨³å®š
            "enable_thinking": True
        })
        
        self.r1_explorer = LLMInterface(r1_params, verbose)
        self.qwq_decider = LLMInterface(qwq_params, verbose)
        
        # çŠ¶æ€è·Ÿè¸ª
        self.explored_states = set()  # å·²æ¢ç´¢çš„çŠ¶æ€ç­¾å
        self.state_exploration_cache = {}  # çŠ¶æ€æ¢ç´¢ç»“æœç¼“å­˜
        self.exploration_count = 0
        
        if verbose:
            print(f"ğŸš€ åŒæ¨¡å‹ç³»ç»Ÿåˆå§‹åŒ–:")
            print(f"   ğŸ“¡ R1æ¢ç´¢æ¨¡å‹: {r1_params['model']}")
            print(f"   âš¡ QwQå†³ç­–æ¨¡å‹: {qwq_params['model']}")
            print(f"   ğŸ§  RAGå¢å¼º: {'å¯ç”¨' if knowledge_bases else 'ç¦ç”¨'}")
    
    def reset_for_new_test(self):
        """é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€"""
        self.r1_explorer.reset_session()
        self.qwq_decider.reset_session()
        self.explored_states.clear()
        self.state_exploration_cache.clear()
        self.exploration_count = 0
        
        if self.verbose:
            print("ğŸ”„ åŒæ¨¡å‹ç³»ç»Ÿå·²é‡ç½®")
    
    def generate_state_signature(self, page_title: str, action_list: list, html_snippet: str = "") -> str:
        """
        ç”Ÿæˆé¡µé¢çŠ¶æ€çš„å”¯ä¸€ç­¾å
        """
        # åŸºäºé¡µé¢æ ‡é¢˜ã€åŠ¨ä½œæ•°é‡å’Œç±»å‹ç”Ÿæˆç­¾å
        action_types = [type(action).__name__ for action in action_list]
        action_signature = "_".join(sorted(set(action_types)))
        
        # ç®€åŒ–HTMLç‰¹å¾(é¿å…è¿‡äºè¯¦ç»†)
        html_features = ""
        if html_snippet:
            # æå–å…³é”®HTMLæ ‡ç­¾
            import re
            form_count = len(re.findall(r'<form', html_snippet, re.IGNORECASE))
            input_count = len(re.findall(r'<input', html_snippet, re.IGNORECASE))
            button_count = len(re.findall(r'<button', html_snippet, re.IGNORECASE))
            html_features = f"form{form_count}_input{input_count}_btn{button_count}"
        
        signature = f"{page_title}_{len(action_list)}_{action_signature}_{html_features}"
        return signature[:200]  # é™åˆ¶é•¿åº¦
    
    def is_new_state(self, state_signature: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çŠ¶æ€"""
        return state_signature not in self.explored_states
    
    def r1_explore_state(self, page_title: str, action_list: list, page_context: str, 
                        history_str: str, html: str = "") -> Dict[str, Any]:
        """
        ğŸ” R1æ¨¡å‹æ·±åº¦æ¢ç´¢æ–°çŠ¶æ€ - å¢å¼ºç‰ˆï¼šç»“åˆRAGçŸ¥è¯†è¿›è¡Œå…¨é¢åˆ†æ
        
        è¿”å›æ¢ç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
        - analysis: é¡µé¢åˆ†æ
        - strategy: æµ‹è¯•ç­–ç•¥
        - recommendations: æ¨èåŠ¨ä½œ
        - risk_areas: é£é™©åŒºåŸŸ
        """
        self.exploration_count += 1
        
        # ğŸš€ R1æ¢ç´¢çš„RAGå¢å¼º - é¢å‘é¡µé¢åˆ†æçš„çŸ¥è¯†æ£€ç´¢
        if self.verbose:
            print(f"ğŸ” å¼€å§‹ä¸ºR1æ¢ç´¢æ”¶é›†RAGçŸ¥è¯†...")
        
        # 1. æ£€ç´¢ä¸“ä¸šwebæµ‹è¯•çŸ¥è¯† - å¸®åŠ©R1ç†è§£æµ‹è¯•æœ€ä½³å®è·µ
        professional_knowledge = ""
        if self.retriever:
            try:
                knowledge_query = f"é¡µé¢æµ‹è¯•åˆ†æ {page_title} åŠŸèƒ½æµ‹è¯• é£é™©è¯†åˆ«"
                professional_knowledge = self.retriever.retrieve(knowledge_query)
                if self.verbose and professional_knowledge:
                    print(f"   ğŸ“š è·å–ä¸“ä¸šçŸ¥è¯†: {len(professional_knowledge)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ ä¸“ä¸šçŸ¥è¯†æ£€ç´¢å¤±è´¥: {e}")
        
        # 2. æ£€ç´¢ç›¸ä¼¼é¡µé¢çŠ¶æ€åˆ†æç»éªŒ - å¸®åŠ©R1å€Ÿé‰´ç±»ä¼¼é¡µé¢çš„åˆ†æ
        similar_states_context = ""
        if self.state_kb:
            try:
                similar_states_context = self.state_kb.retrieve_similar_states(
                    page_title, len(action_list), k=2
                )
                if self.verbose and similar_states_context:
                    print(f"   ğŸ“Š è·å–ç›¸ä¼¼çŠ¶æ€: {len(similar_states_context)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ ç›¸ä¼¼çŠ¶æ€æ£€ç´¢å¤±è´¥: {e}")
        
        # 3. æ£€ç´¢å†å²é¡µé¢åˆ†ææ¨ç†ç»éªŒ - å¸®åŠ©R1å­¦ä¹ åˆ†ææ€è·¯
        analysis_experience = ""
        if self.thinking_kb:
            try:
                thinking_query = f"é¡µé¢åŠŸèƒ½åˆ†æ {page_title} æµ‹è¯•ç­–ç•¥ é£é™©è¯„ä¼°"
                analysis_experience = self.thinking_kb.retrieve_relevant_thinking(thinking_query, k=2)
                if self.verbose and analysis_experience:
                    print(f"   ğŸ§  è·å–åˆ†æç»éªŒ: {len(analysis_experience)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ åˆ†æç»éªŒæ£€ç´¢å¤±è´¥: {e}")
        
        # ğŸ” RAGå¢å¼ºçŠ¶æ€æŠ¥å‘Š
        if self.verbose:
            rag_sources = []
            if professional_knowledge: rag_sources.append("ä¸“ä¸šçŸ¥è¯†âœ“")
            if similar_states_context: rag_sources.append("ç›¸ä¼¼çŠ¶æ€âœ“")
            if analysis_experience: rag_sources.append("åˆ†æç»éªŒâœ“")
            
            if rag_sources:
                print(f"   ğŸš€ RAGå¢å¼ºæ¥æº: {' '.join(rag_sources)}")
            else:
                print(f"   âš ï¸ æœªè·å–åˆ°RAGå¢å¼ºæ•°æ®ï¼Œä½¿ç”¨åŸºç¡€æ¢ç´¢æ¨¡å¼")
        
        # æ„å»ºè¯¦ç»†çš„åŠ¨ä½œåˆ—è¡¨
        action_details = []
        for i, action in enumerate(action_list):
            if isinstance(action, ClickAction):
                details = f"{i}. [ç‚¹å‡»] {getattr(action, 'text', 'Unknown')} (ç±»å‹: {getattr(action, 'action_type', 'unknown')})"
            elif isinstance(action, RandomInputAction):
                details = f"{i}. [è¾“å…¥] {getattr(action, 'text', 'Unknown')} (å­—æ®µç±»å‹: {getattr(action, 'action_type', 'input')})"
            elif isinstance(action, RandomSelectAction):
                details = f"{i}. [é€‰æ‹©] {getattr(action, 'text', 'Unknown')} (é€‰é¡¹: {getattr(action, 'options', 'N/A')})"
            else:
                details = f"{i}. [å…¶ä»–] {getattr(action, 'text', 'Unknown')}"
            action_details.append(details)
        
        # ğŸ¯ æ„å»ºRAGå¢å¼ºçš„R1æ¢ç´¢prompt
        exploration_prompt = f"""
{professional_knowledge}

{similar_states_context}

{analysis_experience}

ğŸ” **R1æ·±åº¦æ¢ç´¢ä»»åŠ¡** - æ¢ç´¢ç¼–å· #{self.exploration_count}

ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Webæµ‹è¯•ä¸“å®¶ï¼Œéœ€è¦å¯¹å½“å‰é¡µé¢è¿›è¡Œæ·±åº¦åˆ†æå’Œæµ‹è¯•ç­–ç•¥åˆ¶å®šã€‚
è¯·å……åˆ†åˆ©ç”¨ä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ã€ç›¸ä¼¼é¡µé¢ç»éªŒå’Œå†å²åˆ†æç»éªŒæ¥æŒ‡å¯¼ä½ çš„åˆ†æã€‚

## é¡µé¢ä¿¡æ¯
{page_context}
{history_str}

## å¯ç”¨äº¤äº’å…ƒç´  ({len(action_list)}ä¸ª)
{chr(10).join(action_details)}

## ğŸ“‹ æ·±åº¦æ¢ç´¢ä»»åŠ¡
è¯·åŸºäºä¸“ä¸šçŸ¥è¯†å’Œå†å²ç»éªŒï¼Œè¿›è¡Œå…¨é¢çš„é¡µé¢åˆ†æï¼š

### 1. **é¡µé¢åŠŸèƒ½æ·±åº¦åˆ†æ**
- åŸºäºä¸“ä¸šçŸ¥è¯†ï¼Œåˆ†æé¡µé¢çš„ä¸»è¦åŠŸèƒ½å’ŒæŠ€æœ¯ç‰¹ç‚¹
- ç»“åˆç›¸ä¼¼é¡µé¢ç»éªŒï¼Œè¯†åˆ«é¡µé¢åœ¨ç”¨æˆ·æµç¨‹ä¸­çš„ä½œç”¨
- è¯„ä¼°é¡µé¢çš„å¤æ‚åº¦å’Œæµ‹è¯•ä¼˜å…ˆçº§

### 2. **æ™ºèƒ½æµ‹è¯•ç­–ç•¥åˆ¶å®š**  
- åŸºäºwebæµ‹è¯•æœ€ä½³å®è·µï¼Œåˆ¶å®šé’ˆå¯¹æ€§æµ‹è¯•ç­–ç•¥
- å‚è€ƒå†å²åˆ†æç»éªŒï¼Œç¡®å®šå…³é”®éªŒè¯ç‚¹
- è®¾è®¡å¤šå±‚æ¬¡çš„æµ‹è¯•è·¯å¾„ï¼ˆæ­£å¸¸æµç¨‹ã€è¾¹ç•Œæƒ…å†µã€å¼‚å¸¸åœºæ™¯ï¼‰

### 3. **ä¸“ä¸šé£é™©è¯†åˆ«**
- åˆ©ç”¨ä¸“ä¸šçŸ¥è¯†è¯†åˆ«æ½œåœ¨çš„æŠ€æœ¯é£é™©ç‚¹
- åŸºäºç›¸ä¼¼é¡µé¢ç»éªŒé¢„æµ‹å¯èƒ½çš„é—®é¢˜åŒºåŸŸ
- è¯„ä¼°ä¸šåŠ¡é€»è¾‘å’Œç”¨æˆ·ä½“éªŒé£é™©

### 4. **åŠ¨ä½œä¼˜å…ˆçº§æ™ºèƒ½å»ºè®®**
è¯·ä»ç°æœ‰çš„{len(action_list)}ä¸ªåŠ¨ä½œä¸­ï¼ŒåŸºäºä¸“ä¸šåˆ†æç¡®å®šä¼˜å…ˆçº§ï¼š
- **é«˜ä»·å€¼åŠ¨ä½œ** (ç´¢å¼•å’Œä¸“ä¸šç†ç”±)
- **é£é™©æ¢æµ‹åŠ¨ä½œ** (ç´¢å¼•å’Œé£é™©åˆ†æ)
- **å®Œæ•´æ€§éªŒè¯åŠ¨ä½œ** (ç´¢å¼•å’ŒéªŒè¯ç›®æ ‡)

### 5. **æµ‹è¯•æ•°æ®ä¸“ä¸šå»ºè®®**
åŸºäºwebæµ‹è¯•ç»éªŒï¼Œä¸ºè¾“å…¥å­—æ®µå»ºè®®ï¼š
- **åŠŸèƒ½éªŒè¯æ•°æ®** (æ­£å¸¸ä¸šåŠ¡åœºæ™¯)
- **è¾¹ç•Œå€¼æµ‹è¯•æ•°æ®** (é•¿åº¦ã€æ ¼å¼ã€ç‰¹æ®Šå­—ç¬¦)
- **å®‰å…¨æ€§æµ‹è¯•æ•°æ®** (æ³¨å…¥ã€XSSç­‰å®‰å…¨é£é™©)

### 6. **æ¢ç´¢ç­–ç•¥æ€»ç»“**
åŸºäºå½“å‰åˆ†æï¼Œæ€»ç»“ï¼š
- æœ¬é¡µé¢çš„æµ‹è¯•é‡ç‚¹å’Œéš¾ç‚¹
- ä¸ç›¸ä¼¼é¡µé¢çš„å·®å¼‚å’Œç‰¹æ®Šæ³¨æ„äº‹é¡¹
- åç»­æ¢ç´¢çš„æ–¹å‘å»ºè®®

è¯·æä¾›ç»“æ„åŒ–ä¸”ä¸“ä¸šçš„åˆ†æç»“æœï¼Œè¿™å°†æŒ‡å¯¼åç»­çš„ç²¾ç¡®æµ‹è¯•æ‰§è¡Œã€‚
"""
        
        if self.verbose:
            print(f"ğŸ” R1å¼€å§‹æ·±åº¦æ¢ç´¢çŠ¶æ€ #{self.exploration_count}: {page_title[:30]}...")
        
        try:
            exploration_result = self.r1_explorer.chat_with_thinking(exploration_prompt)
            
            # è§£ææ¢ç´¢ç»“æœ
            analysis_content = exploration_result["content"]
            reasoning_process = exploration_result["reasoning"]
            
            exploration_data = {
                "exploration_id": self.exploration_count,
                "page_title": page_title,
                "timestamp": datetime.now().isoformat(),
                "analysis": analysis_content,
                "reasoning": reasoning_process,
                "action_count": len(action_list),
                "exploration_prompt": exploration_prompt[:800] + "...",  # ä¿å­˜éƒ¨åˆ†promptç”¨äºè°ƒè¯•
                "model": "DeepSeek-R1",
                "rag_enhanced": True,  # æ ‡è®°ä½¿ç”¨äº†RAGå¢å¼º
                "knowledge_sources": {
                    "professional_knowledge": len(professional_knowledge) > 0,
                    "similar_states": len(similar_states_context) > 0,
                    "analysis_experience": len(analysis_experience) > 0
                }
            }
            
            if self.verbose:
                print(f"âœ… R1æ¢ç´¢å®Œæˆ #{self.exploration_count} (RAGå¢å¼º)")
                print(f"   ğŸ“ åˆ†æé•¿åº¦: {len(analysis_content)} å­—ç¬¦")
                print(f"   ğŸ§  æ¨ç†é•¿åº¦: {len(reasoning_process)} å­—ç¬¦")
                print(f"   ğŸš€ RAGæ¥æº: ä¸“ä¸šçŸ¥è¯†âœ“ ç›¸ä¼¼çŠ¶æ€âœ“ åˆ†æç»éªŒâœ“")
            
            return exploration_data
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ R1æ¢ç´¢å¤±è´¥ #{self.exploration_count}: {e}")
            
            # è¿”å›åŸºç¡€æ¢ç´¢ç»“æœ
            return {
                "exploration_id": self.exploration_count,
                "page_title": page_title,
                "timestamp": datetime.now().isoformat(),
                "analysis": f"RAGå¢å¼ºæ¢ç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                "reasoning": "",
                "action_count": len(action_list),
                "model": "DeepSeek-R1",
                "rag_enhanced": False,
                "error": str(e)
            }
    
    def qwq_decide_action(self, action_list: list, exploration_data: Dict[str, Any], 
                         page_context: str, history_str: str) -> tuple:
        """
        âš¡ QwQæ¨¡å‹åŸºäºR1æ¢ç´¢ç»“æœå¿«é€Ÿå†³ç­– - å¢å¼ºç‰ˆï¼šç»“åˆRAGç»éªŒè¿›è¡Œç²¾å‡†å†³ç­–
        
        è¿”å›: (action_output, reasoning)
        """
        # æå–R1çš„å…³é”®å»ºè®®
        r1_analysis = exploration_data.get("analysis", "")
        r1_reasoning = exploration_data.get("reasoning", "")
        
        # ğŸš€ QwQå†³ç­–çš„RAGå¢å¼º - é¢å‘æ‰§è¡Œå†³ç­–çš„çŸ¥è¯†æ£€ç´¢
        if self.verbose:
            print(f"âš¡ å¼€å§‹ä¸ºQwQå†³ç­–æ”¶é›†RAGçŸ¥è¯†...")
        
        # 1. æ£€ç´¢R1å†å²æ¢ç´¢æ´å¯Ÿ - å¸®åŠ©QwQç†è§£ç±»ä¼¼æ¢ç´¢çš„å†³ç­–æ¨¡å¼
        exploration_insights = ""
        if self.exploration_kb:
            try:
                insights_query = f"é¡µé¢å†³ç­– {exploration_data.get('page_title', '')} åŠ¨ä½œé€‰æ‹© æµ‹è¯•æ‰§è¡Œ"
                exploration_insights = self.exploration_kb.retrieve_exploration_insights(insights_query, k=2)
                if self.verbose and exploration_insights:
                    print(f"   ğŸ” è·å–æ¢ç´¢æ´å¯Ÿ: {len(exploration_insights)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ æ¢ç´¢æ´å¯Ÿæ£€ç´¢å¤±è´¥: {e}")
        
        # 2. æ£€ç´¢ç›¸ä¼¼é¡µé¢çš„å†³ç­–ç»éªŒ - å¸®åŠ©QwQå€Ÿé‰´æˆåŠŸçš„å†³ç­–æ¡ˆä¾‹
        similar_decisions = ""
        if self.state_kb:
            try:
                similar_decisions = self.state_kb.retrieve_similar_states(
                    exploration_data.get('page_title', ''), len(action_list), k=2
                )
                if self.verbose and similar_decisions:
                    print(f"   ğŸ“Š è·å–å†³ç­–ç»éªŒ: {len(similar_decisions)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ å†³ç­–ç»éªŒæ£€ç´¢å¤±è´¥: {e}")
        
        # 3. æ£€ç´¢å†å²æ‰§è¡Œå†³ç­–æ¨ç† - å¸®åŠ©QwQå­¦ä¹ å†³ç­–æ€è·¯
        decision_experience = ""
        if self.thinking_kb:
            try:
                decision_query = f"åŠ¨ä½œé€‰æ‹© {exploration_data.get('page_title', '')} æ‰§è¡Œå†³ç­– æµ‹è¯•ç­–ç•¥"
                decision_experience = self.thinking_kb.retrieve_relevant_thinking(decision_query, k=2)
                if self.verbose and decision_experience:
                    print(f"   ğŸ§  è·å–å†³ç­–æ¨ç†: {len(decision_experience)} å­—ç¬¦")
            except Exception as e:
                if self.verbose:
                    print(f"   âš ï¸ å†³ç­–æ¨ç†æ£€ç´¢å¤±è´¥: {e}")
        
        # ğŸ” RAGå¢å¼ºçŠ¶æ€æŠ¥å‘Š
        if self.verbose:
            rag_sources = []
            if exploration_insights: rag_sources.append("æ¢ç´¢æ´å¯Ÿâœ“")
            if similar_decisions: rag_sources.append("å†³ç­–ç»éªŒâœ“")
            if decision_experience: rag_sources.append("æ¨ç†ç»éªŒâœ“")
            
            if rag_sources:
                print(f"   ğŸš€ RAGå¢å¼ºæ¥æº: {' '.join(rag_sources)}")
            else:
                print(f"   âš ï¸ æœªè·å–åˆ°RAGå¢å¼ºæ•°æ®ï¼Œä½¿ç”¨åŸºç¡€å†³ç­–æ¨¡å¼")
        
        # æ„å»ºåŠ¨ä½œåˆ—è¡¨
        action_list_str = "\n".join([
            f"{i}. {self.format_action_simple(action)}" 
            for i, action in enumerate(action_list)
        ])
        
        # ğŸ¯ æ„å»ºRAGå¢å¼ºçš„QwQå†³ç­–prompt
        decision_prompt = f"""
{exploration_insights}

{similar_decisions}

{decision_experience}

âš¡ **QwQæ™ºèƒ½å†³ç­–ä»»åŠ¡**

åŸºäºR1æ¨¡å‹çš„æ·±åº¦æ¢ç´¢åˆ†æå’Œå†å²å†³ç­–ç»éªŒï¼Œè¯·åšå‡ºæœ€ä¼˜çš„åŠ¨ä½œé€‰æ‹©ã€‚
è¯·å……åˆ†åˆ©ç”¨ä¸Šè¿°æ¢ç´¢æ´å¯Ÿã€ç›¸ä¼¼å†³ç­–ç»éªŒå’Œå†å²æ¨ç†æ¥æŒ‡å¯¼ä½ çš„å†³ç­–ã€‚

## å½“å‰çŠ¶æ€
{page_context}
{history_str}

## R1æ·±åº¦æ¢ç´¢åˆ†æ
{r1_analysis[:1000]}...

## å¯é€‰åŠ¨ä½œ ({len(action_list)}ä¸ª)
{action_list_str}

## ğŸ¯ æ™ºèƒ½å†³ç­–è¦æ±‚
åŸºäºR1çš„ä¸“ä¸šåˆ†æå’Œå†å²ç»éªŒï¼Œé€‰æ‹©å½“å‰æœ€åˆé€‚çš„åŠ¨ä½œï¼š

### å†³ç­–ä¼˜å…ˆçº§
1. **R1é«˜ä»·å€¼æ¨è** - ä¼˜å…ˆè€ƒè™‘R1æ˜ç¡®æ¨èçš„é«˜ä»·å€¼åŠ¨ä½œ
2. **å†å²æˆåŠŸç»éªŒ** - å‚è€ƒç›¸ä¼¼åœºæ™¯ä¸‹çš„æˆåŠŸå†³ç­–æ¨¡å¼
3. **é£é™©è§„é¿ç­–ç•¥** - é¿å…å†å²ä¸Šè¯æ˜æœ‰é£é™©çš„åŠ¨ä½œç±»å‹
4. **æµ‹è¯•å®Œæ•´æ€§** - ç¡®ä¿æµ‹è¯•è¦†ç›–çš„å…¨é¢æ€§å’Œç³»ç»Ÿæ€§

### å†³ç­–è€ƒè™‘å› ç´ 
- **åŠŸèƒ½éªŒè¯**: å½“å‰åŠ¨ä½œæ˜¯å¦èƒ½æœ‰æ•ˆéªŒè¯æ ¸å¿ƒåŠŸèƒ½
- **æ¢ç´¢ä»·å€¼**: åŠ¨ä½œæ˜¯å¦èƒ½å¸¦æ¥æ–°çš„æœ‰ä»·å€¼ä¿¡æ¯
- **æ‰§è¡Œé£é™©**: åŸºäºå†å²ç»éªŒè¯„ä¼°åŠ¨ä½œçš„é£é™©ç¨‹åº¦
- **æµ‹è¯•è¿›åº¦**: è€ƒè™‘å½“å‰æµ‹è¯•çš„æ•´ä½“è¿›åº¦å’Œè¦†ç›–æƒ…å†µ

### è¾“å‡ºè¦æ±‚
**ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º**ï¼š
- ç‚¹å‡»åŠ¨ä½œï¼šç›´æ¥è¿”å›æ•°å­—ï¼Œå¦‚ "3"
- è¾“å…¥åŠ¨ä½œï¼šè¿”å›"æ•°å­—:æ–‡æœ¬"ï¼Œå¦‚ "5:test@example.com"

**å†³ç­–åŸåˆ™**ï¼š
- åŸºäºR1çš„ä¸“ä¸šåˆ†æå’Œå†å²ç»éªŒ
- é€‰æ‹©æµ‹è¯•ä»·å€¼æœ€é«˜ã€é£é™©æœ€å¯æ§çš„åŠ¨ä½œ
- ç¡®ä¿å†³ç­–çš„å‡†ç¡®æ€§å’Œæ‰§è¡Œçš„æœ‰æ•ˆæ€§

è¯·åŸºäºä¸Šè¿°å…¨é¢åˆ†æå¿«é€Ÿåšå‡ºç²¾å‡†å†³ç­–ï¼Œåªè¿”å›åŠ¨ä½œç´¢å¼•æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ã€‚
"""
        
        if self.verbose:
            print(f"âš¡ QwQå¼€å§‹æ™ºèƒ½å†³ç­–...")
        
        try:
            decision_result = self.qwq_decider.chat_with_thinking(decision_prompt)
            qwq_output = decision_result["content"]
            qwq_reasoning = decision_result["reasoning"]
            
            if self.verbose:
                print(f"âš¡ QwQå†³ç­–è¾“å‡º: {qwq_output}")
                print(f"ğŸ§  QwQæ¨ç†: {qwq_reasoning[:100]}...")
                print(f"ğŸš€ RAGæ¥æº: æ¢ç´¢æ´å¯Ÿâœ“ å†³ç­–ç»éªŒâœ“ æ¨ç†ç»éªŒâœ“")
            
            return qwq_output, qwq_reasoning
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ QwQå†³ç­–å¤±è´¥: {e}")
            return None, f"RAGå¢å¼ºå†³ç­–é”™è¯¯: {str(e)}"
    
    def format_action_simple(self, action) -> str:
        """ç®€åŒ–çš„åŠ¨ä½œæ ¼å¼åŒ–"""
        if isinstance(action, ClickAction):
            return f"ç‚¹å‡» '{getattr(action, 'text', 'Unknown')}'"
        elif isinstance(action, RandomInputAction):
            return f"è¾“å…¥ '{getattr(action, 'text', 'Unknown')}'"
        elif isinstance(action, RandomSelectAction):
            return f"é€‰æ‹© '{getattr(action, 'text', 'Unknown')}'"
        else:
            return f"æ“ä½œ '{getattr(action, 'text', 'Unknown')}'"
    
    def get_dual_model_stats(self) -> dict:
        """è·å–åŒæ¨¡å‹ç³»ç»Ÿç»Ÿè®¡"""
        return {
            "total_explorations": self.exploration_count,
            "cached_states": len(self.explored_states),
            "cache_size": len(self.state_exploration_cache),
            "r1_session_id": self.r1_explorer.session_id[:8],
            "qwq_session_id": self.qwq_decider.session_id[:8]
        }


class ExplorationKnowledgeBase:
    """
    ğŸ” ä¸“é—¨å­˜å‚¨R1æ¢ç´¢ç»“æœçš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("exploration_collection_name", "exploration_knowledge")
        self.chunk_size = params.get("exploration_chunk_size", 1000)  # æ¢ç´¢ç»“æœè¾ƒå¤§
        self.chunk_overlap = params.get("exploration_chunk_overlap", 150)
        self.max_entries = params.get("max_exploration_entries", 200)
        self.persist_directory = params.get("exploration_persist_directory", "./exploration_vectorstore")
        self.verbose = verbose
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None
        
        if params.get("clear_exploration_on_init", True):
            self.clear_exploration_vectorstore()
    
    def _initialize_vectorstore(self):
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded exploration KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new exploration KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize exploration KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )
    
    def clear_exploration_vectorstore(self):
        """æ¸…ç©ºæ¢ç´¢çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing exploration KB...")
        
        manage_vectorstore(self.vectorstore, close_connection=True, kb_name="Exploration KB", verbose=self.verbose)
        self.vectorstore = None
        
        import gc
        gc.collect()
        
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Exploration KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear exploration KB: {e}")
        
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create exploration directory: {e}")
    
    def add_exploration_result(self, exploration_data: Dict[str, Any]):
        """æ·»åŠ R1æ¢ç´¢ç»“æœåˆ°çŸ¥è¯†åº“"""
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
            
            # æ„å»ºæ¢ç´¢æ–‡æ¡£å†…å®¹
            content = f"""
æ¢ç´¢ID: {exploration_data.get('exploration_id', 'Unknown')}
æ—¶é—´: {exploration_data.get('timestamp', 'Unknown')}
é¡µé¢: {exploration_data.get('page_title', 'Unknown')}
åŠ¨ä½œæ•°é‡: {exploration_data.get('action_count', 0)}
ä½¿ç”¨æ¨¡å‹: {exploration_data.get('model', 'Unknown')}

=== R1æ·±åº¦åˆ†æ ===
{exploration_data.get('analysis', '')}

=== R1æ¨ç†è¿‡ç¨‹ ===
{exploration_data.get('reasoning', '')}

=== æ¢ç´¢æ‘˜è¦ ===
è¿™æ˜¯ä¸€æ¬¡é’ˆå¯¹"{exploration_data.get('page_title', 'Unknown')}"é¡µé¢çš„æ·±åº¦æ¢ç´¢ï¼Œ
å‘ç°äº†{exploration_data.get('action_count', 0)}ä¸ªå¯äº¤äº’å…ƒç´ ï¼Œ
ç”±DeepSeek-R1æ¨¡å‹è¿›è¡Œä¸“ä¸šåˆ†æå’Œæµ‹è¯•ç­–ç•¥åˆ¶å®šã€‚
"""
            
            doc = Document(
                page_content=content,
                metadata={
                    "exploration_id": exploration_data.get('exploration_id'),
                    "timestamp": exploration_data.get('timestamp'),
                    "page_title": exploration_data.get('page_title', '')[:100],
                    "action_count": exploration_data.get('action_count', 0),
                    "model": exploration_data.get('model', ''),
                    "type": "r1_exploration_result"
                }
            )
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"ğŸ’¾ ä¿å­˜R1æ¢ç´¢ç»“æœ #{exploration_data.get('exploration_id')} ({len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            manage_vectorstore(self.vectorstore, self.max_entries, kb_name="Exploration KB", verbose=self.verbose)
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save exploration result: {e}")
    
    def retrieve_exploration_insights(self, query: str, k: int = 2) -> str:
        """æ£€ç´¢R1æ¢ç´¢æ´å¯Ÿ"""
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            insights = []
            for doc in results:
                insights.append(doc.page_content)
            
            exploration_context = "\n--- R1æ¢ç´¢æ´å¯Ÿ ---\n" + "\n\n".join(insights)
            return exploration_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve exploration insights: {e}")
            return ""


class rag_llm_agent(Agent):
    def __init__(self, params):
        self.params = params
        self.verbose = params.get("verbose", False)
        
        # ğŸš€ å…ˆåˆå§‹åŒ–æ‰€æœ‰çŸ¥è¯†åº“ç³»ç»Ÿ
        self.retriever = RetrieverInterface(params, verbose=self.verbose)
        self.thinking_kb = ThinkingKnowledgeBase(params, verbose=self.verbose)
        self.state_kb = StateKnowledgeBase(params, verbose=self.verbose)
        self.exploration_kb = ExplorationKnowledgeBase(params, verbose=self.verbose)
        
        # ğŸ§  å°†æ‰€æœ‰çŸ¥è¯†åº“æ‰“åŒ…ä¼ é€’ç»™åŒæ¨¡å‹ç³»ç»Ÿ
        knowledge_bases = {
            'retriever': self.retriever,
            'state_kb': self.state_kb,
            'thinking_kb': self.thinking_kb,
            'exploration_kb': self.exploration_kb
        }
        
        # ğŸš€ åˆå§‹åŒ–åŒæ¨¡å‹åä½œç³»ç»Ÿ - ä¼ é€’çŸ¥è¯†åº“å®ä¾‹
        self.dual_model_system = DualModelSystem(params, knowledge_bases=knowledge_bases, verbose=self.verbose)
        
        self.app_name = params.get("app_name", "Web Testing")
        self.history = []
        self.max_history_length = params.get("max_history_length", 5)

        self.login_state = "none"  # none, detected, username_filled, password_filled, completed
        self.login_credentials = {
            "username": "Nefelibata-Zhu",
            "password": "han19780518"
        }
        self.login_attempts = 0
        self.max_login_attempts = 3

        self.explored_pages = set()
        self.executed_actions = {}
        self.page_action_history = {}
        self.bug_indicators = []

        if params.get("reset_dual_model_on_init", True):
            if self.verbose:
                print("Resetting dual model system on init...")
            self.reset_dual_model_session()

        if params.get("clear_rag_on_init", True):
            if self.verbose:
                print("Clearing all RAG databases on init...")
            self.clear_all_rag_databases()

        if self.verbose:
            print(f"ğŸš€ åŒæ¨¡å‹RAG Agent initialized for {self.app_name}")
            stats = self.dual_model_system.get_dual_model_stats()
            print(f"   ğŸ“¡ R1ä¼šè¯: {stats['r1_session_id']}")
            print(f"   âš¡ QwQä¼šè¯: {stats['qwq_session_id']}")
            print("ğŸ§  R1æ¢ç´¢ + QwQå†³ç­– åä½œç³»ç»Ÿå·²å¯ç”¨")
            print("ğŸš€ å››å±‚RAGçŸ¥è¯†åº“ç³»ç»Ÿå·²å¯ç”¨:")
            print("   ğŸ“– RetrieverKB: ä¸“ä¸šæµ‹è¯•çŸ¥è¯†æ–‡æ¡£")
            print("   ğŸ§  ThinkingKB: æ¨¡å‹æ¨ç†è¿‡ç¨‹è®°å½•")
            print("   ğŸ“Š StateKB: é¡µé¢çŠ¶æ€å’Œäº¤äº’å†å²")
            print("   ğŸ” ExplorationKB: R1æ¢ç´¢ç»“æœä¸“ç”¨å­˜å‚¨")

    def reset_login_state(self):
        self.login_state = "none"
        self.login_attempts = 0
        if self.verbose:
            print("ç™»å½•çŠ¶æ€å·²é‡ç½®")

    def set_login_credentials(self, username: str, password: str):
        """
        è®¾ç½®ç™»å½•å‡­è¯
        
        Args:
            username: ç”¨æˆ·åæˆ–é‚®ç®±
            password: å¯†ç 
        """
        self.login_credentials["username"] = username
        self.login_credentials["password"] = password
        if self.verbose:
            print(f"ğŸ” ç™»å½•å‡­è¯å·²æ›´æ–° - ç”¨æˆ·å: {username}")

    def handle_smart_login(self, action_list, page_title: str = "") -> WebAction:
        """
        ğŸ” æ™ºèƒ½ç™»å½•çŠ¶æ€æœº - è‡ªåŠ¨å®Œæˆç™»å½•æµç¨‹
        """
        if self.verbose:
            print(f"ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - å½“å‰çŠ¶æ€: {self.login_state}")

        # åˆ†æå¯ç”¨åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append((i, action))
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append((i, action))
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append((i, action))

        # çŠ¶æ€æœºé€»è¾‘
        if self.login_state == "none" or self.login_state == "detected":
            # ç¬¬ä¸€æ­¥ï¼šå¡«å†™ç”¨æˆ·å
            if username_actions:
                self.login_state = "username_filling"
                action_index, selected_action = username_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["username"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥ç”¨æˆ·å: {self.login_credentials['username']}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤1: å¡«å…¥ç”¨æˆ·å - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Username input")
                
                self.login_state = "username_filled"
                return selected_action

        elif self.login_state == "username_filled":
            # ç¬¬äºŒæ­¥ï¼šå¡«å†™å¯†ç 
            if password_actions:
                self.login_state = "password_filling"
                action_index, selected_action = password_actions[0]
                
                if hasattr(selected_action, 'set_input_text'):
                    selected_action.set_input_text(self.login_credentials["password"])
                
                action_description = f"ğŸ” è‡ªåŠ¨å¡«å…¥å¯†ç : {'*' * len(self.login_credentials['password'])}"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤2: å¡«å…¥å¯†ç  - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Password input")
                
                self.login_state = "password_filled"
                return selected_action

        elif self.login_state == "password_filled":
            # ç¬¬ä¸‰æ­¥ï¼šç‚¹å‡»ç™»å½•æŒ‰é’®
            if login_button_actions:
                action_index, selected_action = login_button_actions[0]
                
                action_description = "ğŸ” è‡ªåŠ¨ç‚¹å‡»ç™»å½•æŒ‰é’®"
                self.history.append(action_description)
                
                if self.verbose:
                    print(f"ğŸ” æ­¥éª¤3: ç‚¹å‡»ç™»å½•æŒ‰é’® - Action [{action_index}]")
                print(f"Action [{action_index}]: ğŸ” AUTO LOGIN - Click login button")
                
                self.login_state = "completed"
                return selected_action

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„åŠ¨ä½œï¼Œå¢åŠ å°è¯•æ¬¡æ•°
        self.login_attempts += 1
        if self.login_attempts >= self.max_login_attempts:
            if self.verbose:
                print(f"ğŸ” ç™»å½•å°è¯•å¤±è´¥ {self.max_login_attempts} æ¬¡ï¼Œåˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼")
            self.login_state = "completed"  # å¼ºåˆ¶å®Œæˆï¼Œä½¿ç”¨æ™®é€šé€»è¾‘
            return None
        
        # è¿”å› None è¡¨ç¤ºç»§ç»­å°è¯•
        return None

    def clear_rag_database(self):
        """
        æ¸…ç©ºä¸‰ä¸ªRAGæ•°æ®åº“
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_llm_session(self):
        """
        é‡ç½®LLMä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.dual_model_system.r1_explorer.reset_session()
            self.dual_model_system.qwq_decider.reset_session()
            if self.verbose:
                print("LLM session reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset LLM session: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - ç¡®ä¿å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
        """
        if self.verbose:
            print("Resetting agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€
        self.reset_dual_model_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬çŠ¶æ€çŸ¥è¯†åº“ï¼‰
        self.clear_rag_database()
        
        if self.verbose:
            print(f"Agent reset complete - New session: {self.dual_model_system.r1_explorer.session_id[:8]}")

    def format_action_info(self, action):
        """æ ¼å¼åŒ–åŠ¨ä½œä¿¡æ¯"""
        if isinstance(action, ClickAction):
            operation_name = "Click"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'unknown')
            addition_info = getattr(action, 'addition_info', '')
            details = f"Widget text: '{action.text}', type: {action_type}, info: {addition_info}"
        elif isinstance(action, RandomInputAction):
            operation_name = "Input"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'input')
            details = f"Input field: '{action.text}', type: {action_type}"
        elif isinstance(action, RandomSelectAction):
            operation_name = "Select"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'select')
            options = getattr(action, 'options', 'N/A')
            details = f"Select field: '{action.text}', type: {action_type}, options: {options}"
        else:
            operation_name = "UnknownOperation"
            # å®‰å…¨åœ°è·å–textå±æ€§
            text = getattr(action, 'text', 'Unknown')
            details = f"Widget: '{text}'"

        return f"'{operation_name}' on {details}"

    def detect_login_page(self, action_list, html: str = "", page_title: str = "") -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        """
        # æ£€æŸ¥é¡µé¢æ ‡é¢˜
        login_title_keywords = [
            "sign in", "login", "log in", "ç™»å½•", "ç™»å…¥"
        ]
        
        if page_title:
            title_lower = page_title.lower()
            for keyword in login_title_keywords:
                if keyword in title_lower:
                    return True
        
        # æ£€æŸ¥HTMLå†…å®¹
        if html:
            html_lower = html.lower()
            if "sign in to github" in html_lower or "github login" in html_lower:
                return True
        
        # æ£€æŸ¥åŠ¨ä½œåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ç™»å½•ç›¸å…³çš„è¾“å…¥å­—æ®µ
        login_field_keywords = [
            "username", "email", "password", "login", "sign in"
        ]
        
        input_fields = [action for action in action_list if isinstance(action, RandomInputAction)]
        login_field_count = 0
        
        for action in input_fields:
            field_text = action.text.lower()
            for keyword in login_field_keywords:
                if keyword in field_text:
                    login_field_count += 1
                    break
        
        # å¦‚æœæœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„ç™»å½•ç›¸å…³å­—æ®µï¼Œè®¤ä¸ºæ˜¯ç™»å½•é¡µé¢
        return login_field_count >= 2

    def get_action_signature(self, action) -> str:
        """
        ç”ŸæˆåŠ¨ä½œçš„å”¯ä¸€ç­¾åï¼Œç”¨äºå»é‡
        """
        if hasattr(action, 'text') and hasattr(action, 'location'):
            return f"{type(action).__name__}_{action.text}_{action.location}"
        elif hasattr(action, 'text'):
            return f"{type(action).__name__}_{action.text}"
        else:
            return f"{type(action).__name__}_{str(action)}"

    def update_exploration_history(self, current_url: str, selected_action, action_index: int):
        """
        æ›´æ–°æ¢ç´¢å†å²è®°å½•
        """
        # è®°å½•è®¿é—®çš„é¡µé¢
        self.explored_pages.add(current_url)
        
        # è®°å½•æ‰§è¡Œçš„åŠ¨ä½œ
        if current_url not in self.executed_actions:
            self.executed_actions[current_url] = {}
        
        action_signature = self.get_action_signature(selected_action)
        if action_signature not in self.executed_actions[current_url]:
            self.executed_actions[current_url][action_signature] = 0
        self.executed_actions[current_url][action_signature] += 1
        
        # è®°å½•é¡µé¢åŠ¨ä½œå†å²
        if current_url not in self.page_action_history:
            self.page_action_history[current_url] = []
        
        self.page_action_history[current_url].append({
            "action_text": getattr(selected_action, 'text', 'Unknown'),
            "action_type": type(selected_action).__name__,
            "action_index": action_index,
            "timestamp": datetime.now().isoformat(),
            "execution_count": self.executed_actions[current_url][action_signature]
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.page_action_history[current_url]) > 20:
            self.page_action_history[current_url] = self.page_action_history[current_url][-20:]

    def generate_login_focused_prompt(self, action_list, page_context: str, history_str: str, page_title: str = "") -> str:
        """
        ç”Ÿæˆä¸“æ³¨äºç™»å½•çš„æç¤ºè¯
        """
        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)
        
        # è¯†åˆ«ç™»å½•ç›¸å…³çš„åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append(i)
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append(i)
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append(i)
        
        login_suggestions = ""
        if username_actions:
            login_suggestions += f"\nç”¨æˆ·åè¾“å…¥å­—æ®µç´¢å¼•: {username_actions} (è¾“å…¥: Nefelibata-Zhu)"
        if password_actions:
            login_suggestions += f"\nå¯†ç è¾“å…¥å­—æ®µç´¢å¼•: {password_actions} (è¾“å…¥: han19780518)"
        if login_button_actions:
            login_suggestions += f"\nç™»å½•æŒ‰é’®ç´¢å¼•: {login_button_actions}"
        
        return f"""
æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼è¯·ç«‹å³å®Œæˆç™»å½•æµç¨‹ã€‚
        
        {page_context}
        {history_str}
        
        å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ æœ‰:
        {action_descriptions_str}
        
ç™»å½•æ“ä½œå»ºè®®ï¼š{login_suggestions}
        
ç™»å½•æ­¥éª¤ï¼ˆè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼‰ï¼š
        1. æ‰¾åˆ°ç”¨æˆ·å/é‚®ç®±è¾“å…¥å­—æ®µ â†’ è¾“å…¥"Nefelibata-Zhu"
        2. æ‰¾åˆ°å¯†ç è¾“å…¥å­—æ®µ â†’ è¾“å…¥"han19780518"
        3. ç‚¹å‡»"Sign in"ç™»å½•æŒ‰é’®ï¼ˆé¿å…æ³¨å†ŒæŒ‰é’®ï¼‰
        
é‡è¦æé†’ï¼š
        - ä¼˜å…ˆå®Œæˆç™»å½•ï¼Œä¸è¦è¿›è¡Œå…¶ä»–æ“ä½œ
        - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‡­æ®æ ¼å¼
        - é¿å…ç‚¹å‡»æ³¨å†Œç›¸å…³æŒ‰é’®
        
        è¯·è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå¯¹åº”ä¸Šé¢åˆ—è¡¨ä¸­åŠ¨ä½œçš„ç´¢å¼•ã€‚
        å¦‚æœé€‰æ‹©è¾“å…¥åŠ¨ä½œï¼Œæ ¼å¼ä¸º"ç´¢å¼•:æ–‡æœ¬"ã€‚
        ä¾‹å¦‚ï¼šç”¨æˆ·åå­—æ®µè¾“å…¥ï¼Œè¿”å›"{username_actions[0] if username_actions else 'X'}:Nefelibata-Zhu"
        
        åªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–è§£é‡Šã€‚
        """.strip()

    def get_action(self, web_state: WebState, html: str) -> WebAction:
        """
        ğŸš€ åŒæ¨¡å‹åä½œå†³ç­–æ–¹æ³• - R1æ¢ç´¢ + QwQå†³ç­–
        """
        action_list = web_state.get_action_list()
        if self.verbose:
            print(f"Available actions: {len(action_list)}")
        if not action_list:
            if self.verbose:
                print("Warning: No available actions")
            return None

        # è·å–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯
        page_context = ""
        page_title = ""
        current_url = ""
        if html:
            title_match = re.search(r"<title>(.*?)</title>", html, re.IGNORECASE)
            if title_match:
                page_title = title_match.group(1)
                page_context = f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}\n"
        
        if hasattr(web_state, 'url'):
            current_url = web_state.url
        elif page_title:
            current_url = page_title

        # æ„å»ºå†å²è®°å½•å­—ç¬¦ä¸²
        history_str = ""
        if self.history:
            history_str = "æœ€è¿‘çš„æ“ä½œå†å²:\n" + "\n".join([f"- {h}" for h in self.history[-self.max_history_length:]])

        # æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        is_login_page = self.detect_login_page(action_list, html, page_title)
        
        # ğŸ” æ™ºèƒ½ç™»å½•å¤„ç† - ä¼˜å…ˆä½¿ç”¨çŠ¶æ€æœº
        if is_login_page and self.login_state != "completed":
            if self.login_state == "none":
                self.login_state = "detected"
                print("ğŸ” æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œå¯åŠ¨æ™ºèƒ½ç™»å½•çŠ¶æ€æœº")
            
            smart_login_action = self.handle_smart_login(action_list, page_title)
            if smart_login_action is not None:
                return smart_login_action
            elif self.login_state == "completed":
                print("ğŸ” ç™»å½•æµç¨‹å·²å®Œæˆï¼Œåˆ‡æ¢åˆ°åŒæ¨¡å‹æµ‹è¯•æ¨¡å¼")
                self.reset_login_state()
        
        if not is_login_page and self.login_state != "none":
            if self.verbose:
                print("ğŸ” ç¦»å¼€ç™»å½•é¡µé¢ï¼Œé‡ç½®ç™»å½•çŠ¶æ€")
            self.reset_login_state()

        # ğŸš€ åŒæ¨¡å‹åä½œå†³ç­–
        print("ğŸš€ ä½¿ç”¨åŒæ¨¡å‹åä½œç³»ç»Ÿè¿›è¡Œå†³ç­–")
        
        try:
            # 1. ç”ŸæˆçŠ¶æ€ç­¾å
            state_signature = self.dual_model_system.generate_state_signature(
                page_title, action_list, html[:500]  # åªä½¿ç”¨å‰500å­—ç¬¦é¿å…è¿‡é•¿
            )
            
            # 2. æ£€æŸ¥æ˜¯å¦ä¸ºæ–°çŠ¶æ€
            is_new_state = self.dual_model_system.is_new_state(state_signature)
            
            if is_new_state:
                # 3a. æ–°çŠ¶æ€ï¼šä½¿ç”¨R1è¿›è¡Œæ·±åº¦æ¢ç´¢
                print(f"ğŸ” æ£€æµ‹åˆ°æ–°çŠ¶æ€ï¼Œå¯åŠ¨R1æ·±åº¦æ¢ç´¢")
                
                exploration_data = self.dual_model_system.r1_explore_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    page_context=page_context,
                    history_str=history_str,
                    html=html
                )
                
                # ä¿å­˜æ¢ç´¢ç»“æœåˆ°ä¸“ç”¨çŸ¥è¯†åº“
                self.exploration_kb.add_exploration_result(exploration_data)
                
                # æ ‡è®°çŠ¶æ€ä¸ºå·²æ¢ç´¢
                self.dual_model_system.explored_states.add(state_signature)
                self.dual_model_system.state_exploration_cache[state_signature] = exploration_data
                
                # 3b. åŸºäºR1æ¢ç´¢ç»“æœï¼Œä½¿ç”¨QwQå¿«é€Ÿå†³ç­–
                qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                    action_list=action_list,
                    exploration_data=exploration_data,
                    page_context=page_context,
                    history_str=history_str
                )
                
                combined_reasoning = f"R1æ¢ç´¢: {exploration_data.get('reasoning', '')[:200]}... | QwQå†³ç­–: {qwq_reasoning[:200]}..."
                
            else:
                # 4. å·²çŸ¥çŠ¶æ€ï¼šç›´æ¥ä½¿ç”¨QwQåŸºäºç¼“å­˜çš„æ¢ç´¢ç»“æœå†³ç­–
                print(f"âš¡ å·²çŸ¥çŠ¶æ€ï¼Œä½¿ç”¨QwQå¿«é€Ÿå†³ç­–")
                
                cached_exploration = self.dual_model_system.state_exploration_cache.get(state_signature)
                if cached_exploration:
                    qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                        action_list=action_list,
                        exploration_data=cached_exploration,
                        page_context=page_context,
                        history_str=history_str
                    )
                else:
                    # ç¼“å­˜ä¸¢å¤±ï¼Œå¿«é€Ÿç”ŸæˆåŸºç¡€æ¢ç´¢ä¿¡æ¯
                    basic_exploration = {
                        "analysis": f"åŸºç¡€çŠ¶æ€åˆ†æï¼šé¡µé¢æœ‰{len(action_list)}ä¸ªå¯äº¤äº’å…ƒç´ ",
                        "reasoning": "ä½¿ç”¨åŸºç¡€æ¢ç´¢ä¿¡æ¯è¿›è¡Œå¿«é€Ÿå†³ç­–"
                    }
                    qwq_output, qwq_reasoning = self.dual_model_system.qwq_decide_action(
                        action_list=action_list,
                        exploration_data=basic_exploration,
                        page_context=page_context,
                        history_str=history_str
                    )
                
                combined_reasoning = f"ç¼“å­˜å†³ç­–: {qwq_reasoning[:300]}..."

            if self.verbose:
                print(f"åŒæ¨¡å‹è¾“å‡º: {qwq_output}")

            # 5. è§£æQwQè¾“å‡º
            action_index, input_text = self.parse_output(qwq_output, len(action_list))

            if action_index is not None and 0 <= action_index < len(action_list):
                # å†³ç­–æœ‰æ•ˆ
                selected_action = action_list[action_index]
                
                if isinstance(selected_action, RandomInputAction) and input_text:
                    if hasattr(selected_action, 'set_input_text'):
                        selected_action.set_input_text(input_text)

                # æ›´æ–°æ¢ç´¢å†å²è®°å½•
                self.update_exploration_history(current_url, selected_action, action_index)
                
                action_description = self.format_action_info(selected_action)
                if input_text:
                    action_description += f" with input: '{input_text}'"
                
                self.history.append(action_description)

                # ä¿å­˜çŸ¥è¯†åº“ä¿¡æ¯
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=action_index,
                    reasoning=combined_reasoning
                )

                self.thinking_kb.add_thinking(
                    prompt=f"åŒæ¨¡å‹åä½œ: æ–°çŠ¶æ€={is_new_state}",
                    reasoning=combined_reasoning,
                    action_taken=action_description
                )

                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]

                # æ˜¾ç¤ºå†³ç­–ç»“æœ
                model_info = "ğŸ”R1+âš¡QwQ" if is_new_state else "âš¡QwQ"
                if self.verbose:
                    print(f"âœ… {model_info}é€‰æ‹© [{action_index}]: {action_description}")
                else:
                    print(f"Action [{action_index}]: {self.format_action_info(selected_action)} ({model_info})")
                
                return selected_action
            else:
                # å†³ç­–æ— æ•ˆï¼Œéšæœºå›é€€
                if self.verbose:
                    print(f"âš ï¸ åŒæ¨¡å‹é€‰æ‹© {action_index} æ— æ•ˆï¼Œä½¿ç”¨éšæœºå›é€€ç­–ç•¥")
                
                import random
                fallback_index = random.randint(0, len(action_list) - 1)
                fallback_action = action_list[fallback_index]
                
                self.update_exploration_history(current_url, fallback_action, fallback_index)
                
                fallback_description = f"Random Fallback: {self.format_action_info(fallback_action)} ğŸ²"
                
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=fallback_index,
                    reasoning=f"åŒæ¨¡å‹é€‰æ‹©æ— æ•ˆï¼Œéšæœºå›é€€: {combined_reasoning if 'combined_reasoning' in locals() else 'Random selection'}"
                )

                if 'combined_reasoning' in locals():
                    self.thinking_kb.add_thinking(
                        prompt="åŒæ¨¡å‹å†³ç­–å¤±è´¥",
                        reasoning=combined_reasoning,
                        action_taken=fallback_description
                    )

                self.history.append(fallback_description)
                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]
                
                return fallback_action

        except Exception as e:
            if self.verbose:
                print(f"âŒ åŒæ¨¡å‹åä½œå¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºå›é€€")
            
            # éšæœºå›é€€
            import random
            fallback_index = random.randint(0, len(action_list) - 1)
            fallback_action = action_list[fallback_index]
            
            self.update_exploration_history(current_url, fallback_action, fallback_index)
            
            error_description = f"Error Fallback: {self.format_action_info(fallback_action)} âŒ"
            
            self.state_kb.add_page_state(
                page_title=page_title or "Unknown Page",
                action_list=action_list,
                selected_action_index=fallback_index,
                reasoning=f"åŒæ¨¡å‹ç³»ç»Ÿé”™è¯¯: {str(e)}ï¼Œéšæœºé€‰æ‹©åŠ¨ä½œ"
            )
            
            self.thinking_kb.add_thinking(
                prompt="åŒæ¨¡å‹ç³»ç»Ÿé”™è¯¯",
                reasoning=f"Error: {str(e)}",
                action_taken=error_description
            )

            self.history.append(error_description)
            if len(self.history) > self.max_history_length:
                self.history = self.history[-self.max_history_length:]
            
            return fallback_action

    def parse_output(self, output: str, num_actions: int) -> tuple:
        """
        è§£æLLMè¾“å‡ºï¼Œæå–åŠ¨ä½œç´¢å¼•å’Œå¯èƒ½çš„è¾“å…¥æ–‡æœ¬
        è¿”å›ä¸€ä¸ªå…ƒç»„ (åŠ¨ä½œç´¢å¼•, è¾“å…¥æ–‡æœ¬)ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥æ–‡æœ¬åˆ™ä¸ºNone
        """
        # å†…éƒ¨å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå»é™¤ ANSI è½¬ä¹‰åºåˆ—
        def remove_ansi(text: str) -> str:
            ansi_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            return ansi_pattern.sub('', text)

        cleaned_output = remove_ansi(output).strip()

        # å°è¯•åŒ¹é…"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼
        input_pattern = re.compile(r'^(\d+):(.+)$', re.DOTALL)
        match = input_pattern.match(cleaned_output)

        if match:
            index_str, input_text = match.groups()
            try:
                index = int(index_str)
                if 0 <= index < num_actions:
                    return index, input_text.strip()
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {index_str}")
                return None, None

        # å°è¯•ç›´æ¥æ‰¾å‡ºæ•°å­—
        number_match = re.search(r'^\d+', cleaned_output)
        if number_match:
            try:
                index = int(number_match.group())
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {number_match.group()}")
                return None, None

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–æœ€åä¸€ä¸ªæ•°å­—ä½œä¸ºç´¢å¼•
        numbers = re.findall(r'\d+', cleaned_output)
        if numbers:
            try:
                index = int(numbers[-1])
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {numbers[-1]}")
                return None, None

        if self.verbose:
            print(f"Failed to parse output: {cleaned_output[:50]}...")
        return None, None

    def get_exploration_stats(self) -> dict:
        """
        è·å–æ¢ç´¢ç»Ÿè®¡ä¿¡æ¯
        """
        total_pages = len(self.explored_pages)
        total_unique_actions = sum(len(actions) for actions in self.executed_actions.values())
        
        # è®¡ç®—é‡å¤åŠ¨ä½œç»Ÿè®¡
        overused_count = 0
        new_actions_available = 0
        
        for url, actions in self.executed_actions.items():
            for action_sig, count in actions.items():
                if count > 2:  # å›ºå®šé˜ˆå€¼ï¼Œä¹‹å‰çš„max_action_repeatsé»˜è®¤å€¼
                    overused_count += 1
        
        # è®¡ç®—æœ€æ´»è·ƒçš„é¡µé¢
        most_active_page = ""
        max_actions = 0
        for url, actions in self.executed_actions.items():
            if len(actions) > max_actions:
                max_actions = len(actions)
                most_active_page = url
        
        return {
            "explored_pages": total_pages,
            "unique_actions_executed": total_unique_actions,
            "overused_actions": overused_count,
            "most_active_page": most_active_page,
            "max_actions_on_page": max_actions,
            "explored_pages_list": list(self.explored_pages)
        }

    def print_exploration_summary(self):
        """
        æ‰“å°æ¢ç´¢æ‘˜è¦
        """
        stats = self.get_exploration_stats()
        print("\n" + "="*50)
        print("ğŸ¯ æ™ºèƒ½æ¢ç´¢ç³»ç»Ÿ - ç»Ÿè®¡æ‘˜è¦")
        print("="*50)
        print(f"ğŸ“Š å·²æ¢ç´¢é¡µé¢æ•°é‡: {stats['explored_pages']}")
        print(f"ğŸ® æ‰§è¡Œçš„å”¯ä¸€åŠ¨ä½œ: {stats['unique_actions_executed']}")
        print(f"âš ï¸ è¿‡åº¦ä½¿ç”¨çš„åŠ¨ä½œ: {stats['overused_actions']}")
        print(f"ğŸ† æœ€æ´»è·ƒé¡µé¢: {stats['most_active_page'][:50]}...")
        print(f"ğŸ”¥ è¯¥é¡µé¢åŠ¨ä½œæ•°: {stats['max_actions_on_page']}")
        
        if self.bug_indicators:
            print(f"ğŸ› æ½œåœ¨BugæŒ‡æ ‡: {len(self.bug_indicators)}")
            for indicator in self.bug_indicators[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3ä¸ª
                print(f"   - {indicator}")
        
        print("="*50)

    def debug_show_final_prompt(self, final_prompt: str):
        """
        è°ƒè¯•æ–¹æ³•ï¼šæ˜¾ç¤ºæœ€ç»ˆå‘é€ç»™LLMçš„å®Œæ•´promptç»“æ„
        """
        if not self.verbose:
            return
            
        print("\n" + "ğŸ” DEBUG: æœ€ç»ˆPromptç»“æ„" + "="*30)
        
        # å°è¯•åˆ†æpromptçš„å„ä¸ªéƒ¨åˆ†
        sections = final_prompt.split("\n\n")
        
        for i, section in enumerate(sections[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ªéƒ¨åˆ†é¿å…è¿‡é•¿
            if len(section.strip()) > 0:
                # è¯†åˆ«ä¸åŒç±»å‹çš„å†…å®¹
                if "ä¸“ä¸šçŸ¥è¯†åº“" in section:
                    print(f"\nğŸ“š ç¬¬{i+1}éƒ¨åˆ† - RAGçŸ¥è¯†å¢å¼º:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ" in section:
                    print(f"\nğŸ§  ç¬¬{i+1}éƒ¨åˆ† - ThinkingçŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif "ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ" in section:
                    print(f"\nğŸ“Š ç¬¬{i+1}éƒ¨åˆ† - çŠ¶æ€çŸ¥è¯†åº“:")
                    print("â”€" * 40)
                    print(section[:300] + "..." if len(section) > 300 else section)
                    
                elif any(keyword in section for keyword in ["å¯æ“ä½œçš„ç•Œé¢å…ƒç´ ", "æ¢ç´¢ç­–ç•¥", "ç™»å½•æ­¥éª¤"]):
                    print(f"\nğŸ¯ ç¬¬{i+1}éƒ¨åˆ† - åŸºç¡€Prompt:")
                    print("â”€" * 40)
                    print(section[:500] + "..." if len(section) > 500 else section)
                    
                else:
                    print(f"\nğŸ“ ç¬¬{i+1}éƒ¨åˆ† - å…¶ä»–å†…å®¹:")
                    print("â”€" * 40)
                    print(section[:200] + "..." if len(section) > 200 else section)
        
        print(f"\nğŸ’¾ å®Œæ•´Promptæ€»é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        print("ğŸ” DEBUG: Promptç»“æ„åˆ†æå®Œæˆ" + "="*25 + "\n")

    def improve_action_selection_randomness(self, action_list, exploration_scores, current_url: str) -> str:
        """
        å·²åºŸå¼ƒçš„æ–¹æ³• - æ”¹ä¸ºçº¯LLMå†³ç­–åä¸å†ä½¿ç”¨
        """
        # æ­¤æ–¹æ³•å·²è¢«åˆ é™¤ï¼Œæ”¹ä¸ºçº¯LLMå†³ç­–
        return ""

    def reset_dual_model_session(self):
        """
        é‡ç½®åŒæ¨¡å‹ä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.dual_model_system.reset_for_new_test()
            if self.verbose:
                print("Dual model system reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset dual model system: {e}")

    def clear_all_rag_databases(self):
        """
        æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬æ–°çš„æ¢ç´¢çŸ¥è¯†åº“ï¼‰
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            self.exploration_kb.clear_exploration_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - åŒæ¨¡å‹ç‰ˆæœ¬
        """
        if self.verbose:
            print("Resetting dual-model agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€
        self.reset_dual_model_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“
        self.clear_all_rag_databases()
        
        if self.verbose:
            stats = self.dual_model_system.get_dual_model_stats()
            print(f"Agent reset complete - R1: {stats['r1_session_id']}, QwQ: {stats['qwq_session_id']}")


def main():
    """ğŸš€ åŒæ¨¡å‹åä½œRAG Agentæµ‹è¯• - R1æ¢ç´¢ + QwQå†³ç­–"""
    # æµ‹è¯•å‚æ•°
    test_params = {
        "api_key": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "embedding_token": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "app_name": "Dual Model Web Testing",
        "verbose": True,  # æµ‹è¯•æ—¶å¯ç”¨è¯¦ç»†è¾“å‡º
        "max_tokens": 1024,  # åŸºç¡€é…ç½®ï¼Œä¼šè¢«å„æ¨¡å‹è¦†ç›–
        "temperature": 0.7,
        "clear_rag_on_init": True,
        "clear_thinking_on_init": True,
        "clear_state_on_init": True,
        "clear_exploration_on_init": True,  # æ–°å¢ï¼šæ¸…ç†æ¢ç´¢çŸ¥è¯†åº“
        "reset_dual_model_on_init": True,  # æ–°å¢ï¼šé‡ç½®åŒæ¨¡å‹ç³»ç»Ÿ
    }

    print("ğŸš€ åŒæ¨¡å‹åä½œRAG Agent - R1æ¢ç´¢ + QwQå†³ç­–")
    print("=" * 60)
    
    try:
        # æµ‹è¯•Agentåˆå§‹åŒ–
        agent = rag_llm_agent(test_params)
        print("âœ“ åŒæ¨¡å‹Agentåˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•åŒæ¨¡å‹ç³»ç»Ÿç»Ÿè®¡
        stats = agent.dual_model_system.get_dual_model_stats()
        print(f"âœ“ åŒæ¨¡å‹ç³»ç»ŸçŠ¶æ€:")
        print(f"  ğŸ“¡ R1ä¼šè¯ID: {stats['r1_session_id']}")
        print(f"  âš¡ QwQä¼šè¯ID: {stats['qwq_session_id']}")
        print(f"  ğŸ“Š æ¢ç´¢æ¬¡æ•°: {stats['total_explorations']}")
        print(f"  ğŸ’¾ ç¼“å­˜çŠ¶æ€: {stats['cached_states']}")
        
        # æµ‹è¯•é‡ç½®åŠŸèƒ½
        original_r1_session = stats['r1_session_id']
        original_qwq_session = stats['qwq_session_id']
        
        agent.reset_for_new_test()
        new_stats = agent.dual_model_system.get_dual_model_stats()
        
        reset_success = (
            original_r1_session != new_stats['r1_session_id'] and
            original_qwq_session != new_stats['qwq_session_id']
        )
        print(f"âœ“ é‡ç½®æµ‹è¯•: {'Success' if reset_success else 'Failed'}")
        
        # æµ‹è¯•åŒæ¨¡å‹æ¶æ„ç‰¹æ€§
        print("\nğŸš€ åŒæ¨¡å‹åä½œæ¶æ„ç‰¹æ€§:")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚  ğŸ” R1æ¨¡å‹ (DeepSeek-R1)                       â”‚")
        print("â”‚  â”œâ”€ èŒè´£: æ–°çŠ¶æ€æ·±åº¦æ¢ç´¢åˆ†æ                   â”‚")
        print("â”‚  â”œâ”€ ç‰¹ç‚¹: 2048 tokens, é«˜æ¸©åº¦(0.8)            â”‚")
        print("â”‚  â””â”€ è¾“å‡º: é¡µé¢åˆ†æã€æµ‹è¯•ç­–ç•¥ã€é£é™©è¯†åˆ«         â”‚")
        print("â”‚                                                 â”‚")
        print("â”‚  âš¡ QwQæ¨¡å‹ (Qwen/QwQ-32B-Preview)              â”‚")
        print("â”‚  â”œâ”€ èŒè´£: åŸºäºR1åˆ†æå¿«é€Ÿå†³ç­–                   â”‚")
        print("â”‚  â”œâ”€ ç‰¹ç‚¹: 512 tokens, ä½æ¸©åº¦(0.3)             â”‚")
        print("â”‚  â””â”€ è¾“å‡º: å…·ä½“åŠ¨ä½œé€‰æ‹©                         â”‚")
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        print("\nğŸ”„ å·¥ä½œæµç¨‹:")
        print("1. ğŸ” çŠ¶æ€æ£€æµ‹ â†’ ç”Ÿæˆé¡µé¢çŠ¶æ€ç­¾å")
        print("2. ğŸ†• æ–°çŠ¶æ€? â†’ R1æ·±åº¦æ¢ç´¢ â†’ å­˜å‚¨åˆ°æ¢ç´¢çŸ¥è¯†åº“")
        print("3. âš¡ QwQå†³ç­– â†’ åŸºäºR1åˆ†æå¿«é€Ÿé€‰æ‹©åŠ¨ä½œ")
        print("4. ğŸ”„ å·²çŸ¥çŠ¶æ€ â†’ ç›´æ¥QwQå†³ç­–(åˆ©ç”¨ç¼“å­˜)")
        
        print("\nğŸ“š å››å±‚çŸ¥è¯†åº“ç³»ç»Ÿ:")
        print("â€¢ ğŸ” ExplorationKB: R1æ¢ç´¢ç»“æœä¸“ç”¨å­˜å‚¨")
        print("â€¢ ğŸ“Š StateKB: é¡µé¢çŠ¶æ€å’Œäº¤äº’å†å²")
        print("â€¢ ğŸ§  ThinkingKB: æ¨¡å‹æ¨ç†è¿‡ç¨‹è®°å½•")
        print("â€¢ ğŸ“– RetrieverKB: ä¸“ä¸šæµ‹è¯•çŸ¥è¯†æ–‡æ¡£")
        
        print("\nğŸ’¡ ç³»ç»Ÿä¼˜åŠ¿:")
        print("ğŸ¯ ç²¾å‡†æ¢ç´¢: R1æ¨¡å‹ä¸“æ³¨æ·±åº¦åˆ†ææ–°çŠ¶æ€")
        print("âš¡ å¿«é€Ÿå†³ç­–: QwQæ¨¡å‹åŸºäºåˆ†æç»“æœé«˜æ•ˆæ‰§è¡Œ")
        print("ğŸ’° æˆæœ¬ä¼˜åŒ–: é¿å…é‡å¤æ¢ç´¢ï¼Œå¤§å¹…é™ä½tokenæ¶ˆè€—")
        print("ğŸ”„ æ™ºèƒ½ç¼“å­˜: å·²çŸ¥çŠ¶æ€å¤ç”¨æ¢ç´¢ç»“æœ")
        print("ğŸ›¡ï¸ å®¹é”™æœºåˆ¶: å¤šå±‚å›é€€ä¿éšœç³»ç»Ÿç¨³å®š")
        
        print("\n" + "=" * 60)
        print("âœ… åŒæ¨¡å‹åä½œç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
        print("\nğŸš€ æ ¸å¿ƒåˆ›æ–°:")
        print("â€¢ ğŸ” R1ä¸“æ³¨æ¢ç´¢: åªåœ¨æ–°çŠ¶æ€æ—¶æ¿€æ´»ï¼Œæ·±åº¦åˆ†æ")
        print("â€¢ âš¡ QwQä¸“æ³¨å†³ç­–: å¿«é€Ÿå“åº”ï¼Œé™ä½å»¶è¿Ÿ")
        print("â€¢ ğŸ’¾ æ™ºèƒ½ç¼“å­˜: é¿å…é‡å¤æ¢ç´¢ï¼Œæ˜¾è‘—èŠ‚çœæˆæœ¬")
        print("â€¢ ğŸ“š çŸ¥è¯†å¢å¼º: å››å±‚RAGç³»ç»Ÿæä¾›å…¨é¢ä¸Šä¸‹æ–‡")
        print("â€¢ ğŸ¨ è‡ªé€‚åº”: æ ¹æ®çŠ¶æ€æ–°æ—§ç¨‹åº¦åŠ¨æ€é€‰æ‹©ç­–ç•¥")
        print("\nğŸ’¡ ç°åœ¨è¿è¡Œ python main.py ä½“éªŒåŒæ¨¡å‹åä½œ!")
            
    except Exception as e:
        print(f"âœ— Test failed: {e}")


if __name__ == "__main__":
    # åªæœ‰åœ¨ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰æ‰§è¡Œæµ‹è¯•
    main()
