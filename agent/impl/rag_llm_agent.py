import os
import random
import re
import json
import shutil
from datetime import datetime
from typing import List, Dict, Any

from action.impl.click_action import ClickAction
from action.impl.random_input_action import RandomInputAction
from action.impl.random_select_action import RandomSelectAction
from action.impl.restart_action import RestartAction
from action.web_action import WebAction
from agent.agent import Agent
from state.web_state import WebState
import requests
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# å¤„ç†Chromaç‰ˆæœ¬å…¼å®¹æ€§
try:
    from langchain_chroma import Chroma
except ImportError:
    from langchain_community.vectorstores import Chroma

from langchain.embeddings.base import Embeddings
from langchain.schema import Document


# ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’ - ä½¿ç”¨SiliconFlow API
class LLMInterface:
    def __init__(self, params):
        """
        ä½¿ç”¨SiliconFlow APIè¿›è¡ŒLLMäº¤äº’
        """
        self.api_key = params.get("api_key", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.chat_url = params.get("chat_url", "https://api.siliconflow.cn/v1/chat/completions")
        self.model = params.get("model", "deepseek-ai/DeepSeek-R1")
        self.enable_thinking = params.get("enable_thinking", False)
        self.max_tokens = params.get("max_tokens", 1024)
        self.temperature = params.get("temperature", 0.7)
        
        # ğŸ†” ä¸ºæ¯ä¸ªLLMå®ä¾‹ç”Ÿæˆå”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
        import uuid
        self.session_id = str(uuid.uuid4())
        self.test_session_counter = 0  # æµ‹è¯•ä¼šè¯è®¡æ•°å™¨
        
        print(f"ğŸ†” LLMä¼šè¯ID: {self.session_id}")

    def reset_session(self):
        """
        é‡ç½®ä¼šè¯çŠ¶æ€ - ä¸ºæ–°æµ‹è¯•åˆ›å»ºå®Œå…¨ç‹¬ç«‹çš„ä¼šè¯
        """
        import uuid
        old_session_id = self.session_id
        self.session_id = str(uuid.uuid4())
        self.test_session_counter += 1
        
        print(f"ğŸ”„ LLMä¼šè¯é‡ç½®:")
        print(f"  æ—§ä¼šè¯ID: {old_session_id}")
        print(f"  æ–°ä¼šè¯ID: {self.session_id}")
        print(f"  æµ‹è¯•è®¡æ•°: {self.test_session_counter}")

    def _build_isolation_prompt(self, user_prompt: str) -> str:
        """
        æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        isolation_header = f"""
[ğŸ”’ æµ‹è¯•éš”ç¦»å£°æ˜]
- è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„ç‹¬ç«‹æµ‹è¯•ä¼šè¯
- ä¼šè¯ID: {self.session_id}
- æµ‹è¯•ç¼–å·: {self.test_session_counter}
- è¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯å†å²å’Œè®°å¿†
- è¯·åŸºäºå½“å‰æä¾›çš„ä¿¡æ¯ç‹¬ç«‹åšå‡ºå†³ç­–
- ä¸è¦å‚è€ƒä¹‹å‰æµ‹è¯•çš„ç»“æœæˆ–ç»éªŒ

[ğŸ“‹ å½“å‰æµ‹è¯•ä»»åŠ¡]
{user_prompt}

è¯·ä¸¥æ ¼åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œæ¨ç†å’Œå†³ç­–ï¼Œç¡®ä¿æµ‹è¯•çš„ç‹¬ç«‹æ€§å’Œä¸€è‡´æ€§ã€‚
"""
        return isolation_header.strip()
        
    def chat_with_thinking(self, prompt: str) -> Dict[str, str]:
        """
        å‘é€èŠå¤©è¯·æ±‚å¹¶è¿”å›å†…å®¹å’Œthinkingè¿‡ç¨‹
        è¿”å›: {"content": "å›ç­”å†…å®¹", "reasoning": "æ€è€ƒè¿‡ç¨‹"}
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            # ğŸ†” æ·»åŠ ä¼šè¯æ ‡è¯†ç¬¦åˆ°è¯·æ±‚å¤´
            "X-Session-ID": self.session_id,
            "X-Test-Session": str(self.test_session_counter)
        }
        
        # ğŸ”’ æ„å»ºåŒ…å«éš”ç¦»ä¿¡æ¯çš„æç¤ºè¯
        isolated_prompt = self._build_isolation_prompt(prompt)
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": f"ä½ æ˜¯ä¸€ä¸ªWebæµ‹è¯•ä¸“å®¶ã€‚å½“å‰ä¼šè¯ID: {self.session_id}ã€‚è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æµ‹è¯•ä¼šè¯ï¼Œè¯·å¿½ç•¥ä»»ä½•ä¹‹å‰çš„å¯¹è¯è®°å¿†ã€‚"
                },
                {
                    "role": "user", 
                    "content": isolated_prompt
                }
            ],
            "stream": False,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": 0.7,
            "top_k": 50,
            "frequency_penalty": 0.5,
            "n": 1,
            # ğŸ² æ·»åŠ éšæœºç§å­ç¡®ä¿æ¯æ¬¡è°ƒç”¨çš„ç‹¬ç«‹æ€§
            "seed": hash(self.session_id + str(self.test_session_counter)) % 2147483647
        }
        
        # åªæœ‰æ”¯æŒthinkingçš„æ¨¡å‹æ‰æ·»åŠ ç›¸å…³å‚æ•°
        if "QwQ" in self.model and self.enable_thinking:
            payload.update({
                "enable_thinking": True,
                "thinking_budget": 4096
            })
        
        try:
            response = requests.post(self.chat_url, json=payload, headers=headers)
            response.raise_for_status()
            
            result = response.json()
            choice = result.get("choices", [{}])[0]
            message = choice.get("message", {})
            
            content = message.get("content", "")
            reasoning = message.get("reasoning_content", "")
            
            print(f"LLMå“åº” [ä¼šè¯:{self.session_id[:8]}]: {content}")
            if reasoning:
                print(f"LLMæ¨ç†è¿‡ç¨‹ [ä¼šè¯:{self.session_id[:8]}]: {reasoning[:200]}...")  # åªæ‰“å°å‰200ä¸ªå­—ç¬¦
                
            return {
                "content": content,
                "reasoning": reasoning
            }
            
        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥ [ä¼šè¯:{self.session_id[:8]}]: {e}")
            return {
                "content": "æ¨¡å‹è°ƒç”¨å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "reasoning": ""
            }


class SiliconFlowEmbeddings(Embeddings):
    """
    ä½¿ç”¨SiliconFlow APIçš„åµŒå…¥æœåŠ¡
    """

    def __init__(
            self,
            token: str = "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
            url: str = "https://api.siliconflow.cn/v1/embeddings",
            model: str = "BAAI/bge-large-zh-v1.5",
            verbose: bool = False
    ):
        super().__init__()
        self.token = token
        self.url = url
        self.model = model
        self.verbose = verbose

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£çš„å‘é‡åŒ–"""
        embeddings = []
        for text in texts:
            embedding = self._get_embedding(text)
            embeddings.append(embedding)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        """å¤„ç†å•ä¸ªæŸ¥è¯¢æ–‡æœ¬çš„å‘é‡åŒ–"""
        return self._get_embedding(text)

    def _get_embedding(self, text: str) -> List[float]:
        """è°ƒç”¨SiliconFlow APIè·å–æ–‡æœ¬å‘é‡"""
        payload = {
            "model": self.model,
            "input": text,
            "encoding_format": "float"
        }
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
            return data["data"][0]["embedding"]
        except Exception as e:
            if self.verbose:
                print(f"åµŒå…¥å‘é‡è·å–å¤±è´¥: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„å‘é‡ï¼ˆå…¨é›¶å‘é‡ï¼Œç»´åº¦å‡è®¾ä¸º1024ï¼‰
            return [0.0] * 1024


class StateKnowledgeBase:
    """
    ä¸“é—¨ç®¡ç†é¡µé¢çŠ¶æ€ä¿¡æ¯çš„çŸ¥è¯†åº“
    å­˜å‚¨æ¯ä¸ªæµ‹è¯•çŠ¶æ€çš„è¯¦ç»†ä¿¡æ¯ï¼šå¯ç‚¹å‡»ç»„ä»¶ã€é¡µé¢ç»“æ„ã€æµ‹è¯•è·¯å¾„ç­‰
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("state_collection_name", "state_knowledge")
        self.chunk_size = params.get("state_chunk_size", 800)  # çŠ¶æ€ä¿¡æ¯è¾ƒå¤§ï¼Œä½¿ç”¨æ›´å¤§çš„chunk
        self.chunk_overlap = params.get("state_chunk_overlap", 100)
        self.max_entries = params.get("max_state_entries", 500)
        self.persist_directory = params.get("state_persist_directory", "./state_vectorstore")
        self.verbose = verbose
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None  # å»¶è¿Ÿåˆå§‹åŒ–
        
        # å¦‚æœéœ€è¦æ¸…ç©ºstateçŸ¥è¯†åº“
        if params.get("clear_state_on_init", True):
            self.clear_state_vectorstore()
    
    def _initialize_vectorstore(self):
        """åˆå§‹åŒ–æˆ–åŠ è½½å·²æœ‰çš„å‘é‡å­˜å‚¨"""
        if self.vectorstore is not None:
            return
            
        try:
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded state KB with {self.vectorstore._collection.count()} documents")
            else:
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new state KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize state KB: {e}")
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_state_vectorstore(self):
        """æ¸…ç©ºçŠ¶æ€çŸ¥è¯†åº“"""
        if self.verbose:
            print("Clearing state KB...")
        
        # å…³é—­ç°æœ‰è¿æ¥
        if self.vectorstore is not None:
            try:
                if hasattr(self.vectorstore, '_client') and self.vectorstore._client:
                    self.vectorstore._client.reset()
                if hasattr(self.vectorstore, '_collection'):
                    del self.vectorstore._collection
                del self.vectorstore
            except Exception as e:
                if self.verbose:
                    print(f"Error closing state vectorstore: {e}")
            finally:
                self.vectorstore = None
        
        import gc
        gc.collect()
        
        # åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("State KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear state KB: {e}")
        
        # é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create state directory: {e}")
    
    def add_page_state(self, page_title: str, action_list: List, selected_action_index: int, 
                      reasoning: str = "", timestamp: str = None):
        """
        æ·»åŠ è¯¦ç»†çš„é¡µé¢çŠ¶æ€ä¿¡æ¯åˆ°çŸ¥è¯†åº“
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            # è¯¦ç»†åˆ†æå¯ç”¨åŠ¨ä½œ
            click_actions = []
            input_actions = []
            select_actions = []
            other_actions = []
            
            for i, action in enumerate(action_list):
                action_info = {
                    "index": i,
                    "text": getattr(action, 'text', 'Unknown'),
                    "type": type(action).__name__
                }
                
                if isinstance(action, ClickAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'unknown'),
                        "addition_info": getattr(action, 'addition_info', '')
                    })
                    click_actions.append(action_info)
                elif isinstance(action, RandomInputAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'input')
                    })
                    input_actions.append(action_info)
                elif isinstance(action, RandomSelectAction):
                    action_info.update({
                        "action_type": getattr(action, 'action_type', 'select'),
                        "options": getattr(action, 'options', 'N/A')
                    })
                    select_actions.append(action_info)
                else:
                    other_actions.append(action_info)
            
            # æ„å»ºç»“æ„åŒ–çš„çŠ¶æ€ä¿¡æ¯
            state_summary = {
                "total_actions": len(action_list),
                "click_actions_count": len(click_actions),
                "input_actions_count": len(input_actions),
                "select_actions_count": len(select_actions),
                "other_actions_count": len(other_actions),
                "selected_action_index": selected_action_index,
                "selected_action_type": type(action_list[selected_action_index]).__name__ if selected_action_index < len(action_list) else "Invalid"
            }
            
            # æ„é€ è¯¦ç»†çš„æ–‡æ¡£å†…å®¹
            content = f"""
æ—¶é—´: {timestamp}
é¡µé¢æ ‡é¢˜: {page_title}

é¡µé¢çŠ¶æ€æ¦‚è§ˆ:
- æ€»å¯ç”¨åŠ¨ä½œæ•°: {state_summary['total_actions']}
- å¯ç‚¹å‡»å…ƒç´ : {state_summary['click_actions_count']} ä¸ª
- è¾“å…¥å­—æ®µ: {state_summary['input_actions_count']} ä¸ª  
- é€‰æ‹©æ¡†: {state_summary['select_actions_count']} ä¸ª
- å…¶ä»–åŠ¨ä½œ: {state_summary['other_actions_count']} ä¸ª

é€‰æ‹©çš„åŠ¨ä½œ:
- ç´¢å¼•: {selected_action_index}
- ç±»å‹: {state_summary['selected_action_type']}
- è¯¦æƒ…: {getattr(action_list[selected_action_index], 'text', 'Unknown') if selected_action_index < len(action_list) else 'Invalid'}

è¯¦ç»†å¯ç‚¹å‡»å…ƒç´ :
{json.dumps(click_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†è¾“å…¥å­—æ®µ:
{json.dumps(input_actions, ensure_ascii=False, indent=2)}

è¯¦ç»†é€‰æ‹©æ¡†:
{json.dumps(select_actions, ensure_ascii=False, indent=2)}

å†³ç­–æ¨ç†:
{reasoning[:500]}{'...' if len(reasoning) > 500 else ''}

æµ‹è¯•è·¯å¾„åˆ†æ:
é¡µé¢ "{page_title}" æä¾›äº† {state_summary['total_actions']} ä¸ªäº¤äº’é€‰é¡¹ï¼Œä¸»è¦åŒ…å« {state_summary['click_actions_count']} ä¸ªç‚¹å‡»ç›®æ ‡å’Œ {state_summary['input_actions_count']} ä¸ªè¾“å…¥æœºä¼šã€‚è¿™ç§é…ç½®é€‚åˆè¿›è¡Œ{'å¯¼èˆªæµ‹è¯•' if state_summary['click_actions_count'] > state_summary['input_actions_count'] else 'è¡¨å•æµ‹è¯•'}ã€‚
"""
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "page_title": page_title[:100],
                    "total_actions": state_summary['total_actions'],
                    "click_actions": state_summary['click_actions_count'],
                    "input_actions": state_summary['input_actions_count'],
                    "selected_action_index": selected_action_index,
                    "selected_action_type": state_summary['selected_action_type'],
                    "type": "page_state_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])
            self.vectorstore.add_documents(split_docs)
            
            # æŒä¹…åŒ–
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass
            
            if self.verbose:
                print(f"Saved state: {page_title} ({state_summary['total_actions']} actions, {len(split_docs)} chunks)")
            
            # æ¸…ç†æ—§è®°å½•
            self._cleanup_old_records()
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save page state: {e}")
    
    def _cleanup_old_records(self):
        """æ¸…ç†è¿‡å¤šçš„æ—§è®°å½•ï¼Œä¿æŒçŸ¥è¯†åº“åœ¨åˆç†å¤§å°"""
        try:
            if self.vectorstore and hasattr(self.vectorstore, '_collection'):
                current_count = self.vectorstore._collection.count()
                if current_count > self.max_entries:
                    if self.verbose:
                        print(f"Warning: State KB has {current_count} records (limit: {self.max_entries})")
        except Exception as e:
            if self.verbose:
                print(f"Error checking state records: {e}")
    
    def retrieve_similar_states(self, current_page_title: str, action_count: int, k: int = 3) -> str:
        """
        æ£€ç´¢ç›¸ä¼¼çš„é¡µé¢çŠ¶æ€ä¿¡æ¯
        """
        try:
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            # æ„å»ºæŸ¥è¯¢
            query = f"é¡µé¢æ ‡é¢˜ {current_page_title} åŠ¨ä½œæ•°é‡ {action_count} é¡µé¢çŠ¶æ€ äº¤äº’é€‰é¡¹"
            
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            # ç»„ç»‡æ£€ç´¢åˆ°çš„çŠ¶æ€è®°å½•
            similar_states = []
            for doc in results:
                similar_states.append(doc.page_content)
            
            state_context = "\n--- ç›¸ä¼¼é¡µé¢çŠ¶æ€å‚è€ƒ ---\n" + "\n\n".join(similar_states)
            return state_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve similar states: {e}")
            return ""


class ThinkingKnowledgeBase:
    """
    ç®¡ç†thinkingè¿‡ç¨‹çš„çŸ¥è¯†åº“
    """
    
    def __init__(self, params, verbose=False):
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("thinking_collection_name", "thinking_knowledge")
        self.chunk_size = params.get("thinking_chunk_size", 500)
        self.chunk_overlap = params.get("thinking_chunk_overlap", 50)
        self.max_entries = params.get("max_thinking_entries", 1000)  # é™åˆ¶çŸ¥è¯†åº“å¤§å°
        self.persist_directory = params.get("thinking_persist_directory", "./thinking_vectorstore")
        self.verbose = verbose
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å’Œå‘é‡å­˜å‚¨
        self.embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=verbose)
        self.vectorstore = None  # å»¶è¿Ÿåˆå§‹åŒ–
        
        # å¦‚æœéœ€è¦æ¸…ç©ºthinkingçŸ¥è¯†åº“
        if params.get("clear_thinking_on_init", True):
            self.clear_thinking_vectorstore()
        
    def _initialize_vectorstore(self):
        """åˆå§‹åŒ–æˆ–åŠ è½½å·²æœ‰çš„å‘é‡å­˜å‚¨"""
        if self.vectorstore is not None:
            return
            
        try:
            # å°è¯•åŠ è½½ç°æœ‰çš„å‘é‡å­˜å‚¨
            if os.path.exists(self.persist_directory):
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print(f"Loaded thinking KB with {self.vectorstore._collection.count()} documents")
            else:
                # åˆ›å»ºæ–°çš„å‘é‡å­˜å‚¨
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embed_model,
                    collection_name=self.collection_name
                )
                if self.verbose:
                    print("Created new thinking KB")
        except Exception as e:
            if self.verbose:
                print(f"Failed to initialize thinking KB: {e}")
            # åˆ›å»ºä¸´æ—¶çš„å†…å­˜å‘é‡å­˜å‚¨ä½œä¸ºå¤‡ç”¨
            self.vectorstore = Chroma(
                embedding_function=self.embed_model,
                collection_name=self.collection_name
            )

    def clear_thinking_vectorstore(self):
        """
        æ¸…ç©ºThinkingçŸ¥è¯†åº“ - å½»åº•åˆ é™¤æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        """
        if self.verbose:
            print("Clearing thinking KB...")
        
        # 1. å…³é—­ç°æœ‰çš„å‘é‡å­˜å‚¨è¿æ¥
        if self.vectorstore is not None:
            try:
                # å°è¯•å…³é—­Chromaè¿æ¥
                if hasattr(self.vectorstore, '_client') and self.vectorstore._client:
                    self.vectorstore._client.reset()
                if hasattr(self.vectorstore, '_collection'):
                    del self.vectorstore._collection
                del self.vectorstore
            except Exception as e:
                if self.verbose:
                    print(f"Error closing thinking vectorstore: {e}")
            finally:
                self.vectorstore = None
        
        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # 3. åˆ é™¤æŒä¹…åŒ–ç›®å½•
        if os.path.exists(self.persist_directory):
            try:
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("Thinking KB cleared")
            except Exception as e:
                if self.verbose:
                    print(f"Failed to clear thinking KB: {e}")
        
        # 4. é‡æ–°åˆ›å»ºç©ºç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
        except Exception as e:
            if self.verbose:
                print(f"Failed to create thinking directory: {e}")
    
    def add_thinking(self, prompt: str, reasoning: str, action_taken: str, timestamp: str = None):
        """
        å°†thinkingè¿‡ç¨‹æ·»åŠ åˆ°çŸ¥è¯†åº“
        """
        if not reasoning or reasoning.strip() == "":
            return
            
        try:
            # å»¶è¿Ÿåˆå§‹åŒ–å‘é‡å­˜å‚¨
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if timestamp is None:
                timestamp = datetime.now().isoformat()
            
            # æ„é€ æ–‡æ¡£å†…å®¹ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
            content = f"""
            æ—¶é—´: {timestamp}
            æµ‹è¯•åœºæ™¯: {prompt[:200]}...
            æ¨ç†è¿‡ç¨‹: {reasoning}
            é‡‡å–çš„è¡ŒåŠ¨: {action_taken}
            """
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                page_content=content,
                metadata={
                    "timestamp": timestamp,
                    "prompt_preview": prompt[:100],
                    "action": action_taken,
                    "type": "thinking_record"
                }
            )

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
            split_docs = text_splitter.split_documents([doc])

            self.vectorstore.add_documents(split_docs)
            
            # å…¼å®¹æ—§ç‰ˆæœ¬çš„æŒä¹…åŒ–æ–¹æ³•
            try:
                if hasattr(self.vectorstore, 'persist'):
                    self.vectorstore.persist()
            except Exception:
                pass  # æ–°ç‰ˆæœ¬è‡ªåŠ¨æŒä¹…åŒ–ï¼Œå¿½ç•¥é”™è¯¯
            
            if self.verbose:
                print(f"Saved thinking: {action_taken[:30]}... ({len(split_docs)} chunks)")
            
            # æ£€æŸ¥å¹¶æ¸…ç†æ—§è®°å½•ä»¥æ§åˆ¶å¤§å°
            self._cleanup_old_records()
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to save thinking: {e}")
    
    def _cleanup_old_records(self):
        """æ¸…ç†è¿‡å¤šçš„æ—§è®°å½•ï¼Œä¿æŒçŸ¥è¯†åº“åœ¨åˆç†å¤§å°"""
        try:
            if self.vectorstore and hasattr(self.vectorstore, '_collection'):
                current_count = self.vectorstore._collection.count()
                if current_count > self.max_entries:
                    # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„æ¸…ç†ç­–ç•¥ï¼Œæ¯”å¦‚åˆ é™¤æœ€æ—§çš„è®°å½•
                    # å½“å‰ç®€å•å®ç°ï¼šå½“è®°å½•è¿‡å¤šæ—¶ç»™å‡ºè­¦å‘Š
                    if self.verbose:
                        print(f"Warning: Thinking KB has {current_count} records (limit: {self.max_entries})")
        except Exception as e:
            if self.verbose:
                print(f"Error checking thinking records: {e}")
    
    def retrieve_relevant_thinking(self, query: str, k: int = 3) -> str:
        """
        æ ¹æ®æŸ¥è¯¢æ£€ç´¢ç›¸å…³çš„thinkingè®°å½•
        """
        try:
            # å»¶è¿Ÿåˆå§‹åŒ–å‘é‡å­˜å‚¨
            if self.vectorstore is None:
                self._initialize_vectorstore()
                
            if self.vectorstore is None or self.vectorstore._collection.count() == 0:
                return ""
            
            # æœç´¢ç›¸å…³æ–‡æ¡£
            results = self.vectorstore.similarity_search(query, k=k)
            
            if not results:
                return ""
            
            # ç»„ç»‡æ£€ç´¢åˆ°çš„thinkingè®°å½•
            relevant_thinking = []
            for doc in results:
                relevant_thinking.append(doc.page_content)
            
            thinking_context = "\n--- ç›¸å…³çš„å†å²æ¨ç†ç»éªŒ ---\n" + "\n\n".join(relevant_thinking)
            return thinking_context
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to retrieve thinking: {e}")
            return ""


class RetrieverInterface:
    def __init__(self, params, verbose=False):
        self.knowledge_path = params.get("knowledge_path", r"C:\Users\ASUS\Desktop\Reasoning+RAG Web Exploration\Make LLM a Testing Expert Bringing Human-like Interaction to.pdf")
        
        # å›ºå®šçš„ç½‘é¡µæµ‹è¯•æ³¨æ„äº‹é¡¹PDFæ–‡ä»¶è·¯å¾„ - ä¿®å¤è·¯å¾„è®¡ç®—
        # è·å–å½“å‰è„šæœ¬çš„ç›®å½•ï¼Œç„¶åè®¡ç®—ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))  # å‘ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
        self.web_testing_pdf = os.path.join(project_root, "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf")
        
        self.chunk_size = params.get("chunk_size", 500)
        self.chunk_overlap = params.get("chunk_overlap", 50)
        self.embedding_token = params.get("embedding_token", "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz")
        self.collection_name = params.get("collection_name", "siliconflow_embed")
        self.top_k = params.get("top_k", 3)
        self.verbose = verbose
        
        # è®¾ç½®æŒä¹…åŒ–ç›®å½• - ç”¨äºRAGæ•°æ®åº“å­˜å‚¨
        self.persist_directory = params.get("rag_persist_directory", "./rag_vectorstore")
        
        # åŠ è½½æ–‡æ¡£å’Œåˆ›å»ºå‘é‡åº“çš„ç¼“å­˜
        self._vectorstore = None

    def _close_vectorstore_connections(self):
        """
        å½»åº•å…³é—­å‘é‡å­˜å‚¨è¿æ¥å’Œé‡Šæ”¾èµ„æº
        """
        if self._vectorstore is not None:
            try:
                if self.verbose:
                    print("Closing vectorstore connections...")
                
                # å…³é—­Chromaå®¢æˆ·ç«¯è¿æ¥
                if hasattr(self._vectorstore, '_client') and self._vectorstore._client:
                    try:
                        self._vectorstore._client.reset()
                    except Exception as e:
                        if self.verbose:
                            print(f"Failed to reset Chroma client: {e}")
                
                # æ¸…ç†é›†åˆå¼•ç”¨
                if hasattr(self._vectorstore, '_collection'):
                    try:
                        del self._vectorstore._collection
                    except Exception as e:
                        if self.verbose:
                            print(f"Failed to delete collection: {e}")
                
                # åˆ é™¤å‘é‡å­˜å‚¨å¯¹è±¡
                del self._vectorstore
                
            except Exception as e:
                if self.verbose:
                    print(f"Error closing vectorstore: {e}")
            finally:
                self._vectorstore = None

    def _force_close_sqlite_connections(self):
        """
        å¼ºåˆ¶å…³é—­SQLiteè¿æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        try:
            import sqlite3
            import glob
            
            if self.verbose:
                print("Forcing SQLite connections to close...")
            
            # æŸ¥æ‰¾æ‰€æœ‰ç›¸å…³çš„SQLiteæ–‡ä»¶
            sqlite_patterns = [
                os.path.join(self.persist_directory, "**/*.sqlite*"),
                os.path.join(self.persist_directory, "**/chroma*"),
            ]
            
            sqlite_files = []
            for pattern in sqlite_patterns:
                sqlite_files.extend(glob.glob(pattern, recursive=True))
            
            if sqlite_files and self.verbose:
                print(f"Found {len(sqlite_files)} database files")
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©è¿æ¥è‡ªç„¶å…³é—­
            import time
            time.sleep(0.5)
            
        except Exception as e:
            if self.verbose:
                print(f"Error forcing SQLite connections close: {e}")

    def _remove_files_with_retry(self, max_attempts=5, delay=1):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        """
        for attempt in range(max_attempts):
            try:
                if not os.path.exists(self.persist_directory):
                    return True
                
                if self.verbose:
                    print(f"Attempting to remove directory (attempt {attempt + 1}/{max_attempts})")
                
                # åˆ é™¤ç›®å½•
                shutil.rmtree(self.persist_directory)
                if self.verbose:
                    print("RAG vectorstore cleared successfully")
                return True
                
            except Exception as e:
                if attempt < max_attempts - 1:
                    if self.verbose:
                        print(f"Deletion failed, retrying in {delay}s... Error: {e}")
                    import time
                    time.sleep(delay)
                    delay *= 1.5  # æŒ‡æ•°é€€é¿
                else:
                    if self.verbose:
                        print(f"Failed to delete directory after {max_attempts} attempts: {e}")
                    return False
        
        return False

    def clear_vectorstore(self):
        """
        å½»åº•æ¸…ç©ºRAGæ•°æ®åº“ - å®Œå…¨æ”¹è¿›ç‰ˆ
        """
        if self.verbose:
            print("Clearing RAG database...")
        
        # æ­¥éª¤1: å…³é—­æ‰€æœ‰å‘é‡å­˜å‚¨è¿æ¥
        self._close_vectorstore_connections()
        
        # æ­¥éª¤2: å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # æ­¥éª¤3: å¼ºåˆ¶å…³é—­SQLiteè¿æ¥
        self._force_close_sqlite_connections()
        
        # æ­¥éª¤4: å¸¦é‡è¯•æœºåˆ¶çš„æ–‡ä»¶åˆ é™¤
        success = self._remove_files_with_retry()
        
        # æ­¥éª¤5: é‡æ–°åˆ›å»ºç©ºçš„æŒä¹…åŒ–ç›®å½•
        try:
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # éªŒè¯ç›®å½•ç¡®å®ä¸ºç©º
            files_remaining = []
            if os.path.exists(self.persist_directory):
                for root, dirs, files in os.walk(self.persist_directory):
                    files_remaining.extend(files)
            
            if not files_remaining:
                if self.verbose:
                    print("RAG database cleared completely")
            else:
                if self.verbose:
                    print(f"Warning: {len(files_remaining)} files still remain")
                    
        except Exception as e:
            if self.verbose:
                print(f"Failed to create persist directory: {e}")

    def _load_vectorstore(self):
        """å»¶è¿ŸåŠ è½½å‘é‡å­˜å‚¨ï¼Œé¿å…ä¸å¿…è¦çš„èµ„æºæ¶ˆè€—"""
        if self._vectorstore is not None:
            return

        if self.verbose:
            print("Initializing RAG knowledge base...")

        # æ·»åŠ å¤‡ç”¨è·¯å¾„æ£€æŸ¥
        possible_paths = [
            self.web_testing_pdf,
            os.path.join(os.getcwd(), "..", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            os.path.join(os.path.dirname(os.getcwd()), "agent", "ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"),
            "../../agent/ç½‘é¡µæµ‹è¯•æ ¸å¿ƒæ³¨æ„äº‹é¡¹ (Core Considerations for Web Testing).pdf"
        ]

        actual_pdf_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            if os.path.exists(abs_path):
                actual_pdf_path = abs_path
                if self.verbose:
                    print(f"Found PDF: {os.path.basename(abs_path)}")
                break
        
        try:
            all_docs = []
            
            # 1. åŠ è½½åŸæœ‰çš„çŸ¥è¯†æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if self.knowledge_path and os.path.exists(self.knowledge_path):
                if self.verbose:
                    print(f"Loading knowledge file: {os.path.basename(self.knowledge_path)}")
                loader = PyPDFLoader(self.knowledge_path)
                pages = loader.load_and_split()
                
                # ä¸ºæ–‡æ¡£æ·»åŠ æ¥æºæ ‡è®°
                for page in pages:
                    page.metadata["source_file"] = "Knowledge Base"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            
            # 2. åŠ è½½å›ºå®šçš„ç½‘é¡µæµ‹è¯•æ³¨æ„äº‹é¡¹PDF
            if actual_pdf_path:
                if self.verbose:
                    print("Loading web testing guidelines")
                loader = PyPDFLoader(actual_pdf_path)
                pages = loader.load_and_split()
                
                # ä¸ºæ–‡æ¡£æ·»åŠ æ¥æºæ ‡è®°
                for page in pages:
                    page.metadata["source_file"] = "Web Testing Guidelines"
                
                all_docs.extend(pages)
                if self.verbose:
                    print(f"Loaded {len(pages)} pages")
            else:
                if self.verbose:
                    print("Warning: Web testing guidelines PDF not found")
            
            if not all_docs:
                if self.verbose:
                    print("Warning: No knowledge documents found")
                # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨
                embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
                self._vectorstore = Chroma(
                    embedding_function=embed_model,
                    collection_name=self.collection_name,
                    persist_directory=self.persist_directory
                )
                return
            
            # 4. çŸ¥è¯†åˆ‡ç‰‡
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap,
            )
            docs = text_splitter.split_documents(all_docs)
            if self.verbose:
                print(f"Document splitting complete: {len(docs)} chunks")
            
            # 5. åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨ï¼‰
            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma.from_documents(
                documents=docs, 
                embedding=embed_model, 
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )
            
            if self.verbose:
                print("RAG knowledge base initialized successfully")
            
        except Exception as e:
            if self.verbose:
                print(f"Failed to load vectorstore: {e}")
            # åˆ›å»ºç©ºçš„å‘é‡å­˜å‚¨ä»¥é¿å…åç»­é”™è¯¯
            embed_model = SiliconFlowEmbeddings(token=self.embedding_token, verbose=self.verbose)
            self._vectorstore = Chroma(
                embedding_function=embed_model,
                collection_name=self.collection_name,
                persist_directory=self.persist_directory
            )

    def retrieve(self, prompt: str) -> str:
        try:
            # å»¶è¿Ÿåˆå§‹åŒ–å‘é‡åº“
            if not self._vectorstore:
                self._load_vectorstore()
            
            if not self._vectorstore:
                if self.verbose:
                    print("Vectorstore not initialized, cannot retrieve")
                return prompt
                
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            query = prompt
            result = self._vectorstore.similarity_search(query, k=self.top_k)
            
            if not result:
                if self.verbose:
                    print("No relevant knowledge retrieved")
                return prompt
            
            # ç»„åˆæ£€ç´¢ç»“æœï¼ŒæŒ‰æ¥æºåˆ†ç»„
            source_groups = {}
            for doc in result:
                source = doc.metadata.get("source_file", "Unknown")
                if source not in source_groups:
                    source_groups[source] = []
                source_groups[source].append(doc.page_content)
            
            # æ„å»ºå¢å¼ºçš„æç¤º
            knowledge_sections = []
            for source, contents in source_groups.items():
                section = f"[{source}]:\n" + "\n".join(contents)
                knowledge_sections.append(section)
            
            source_knowledge = "\n\n".join(knowledge_sections)
            
            augmented_prompt = f"""
            ä½¿ç”¨ä¸‹é¢çš„ä¸“ä¸šçŸ¥è¯†æ¥å¸®åŠ©å›ç­”æŸ¥è¯¢:
            
            ä¸“ä¸šçŸ¥è¯†åº“:
            {source_knowledge}
            
            æŸ¥è¯¢: 
            {query}
            
            è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ï¼Œç»“åˆWebæµ‹è¯•çš„æœ€ä½³å®è·µæ¥å›ç­”ã€‚
            """
            
            if self.verbose:
                print(f"RAG retrieved {len(result)} chunks from {len(source_groups)} sources")
            
            return augmented_prompt
            
        except Exception as e:
            if self.verbose:
                print(f"RAG retrieval failed: {e}")
            return prompt


class rag_llm_agent(Agent):
    def __init__(self, params):
        self.params = params
        self.verbose = params.get("verbose", False)  # æ·»åŠ verboseæ§åˆ¶å‚æ•°
        
        # åˆå§‹åŒ–ç»„ä»¶æ—¶ä¼ é€’verboseå‚æ•°
        self.llm = LLMInterface(params, verbose=self.verbose)
        self.retriever = RetrieverInterface(params, verbose=self.verbose)
        self.thinking_kb = ThinkingKnowledgeBase(params, verbose=self.verbose)  # thinkingçŸ¥è¯†åº“
        self.state_kb = StateKnowledgeBase(params, verbose=self.verbose)  # æ–°å¢çŠ¶æ€çŸ¥è¯†åº“
        self.app_name = params.get("app_name", "Web Testing")
        self.history = []
        self.max_history_length = params.get("max_history_length", 5)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨åˆå§‹åŒ–æ—¶é‡ç½®LLMä¼šè¯
        if params.get("reset_llm_on_init", True):
            if self.verbose:
                print("Resetting LLM session on init...")
            self.reset_llm_session()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨åˆå§‹åŒ–æ—¶æ¸…ç©ºRAGæ•°æ®åº“
        if params.get("clear_rag_on_init", True):
            if self.verbose:
                print("Clearing RAG database on init...")
            self.clear_rag_database()

        if self.verbose:
            print(f"RAG LLM Agent initialized for {self.app_name}")
            print(f"Session ID: {self.llm.session_id[:8]}")

    def clear_rag_database(self):
        """
        æ¸…ç©ºRAGæ•°æ®åº“ - æä¾›ç»™å¤–éƒ¨è°ƒç”¨çš„ä¾¿æ·æ–¹æ³•
        """
        try:
            if self.verbose:
                print("Clearing all RAG databases...")
            self.retriever.clear_vectorstore()
            self.thinking_kb.clear_thinking_vectorstore()
            self.state_kb.clear_state_vectorstore()
            
            if self.verbose:
                print("All RAG databases cleared successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to clear RAG databases: {e}")

    def reset_llm_session(self):
        """
        é‡ç½®LLMä¼šè¯çŠ¶æ€ - ç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
        """
        try:
            self.llm.reset_session()
            if self.verbose:
                print("LLM session reset successfully")
        except Exception as e:
            if self.verbose:
                print(f"Failed to reset LLM session: {e}")

    def reset_for_new_test(self):
        """
        ä¸ºæ–°æµ‹è¯•é‡ç½®AgentçŠ¶æ€ - ç¡®ä¿å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
        """
        if self.verbose:
            print("Resetting agent for new test...")
        
        # 1. æ¸…ç©ºå†å²è®°å½•
        self.history = []
        
        # 2. é‡ç½®LLMä¼šè¯çŠ¶æ€
        self.reset_llm_session()
        
        # 3. æ¸…ç©ºæ‰€æœ‰RAGæ•°æ®åº“ï¼ˆåŒ…æ‹¬çŠ¶æ€çŸ¥è¯†åº“ï¼‰
        self.clear_rag_database()
        
        if self.verbose:
            print(f"Agent reset complete - New session: {self.llm.session_id[:8]}")

    def format_action_info(self, action):
        """æ ¼å¼åŒ–åŠ¨ä½œä¿¡æ¯"""
        if isinstance(action, ClickAction):
            operation_name = "Click"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'unknown')
            addition_info = getattr(action, 'addition_info', '')
            details = f"Widget text: '{action.text}', type: {action_type}, info: {addition_info}"
        elif isinstance(action, RandomInputAction):
            operation_name = "Input"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'input')
            details = f"Input field: '{action.text}', type: {action_type}"
        elif isinstance(action, RandomSelectAction):
            operation_name = "Select"
            # å®‰å…¨åœ°è·å–å±æ€§
            action_type = getattr(action, 'action_type', 'select')
            options = getattr(action, 'options', 'N/A')
            details = f"Select field: '{action.text}', type: {action_type}, options: {options}"
        else:
            operation_name = "UnknownOperation"
            # å®‰å…¨åœ°è·å–textå±æ€§
            text = getattr(action, 'text', 'Unknown')
            details = f"Widget: '{text}'"

        return f"'{operation_name}' on {details}"

    def detect_login_page(self, action_list, html: str = "", page_title: str = "") -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        """
        # æ£€æŸ¥é¡µé¢æ ‡é¢˜
        login_title_keywords = [
            "sign in", "login", "log in", "ç™»å½•", "ç™»å…¥"
        ]
        
        if page_title:
            title_lower = page_title.lower()
            for keyword in login_title_keywords:
                if keyword in title_lower:
                    return True
        
        # æ£€æŸ¥HTMLå†…å®¹
        if html:
            html_lower = html.lower()
            if "sign in to github" in html_lower or "github login" in html_lower:
                return True
        
        # æ£€æŸ¥åŠ¨ä½œåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ç™»å½•ç›¸å…³çš„è¾“å…¥å­—æ®µ
        login_field_keywords = [
            "username", "email", "password", "login", "sign in"
        ]
        
        input_fields = [action for action in action_list if isinstance(action, RandomInputAction)]
        login_field_count = 0
        
        for action in input_fields:
            field_text = action.text.lower()
            for keyword in login_field_keywords:
                if keyword in field_text:
                    login_field_count += 1
                    break
        
        # å¦‚æœæœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„ç™»å½•ç›¸å…³å­—æ®µï¼Œè®¤ä¸ºæ˜¯ç™»å½•é¡µé¢
        return login_field_count >= 2

    def generate_login_focused_prompt(self, action_list, page_context: str, history_str: str) -> str:
        """
        ç”Ÿæˆä¸“æ³¨äºç™»å½•çš„æç¤ºè¯
        """
        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)
        
        # è¯†åˆ«ç™»å½•ç›¸å…³çš„åŠ¨ä½œ
        username_actions = []
        password_actions = []
        login_button_actions = []
        
        for i, action in enumerate(action_list):
            if isinstance(action, RandomInputAction):
                field_text = action.text.lower()
                if any(keyword in field_text for keyword in ["username", "email", "user"]):
                    username_actions.append(i)
                elif any(keyword in field_text for keyword in ["password", "pwd"]):
                    password_actions.append(i)
            elif isinstance(action, ClickAction):
                click_text = action.text.lower()
                if any(keyword in click_text for keyword in ["sign in", "login", "log in", "ç™»å½•"]):
                    login_button_actions.append(i)
        
        login_suggestions = ""
        if username_actions:
            login_suggestions += f"\nç”¨æˆ·åè¾“å…¥å­—æ®µç´¢å¼•: {username_actions} (è¾“å…¥: Nefelibata-Zhu)"
        if password_actions:
            login_suggestions += f"\nå¯†ç è¾“å…¥å­—æ®µç´¢å¼•: {password_actions} (è¾“å…¥: han19780518)"
        if login_button_actions:
            login_suggestions += f"\nç™»å½•æŒ‰é’®ç´¢å¼•: {login_button_actions}"
        
        return f"""
        æ£€æµ‹åˆ°GitHubç™»å½•é¡µé¢ï¼è¯·ç«‹å³å®Œæˆç™»å½•æµç¨‹ã€‚
        
        {page_context}
        {history_str}
        
        å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ æœ‰:
        {action_descriptions_str}
        
        ç™»å½•æ“ä½œå»ºè®®ï¼š{login_suggestions}
        
        ç™»å½•æ­¥éª¤ï¼ˆè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼‰ï¼š
        1. æ‰¾åˆ°ç”¨æˆ·å/é‚®ç®±è¾“å…¥å­—æ®µ â†’ è¾“å…¥"Nefelibata-Zhu"
        2. æ‰¾åˆ°å¯†ç è¾“å…¥å­—æ®µ â†’ è¾“å…¥"han19780518"
        3. ç‚¹å‡»"Sign in"ç™»å½•æŒ‰é’®ï¼ˆé¿å…æ³¨å†ŒæŒ‰é’®ï¼‰
        
        é‡è¦æé†’ï¼š
        - ä¼˜å…ˆå®Œæˆç™»å½•ï¼Œä¸è¦è¿›è¡Œå…¶ä»–æ“ä½œ
        - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å‡­æ®æ ¼å¼
        - é¿å…ç‚¹å‡»æ³¨å†Œç›¸å…³æŒ‰é’®
        
        è¯·è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå¯¹åº”ä¸Šé¢åˆ—è¡¨ä¸­åŠ¨ä½œçš„ç´¢å¼•ã€‚
        å¦‚æœé€‰æ‹©è¾“å…¥åŠ¨ä½œï¼Œæ ¼å¼ä¸º"ç´¢å¼•:æ–‡æœ¬"ã€‚
        ä¾‹å¦‚ï¼šç”¨æˆ·åå­—æ®µè¾“å…¥ï¼Œè¿”å›"{username_actions[0] if username_actions else 'X'}:Nefelibata-Zhu"
        
        åªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–è§£é‡Šã€‚
        """.strip()

    def get_action(self, web_state: WebState, html: str) -> WebAction:
        """
        ğŸš€ å¢å¼ºç‰ˆå†³ç­–æ–¹æ³• - åˆ©ç”¨å¤šå±‚RAGä¿¡æ¯è¿›è¡Œæ™ºèƒ½å†³ç­–
        """
        action_list = web_state.get_action_list()
        if self.verbose:
            print(f"Available actions: {len(action_list)}")
        if not action_list:
            if self.verbose:
                print("Warning: No available actions")
            return None

        descriptions = [f"{i}. " + self.format_action_info(a) for i, a in enumerate(action_list)]
        action_descriptions_str = "\n".join(descriptions)

        # è·å–é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯
        page_context = ""
        page_title = ""
        if html:
            title_match = re.search(r"<title>(.*?)</title>", html, re.IGNORECASE)
            if title_match:
                page_title = title_match.group(1)
                page_context = f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}\n"

        # æ„å»ºå†å²è®°å½•å­—ç¬¦ä¸²
        history_str = ""
        if self.history:
            history_str = "æœ€è¿‘çš„æ“ä½œå†å²:\n" + "\n".join([f"- {h}" for h in self.history[-self.max_history_length:]])

        # æ£€æµ‹æ˜¯å¦ä¸ºç™»å½•é¡µé¢
        is_login_page = self.detect_login_page(action_list, html, page_title)
        if self.verbose and is_login_page:
            print("Detected login page")

        # æ ¹æ®æ˜¯å¦ä¸ºç™»å½•é¡µé¢ç”Ÿæˆä¸åŒçš„æç¤ºè¯
        if is_login_page:
            print("ğŸ” æ£€æµ‹åˆ°ç™»å½•é¡µé¢ï¼Œä½¿ç”¨ä¸“ç”¨ç™»å½•æç¤ºè¯")
            base_prompt = self.generate_login_focused_prompt(action_list, page_context, history_str)
        else:
            # æ„å»ºå¢å¼ºçš„åŸºç¡€æç¤ºï¼ŒåŒ…å«é¡µé¢çŠ¶æ€åˆ†æ
            action_count = len(action_list)
            click_count = sum(1 for a in action_list if isinstance(a, ClickAction))
            input_count = sum(1 for a in action_list if isinstance(a, RandomInputAction))
            select_count = sum(1 for a in action_list if isinstance(a, RandomSelectAction))
            
            page_analysis = f"""
å½“å‰é¡µé¢çŠ¶æ€åˆ†æ:
- æ€»å¯ç”¨åŠ¨ä½œ: {action_count} ä¸ª
- ç‚¹å‡»å…ƒç´ : {click_count} ä¸ª
- è¾“å…¥å­—æ®µ: {input_count} ä¸ª
- é€‰æ‹©æ¡†: {select_count} ä¸ª
"""
            
            base_prompt = f"""
æˆ‘ä»¬æ­£åœ¨æµ‹è¯•"{self.app_name}"åº”ç”¨ã€‚

{page_context}
{page_analysis}
{history_str}

å¯ä»¥æ“ä½œçš„ç•Œé¢å…ƒç´ æœ‰:
{action_descriptions_str}

ä½œä¸ºWebæµ‹è¯•ä¸“å®¶ï¼Œè¯·é€‰æ‹©æœ€åˆé€‚çš„æ“ä½œæ¥ç»§ç»­æ¢ç´¢å’Œæµ‹è¯•åº”ç”¨ã€‚è€ƒè™‘ä»¥ä¸‹å› ç´ :
1. å½“å‰é¡µé¢çš„ç‰¹ç‚¹å’Œä¸»è¦åŠŸèƒ½
2. æ¢ç´¢æ–°åŠŸèƒ½å’Œé¡µé¢è·¯å¾„
3. æµ‹è¯•å…³é”®åŠŸèƒ½æµç¨‹
4. å‘ç°æ½œåœ¨çš„bugå’Œè¾¹ç•Œæƒ…å†µ
5. åˆ©ç”¨å†å²æµ‹è¯•ç»éªŒæŒ‡å¯¼å†³ç­–

è¯·è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå¯¹åº”ä¸Šé¢åˆ—è¡¨ä¸­åŠ¨ä½œçš„ç´¢å¼•ã€‚
å¦‚æœé€‰æ‹©çš„åŠ¨ä½œéœ€è¦æ–‡æœ¬è¾“å…¥ï¼Œè¯·è¿”å›ç´¢å¼•åè·Ÿå†’å·å’Œè¾“å…¥æ–‡æœ¬ã€‚
ä¾‹å¦‚ï¼šé€‰æ‹©ç”¨æˆ·åè¾“å…¥æ¡†å¹¶è¾“å…¥è´¦å·ï¼Œè¿”å›"2:Nefelibata-Zhu"

åªè¿”å›ç´¢å¼•æ•°å­—æˆ–"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–è§£é‡Šã€‚
""".strip()

        try:
            # ğŸ” 1. ä½¿ç”¨ä¼ ç»ŸRAGå¢å¼ºæç¤ºï¼ˆé™æ€çŸ¥è¯†ï¼‰
            augmented_prompt = self.retriever.retrieve(base_prompt)

            # ğŸ§  2. ä»thinkingçŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ¨ç†ç»éªŒ
            thinking_context = self.thinking_kb.retrieve_relevant_thinking(base_prompt, k=3)

            # ğŸ“Š 3. ä»çŠ¶æ€çŸ¥è¯†åº“æ£€ç´¢ç›¸ä¼¼é¡µé¢çŠ¶æ€ï¼ˆé‡è¦æ”¹è¿›ï¼ï¼‰
            state_context = self.state_kb.retrieve_similar_states(page_title, len(action_list), k=2)

            # ğŸš€ 4. ç»„åˆæ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯
            context_sections = [augmented_prompt]
            
            if thinking_context:
                context_sections.append(thinking_context)
            
            if state_context:
                context_sections.append(state_context)
            
            final_prompt = "\n\n".join(context_sections)

            if self.verbose:
                rag_enhanced = len(augmented_prompt) > len(base_prompt)
                print(f"Enhancement - RAG: {'âœ“' if rag_enhanced else 'âœ—'} | Thinking: {'âœ“' if thinking_context else 'âœ—'} | State: {'âœ“' if state_context else 'âœ—'}")

            # 5. è°ƒç”¨LLMè·å–å†³ç­–å’Œthinkingè¿‡ç¨‹
            llm_response = self.llm.chat_with_thinking(final_prompt)
            llm_output = llm_response["content"]
            reasoning = llm_response["reasoning"]

            if self.verbose:
                print(f"LLM output: {llm_output}")

            # 6. è§£æLLMè¾“å‡º
            action_index, input_text = self.parse_output(llm_output, len(action_list))

            if action_index is not None and 0 <= action_index < len(action_list):
                selected_action = action_list[action_index]

                # å¦‚æœæ˜¯è¾“å…¥ç±»åŠ¨ä½œå¹¶ä¸”æœ‰è¾“å…¥æ–‡æœ¬
                if isinstance(selected_action, RandomInputAction) and input_text:
                    if hasattr(selected_action, 'set_input_text'):
                        selected_action.set_input_text(input_text)

                # è®°å½•æ“ä½œåˆ°å†å²
                action_description = self.format_action_info(selected_action)
                if input_text:
                    action_description += f" with input: '{input_text}'"
                self.history.append(action_description)

                # ğŸ“Š 7. ä¿å­˜å®Œæ•´çš„é¡µé¢çŠ¶æ€ä¿¡æ¯åˆ°çŠ¶æ€çŸ¥è¯†åº“ï¼ˆå…³é”®æ”¹è¿›ï¼ï¼‰
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=action_index,
                    reasoning=reasoning
                )

                # ğŸ§  8. ä¿å­˜thinkingè¿‡ç¨‹åˆ°thinkingçŸ¥è¯†åº“
                self.thinking_kb.add_thinking(
                    prompt=base_prompt,
                    reasoning=reasoning,
                    action_taken=action_description
                )

                # ä¿æŒå†å²è®°å½•åœ¨é™å®šé•¿åº¦å†…
                if len(self.history) > self.max_history_length:
                    self.history = self.history[-self.max_history_length:]

                if self.verbose:
                    print(f"Selected action [{action_index}]: {action_description}")
                else:
                    # åœ¨éverboseæ¨¡å¼ä¸‹ï¼Œåªæ˜¾ç¤ºæœ€åŸºæœ¬çš„é€‰æ‹©ä¿¡æ¯
                    print(f"Action [{action_index}]: {self.format_action_info(selected_action)}")
                
                return selected_action
            else:
                if self.verbose:
                    print(f"Invalid index {action_index}, using fallback strategy")
                fallback_action = random.choice(action_list)

                # å³ä½¿æ˜¯å›é€€ç­–ç•¥ï¼Œä¹Ÿä¿å­˜çŠ¶æ€å’Œthinkingä¿¡æ¯
                fallback_description = f"Fallback: {self.format_action_info(fallback_action)}"
                
                self.state_kb.add_page_state(
                    page_title=page_title or "Unknown Page",
                    action_list=action_list,
                    selected_action_index=action_list.index(fallback_action),
                    reasoning=f"è§£æå¤±è´¥ï¼Œä½¿ç”¨éšæœºå›é€€ç­–ç•¥: {reasoning if reasoning else 'æ— æ¨ç†è¿‡ç¨‹'}"
                )

                if reasoning:
                    self.thinking_kb.add_thinking(
                        prompt=base_prompt,
                        reasoning=reasoning,
                        action_taken=fallback_description
                    )

                return fallback_action

        except Exception as e:
            if self.verbose:
                print(f"Error in decision making: {e}")
            fallback_action = random.choice(action_list)
            fallback_index = action_list.index(fallback_action)

            # è®°å½•é”™è¯¯æƒ…å†µ
            error_reasoning = f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}ï¼Œä½¿ç”¨éšæœºç­–ç•¥ä½œä¸ºå¤‡é€‰"
            error_description = f"Error fallback: {self.format_action_info(fallback_action)}"
            
            # å³ä½¿å‡ºé”™ä¹Ÿä¿å­˜çŠ¶æ€ä¿¡æ¯
            self.state_kb.add_page_state(
                page_title=page_title or "Unknown Page",
                action_list=action_list,
                selected_action_index=fallback_index,
                reasoning=error_reasoning
            )
            
            self.thinking_kb.add_thinking(
                prompt=base_prompt,
                reasoning=error_reasoning,
                action_taken=error_description
            )

            return fallback_action

    def parse_output(self, output: str, num_actions: int) -> tuple:
        """
        è§£æLLMè¾“å‡ºï¼Œæå–åŠ¨ä½œç´¢å¼•å’Œå¯èƒ½çš„è¾“å…¥æ–‡æœ¬
        è¿”å›ä¸€ä¸ªå…ƒç»„ (åŠ¨ä½œç´¢å¼•, è¾“å…¥æ–‡æœ¬)ï¼Œå¦‚æœæ²¡æœ‰è¾“å…¥æ–‡æœ¬åˆ™ä¸ºNone
        """
        # å†…éƒ¨å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå»é™¤ ANSI è½¬ä¹‰åºåˆ—
        def remove_ansi(text: str) -> str:
            ansi_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            return ansi_pattern.sub('', text)

        cleaned_output = remove_ansi(output).strip()

        # å°è¯•åŒ¹é…"ç´¢å¼•:æ–‡æœ¬"æ ¼å¼
        input_pattern = re.compile(r'^(\d+):(.+)$', re.DOTALL)
        match = input_pattern.match(cleaned_output)

        if match:
            index_str, input_text = match.groups()
            try:
                index = int(index_str)
                if 0 <= index < num_actions:
                    return index, input_text.strip()
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {index_str}")
                return None, None

        # å°è¯•ç›´æ¥æ‰¾å‡ºæ•°å­—
        number_match = re.search(r'^\d+', cleaned_output)
        if number_match:
            try:
                index = int(number_match.group())
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {number_match.group()}")
                return None, None

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–æœ€åä¸€ä¸ªæ•°å­—ä½œä¸ºç´¢å¼•
        numbers = re.findall(r'\d+', cleaned_output)
        if numbers:
            try:
                index = int(numbers[-1])
                if 0 <= index < num_actions:
                    return index, None
                else:
                    if self.verbose:
                        print(f"Index {index} out of range [0, {num_actions-1}]")
                    return None, None
            except ValueError:
                if self.verbose:
                    print(f"Cannot convert index: {numbers[-1]}")
                return None, None

        if self.verbose:
            print(f"Failed to parse output: {cleaned_output[:50]}...")
        return None, None


def main():
    """ç®€åŒ–çš„RAG LLM Agentæµ‹è¯•"""
    # æµ‹è¯•å‚æ•°
    test_params = {
        "api_key": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "embedding_token": "sk-esaaumvchjupuotzcybqofgbiuqbfmhwpvfwiyefacxznnpz",
        "app_name": "Test Application",
        "verbose": True,  # æµ‹è¯•æ—¶å¯ç”¨è¯¦ç»†è¾“å‡º
        "max_tokens": 512,
        "temperature": 0.7,
        "clear_rag_on_init": True,
        "clear_thinking_on_init": True,
        "clear_state_on_init": True,
        "reset_llm_on_init": True,
    }

    print("RAG LLM Agent Test")
    print("=" * 40)
    
    try:
        # æµ‹è¯•Agentåˆå§‹åŒ–
        agent = rag_llm_agent(test_params)
        print("âœ“ Agent initialized successfully")
        
        # æµ‹è¯•é‡ç½®åŠŸèƒ½
        original_session = agent.llm.session_id
        agent.reset_for_new_test()
        new_session = agent.llm.session_id
        
        print(f"âœ“ Reset test: {'Success' if original_session != new_session else 'Failed'}")
        
        print("=" * 40)
        print("Test completed successfully!")
        print("\nTo disable verbose output, set params['verbose'] = False")
        
    except Exception as e:
        print(f"âœ— Test failed: {e}")


if __name__ == "__main__":
    # åªæœ‰åœ¨ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰æ‰§è¡Œæµ‹è¯•
    main()
